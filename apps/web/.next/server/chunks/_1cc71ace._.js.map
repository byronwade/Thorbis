{"version":3,"sources":["../../../../../apps/web/src/lib/ai/store.tsx/__nextjs-internal-proxy.mjs","../../../../../apps/web/src/lib/ai/tracing.ts","../../../../../node_modules/.pnpm/next%4016.0.4_%40opentelemetry%2Bapi%401.9.0_react-dom%4019.2.0_react%4019.2.0__react%4019.2.0/node_modules/next/dist/esm/build/templates/app-route.js","../../../../../node_modules/.pnpm/%40ai-sdk-tools%2Bagents%401.2.0_%40ai-sdk-tools%2Bartifacts%401.2.0_ai%405.0.98_zod%404.1.12__react%4019.2.0___hlms42dljv2iu5mxir6u6bwuaa/node_modules/%40ai-sdk-tools/agents/dist/index.js","../../../../../apps/web/src/app/api/chat/route.ts","../../../../../node_modules/.pnpm/%40ai-sdk-tools%2Bartifacts%401.2.0_ai%405.0.98_zod%404.1.12__react%4019.2.0/node_modules/%40ai-sdk-tools/artifacts/dist/index.mjs","../../../../../apps/web/src/lib/ai/audit-trail.ts","../../../../../apps/web/src/lib/ai/cache.ts","../../../../../apps/web/src/lib/ai/index.ts","../../../../../apps/web/src/lib/ai/agents/index.ts","../../../../../apps/web/src/lib/ai/artifacts.ts","../../../../../node_modules/.pnpm/%40ai-sdk-tools%2Bcache%401.2.0_%40ai-sdk-tools%2Bartifacts%401.2.0_ai%405.0.98_zod%404.1.12__react%4019.2.0__ai%405.0.98_zod%404.1.12_/node_modules/%40ai-sdk-tools/artifacts/src/utils.ts","../../../../../node_modules/.pnpm/%40ai-sdk-tools%2Bcache%401.2.0_%40ai-sdk-tools%2Bartifacts%401.2.0_ai%405.0.98_zod%404.1.12__react%4019.2.0__ai%405.0.98_zod%404.1.12_/node_modules/%40ai-sdk-tools/artifacts/src/artifact.ts","../../../../../node_modules/.pnpm/next%4016.0.4_%40opentelemetry%2Bapi%401.9.0_react-dom%4019.2.0_react%4019.2.0__react%4019.2.0/node_modules/next/src/build/templates/app-route.ts","../../../../../apps/web/src/lib/ai/action-reverter.ts","../../../../../apps/web/src/lib/ai/memory-provider.ts","../../../../../apps/web/src/lib/ai/feedback-service.ts","../../../../../node_modules/.pnpm/%40ai-sdk-tools%2Bcache%401.2.0_%40ai-sdk-tools%2Bartifacts%401.2.0_ai%405.0.98_zod%404.1.12__react%4019.2.0__ai%405.0.98_zod%404.1.12_/node_modules/%40ai-sdk-tools/artifacts/src/context.ts","../../../../../apps/web/src/lib/ai/proactive-analyzer.ts","../../../../../apps/web/src/lib/ai/planner.ts","../../../../../node_modules/.pnpm/%40ai-sdk-tools%2Bcache%401.2.0_%40ai-sdk-tools%2Bartifacts%401.2.0_ai%405.0.98_zod%404.1.12__react%4019.2.0__ai%405.0.98_zod%404.1.12_/node_modules/%40ai-sdk-tools/artifacts/src/types.ts","../../../../../node_modules/.pnpm/%40ai-sdk-tools%2Bcache%401.2.0_%40ai-sdk-tools%2Bartifacts%401.2.0_ai%405.0.98_zod%404.1.12__react%4019.2.0__ai%405.0.98_zod%404.1.12_/node_modules/%40ai-sdk-tools/artifacts/src/streaming.ts","../../../../../node_modules/.pnpm/%40ai-sdk-tools%2Bartifacts%401.2.0_ai%405.0.98_zod%404.1.12__react%4019.2.0/node_modules/%40ai-sdk-tools/artifacts/src/artifact.ts","../../../../../node_modules/.pnpm/%40ai-sdk-tools%2Bartifacts%401.2.0_ai%405.0.98_zod%404.1.12__react%4019.2.0/node_modules/%40ai-sdk-tools/artifacts/src/types.ts","../../../../../node_modules/.pnpm/%40ai-sdk-tools%2Bagents%401.2.0_%40ai-sdk-tools%2Bartifacts%401.2.0_ai%405.0.98_zod%404.1.12__react%4019.2.0___hlms42dljv2iu5mxir6u6bwuaa/node_modules/%40ai-sdk-tools/agents/src/handoff.ts","../../../../../node_modules/.pnpm/%40ai-sdk-tools%2Bcache%401.2.0_%40ai-sdk-tools%2Bartifacts%401.2.0_ai%405.0.98_zod%404.1.12__react%4019.2.0__ai%405.0.98_zod%404.1.12_/node_modules/%40ai-sdk-tools/cache/src/cache-store.ts","../../../../../node_modules/.pnpm/%40ai-sdk-tools%2Bcache%401.2.0_%40ai-sdk-tools%2Bartifacts%401.2.0_ai%405.0.98_zod%404.1.12__react%4019.2.0__ai%405.0.98_zod%404.1.12_/node_modules/%40ai-sdk-tools/cache/src/backends/memory.ts","../../../../../node_modules/.pnpm/%40ai-sdk-tools%2Bagents%401.2.0_%40ai-sdk-tools%2Bartifacts%401.2.0_ai%405.0.98_zod%404.1.12__react%4019.2.0___hlms42dljv2iu5mxir6u6bwuaa/node_modules/%40ai-sdk-tools/agents/src/tool-result-extractor.ts","../../../../../node_modules/.pnpm/%40ai-sdk-tools%2Bagents%401.2.0_%40ai-sdk-tools%2Bartifacts%401.2.0_ai%405.0.98_zod%404.1.12__react%4019.2.0___hlms42dljv2iu5mxir6u6bwuaa/node_modules/%40ai-sdk-tools/agents/src/utils.ts","../../../../../node_modules/.pnpm/%40ai-sdk-tools%2Bcache%401.2.0_%40ai-sdk-tools%2Bartifacts%401.2.0_ai%405.0.98_zod%404.1.12__react%4019.2.0__ai%405.0.98_zod%404.1.12_/node_modules/%40ai-sdk-tools/cache/src/backends/redis.ts","../../../../../node_modules/.pnpm/%40ai-sdk-tools%2Bcache%401.2.0_%40ai-sdk-tools%2Bartifacts%401.2.0_ai%405.0.98_zod%404.1.12__react%4019.2.0__ai%405.0.98_zod%404.1.12_/node_modules/%40ai-sdk-tools/cache/src/backends/factory.ts","../../../../../node_modules/.pnpm/%40ai-sdk-tools%2Bcache%401.2.0_%40ai-sdk-tools%2Bartifacts%401.2.0_ai%405.0.98_zod%404.1.12__react%4019.2.0__ai%405.0.98_zod%404.1.12_/node_modules/%40ai-sdk-tools/cache/src/cache.ts","../../../../../node_modules/.pnpm/%40ai-sdk-tools%2Bagents%401.2.0_%40ai-sdk-tools%2Bartifacts%401.2.0_ai%405.0.98_zod%404.1.12__react%4019.2.0___hlms42dljv2iu5mxir6u6bwuaa/node_modules/%40ai-sdk-tools/agents/src/agent.ts"],"sourcesContent":["// This file is generated by next-core EcmascriptClientReferenceModule.\nimport { registerClientReference } from \"react-server-dom-turbopack/server\";\nexport const StratosChatProvider = registerClientReference(\n    function() { throw new Error(\"Attempted to call StratosChatProvider() from the server but StratosChatProvider is on the client. It's not possible to invoke a client function from the server, it can only be rendered as a Component or passed to props of a Client Component.\"); },\n    \"[project]/apps/web/src/lib/ai/store.tsx\",\n    \"StratosChatProvider\",\n);\nexport const createStratosChatStore = registerClientReference(\n    function() { throw new Error(\"Attempted to call createStratosChatStore() from the server but createStratosChatStore is on the client. It's not possible to invoke a client function from the server, it can only be rendered as a Component or passed to props of a Client Component.\"); },\n    \"[project]/apps/web/src/lib/ai/store.tsx\",\n    \"createStratosChatStore\",\n);\nexport const useAgentHandoff = registerClientReference(\n    function() { throw new Error(\"Attempted to call useAgentHandoff() from the server but useAgentHandoff is on the client. It's not possible to invoke a client function from the server, it can only be rendered as a Component or passed to props of a Client Component.\"); },\n    \"[project]/apps/web/src/lib/ai/store.tsx\",\n    \"useAgentHandoff\",\n);\nexport const useAgentStatus = registerClientReference(\n    function() { throw new Error(\"Attempted to call useAgentStatus() from the server but useAgentStatus is on the client. It's not possible to invoke a client function from the server, it can only be rendered as a Component or passed to props of a Client Component.\"); },\n    \"[project]/apps/web/src/lib/ai/store.tsx\",\n    \"useAgentStatus\",\n);\nexport const useArtifacts = registerClientReference(\n    function() { throw new Error(\"Attempted to call useArtifacts() from the server but useArtifacts is on the client. It's not possible to invoke a client function from the server, it can only be rendered as a Component or passed to props of a Client Component.\"); },\n    \"[project]/apps/web/src/lib/ai/store.tsx\",\n    \"useArtifacts\",\n);\nexport const useChatActions = registerClientReference(\n    function() { throw new Error(\"Attempted to call useChatActions() from the server but useChatActions is on the client. It's not possible to invoke a client function from the server, it can only be rendered as a Component or passed to props of a Client Component.\"); },\n    \"[project]/apps/web/src/lib/ai/store.tsx\",\n    \"useChatActions\",\n);\nexport const useChatError = registerClientReference(\n    function() { throw new Error(\"Attempted to call useChatError() from the server but useChatError is on the client. It's not possible to invoke a client function from the server, it can only be rendered as a Component or passed to props of a Client Component.\"); },\n    \"[project]/apps/web/src/lib/ai/store.tsx\",\n    \"useChatError\",\n);\nexport const useChatId = registerClientReference(\n    function() { throw new Error(\"Attempted to call useChatId() from the server but useChatId is on the client. It's not possible to invoke a client function from the server, it can only be rendered as a Component or passed to props of a Client Component.\"); },\n    \"[project]/apps/web/src/lib/ai/store.tsx\",\n    \"useChatId\",\n);\nexport const useChatMessages = registerClientReference(\n    function() { throw new Error(\"Attempted to call useChatMessages() from the server but useChatMessages is on the client. It's not possible to invoke a client function from the server, it can only be rendered as a Component or passed to props of a Client Component.\"); },\n    \"[project]/apps/web/src/lib/ai/store.tsx\",\n    \"useChatMessages\",\n);\nexport const useChatReset = registerClientReference(\n    function() { throw new Error(\"Attempted to call useChatReset() from the server but useChatReset is on the client. It's not possible to invoke a client function from the server, it can only be rendered as a Component or passed to props of a Client Component.\"); },\n    \"[project]/apps/web/src/lib/ai/store.tsx\",\n    \"useChatReset\",\n);\nexport const useChatStatus = registerClientReference(\n    function() { throw new Error(\"Attempted to call useChatStatus() from the server but useChatStatus is on the client. It's not possible to invoke a client function from the server, it can only be rendered as a Component or passed to props of a Client Component.\"); },\n    \"[project]/apps/web/src/lib/ai/store.tsx\",\n    \"useChatStatus\",\n);\nexport const useChatStore = registerClientReference(\n    function() { throw new Error(\"Attempted to call useChatStore() from the server but useChatStore is on the client. It's not possible to invoke a client function from the server, it can only be rendered as a Component or passed to props of a Client Component.\"); },\n    \"[project]/apps/web/src/lib/ai/store.tsx\",\n    \"useChatStore\",\n);\nexport const useDataPart = registerClientReference(\n    function() { throw new Error(\"Attempted to call useDataPart() from the server but useDataPart is on the client. It's not possible to invoke a client function from the server, it can only be rendered as a Component or passed to props of a Client Component.\"); },\n    \"[project]/apps/web/src/lib/ai/store.tsx\",\n    \"useDataPart\",\n);\nexport const useDataParts = registerClientReference(\n    function() { throw new Error(\"Attempted to call useDataParts() from the server but useDataParts is on the client. It's not possible to invoke a client function from the server, it can only be rendered as a Component or passed to props of a Client Component.\"); },\n    \"[project]/apps/web/src/lib/ai/store.tsx\",\n    \"useDataParts\",\n);\nexport const useIsStreaming = registerClientReference(\n    function() { throw new Error(\"Attempted to call useIsStreaming() from the server but useIsStreaming is on the client. It's not possible to invoke a client function from the server, it can only be rendered as a Component or passed to props of a Client Component.\"); },\n    \"[project]/apps/web/src/lib/ai/store.tsx\",\n    \"useIsStreaming\",\n);\nexport const useLastAssistantMessage = registerClientReference(\n    function() { throw new Error(\"Attempted to call useLastAssistantMessage() from the server but useLastAssistantMessage is on the client. It's not possible to invoke a client function from the server, it can only be rendered as a Component or passed to props of a Client Component.\"); },\n    \"[project]/apps/web/src/lib/ai/store.tsx\",\n    \"useLastAssistantMessage\",\n);\nexport const useMessageById = registerClientReference(\n    function() { throw new Error(\"Attempted to call useMessageById() from the server but useMessageById is on the client. It's not possible to invoke a client function from the server, it can only be rendered as a Component or passed to props of a Client Component.\"); },\n    \"[project]/apps/web/src/lib/ai/store.tsx\",\n    \"useMessageById\",\n);\nexport const useMessageCount = registerClientReference(\n    function() { throw new Error(\"Attempted to call useMessageCount() from the server but useMessageCount is on the client. It's not possible to invoke a client function from the server, it can only be rendered as a Component or passed to props of a Client Component.\"); },\n    \"[project]/apps/web/src/lib/ai/store.tsx\",\n    \"useMessageCount\",\n);\nexport const useMessageCountByRole = registerClientReference(\n    function() { throw new Error(\"Attempted to call useMessageCountByRole() from the server but useMessageCountByRole is on the client. It's not possible to invoke a client function from the server, it can only be rendered as a Component or passed to props of a Client Component.\"); },\n    \"[project]/apps/web/src/lib/ai/store.tsx\",\n    \"useMessageCountByRole\",\n);\nexport const useMessageIds = registerClientReference(\n    function() { throw new Error(\"Attempted to call useMessageIds() from the server but useMessageIds is on the client. It's not possible to invoke a client function from the server, it can only be rendered as a Component or passed to props of a Client Component.\"); },\n    \"[project]/apps/web/src/lib/ai/store.tsx\",\n    \"useMessageIds\",\n);\nexport const useRateLimit = registerClientReference(\n    function() { throw new Error(\"Attempted to call useRateLimit() from the server but useRateLimit is on the client. It's not possible to invoke a client function from the server, it can only be rendered as a Component or passed to props of a Client Component.\"); },\n    \"[project]/apps/web/src/lib/ai/store.tsx\",\n    \"useRateLimit\",\n);\nexport const useSelector = registerClientReference(\n    function() { throw new Error(\"Attempted to call useSelector() from the server but useSelector is on the client. It's not possible to invoke a client function from the server, it can only be rendered as a Component or passed to props of a Client Component.\"); },\n    \"[project]/apps/web/src/lib/ai/store.tsx\",\n    \"useSelector\",\n);\nexport const useSuggestions = registerClientReference(\n    function() { throw new Error(\"Attempted to call useSuggestions() from the server but useSuggestions is on the client. It's not possible to invoke a client function from the server, it can only be rendered as a Component or passed to props of a Client Component.\"); },\n    \"[project]/apps/web/src/lib/ai/store.tsx\",\n    \"useSuggestions\",\n);\nexport const useVirtualMessages = registerClientReference(\n    function() { throw new Error(\"Attempted to call useVirtualMessages() from the server but useVirtualMessages is on the client. It's not possible to invoke a client function from the server, it can only be rendered as a Component or passed to props of a Client Component.\"); },\n    \"[project]/apps/web/src/lib/ai/store.tsx\",\n    \"useVirtualMessages\",\n);\n","/**\n * AI Tracing Service - OpenTelemetry-style trace and span management\n * Based on industry best practices from Langfuse, Datadog, and Grafana\n */\n\nimport { createServiceSupabaseClient } from \"@/lib/supabase/service-client\";\n\nexport type SpanType =\n  | \"llm_call\"\n  | \"tool_execution\"\n  | \"retrieval\"\n  | \"embedding\"\n  | \"user_input\"\n  | \"system\"\n  | \"agent_step\"\n  | \"memory_operation\";\n\nexport type SpanStatus = \"running\" | \"completed\" | \"failed\" | \"cancelled\" | \"timeout\";\n\nexport interface TraceContext {\n  traceId: string;\n  companyId: string;\n  userId?: string;\n  chatId?: string;\n}\n\nexport interface SpanData {\n  spanName: string;\n  spanType: SpanType;\n  parentSpanId?: string;\n  modelId?: string;\n  modelProvider?: string;\n  inputTokens?: number;\n  outputTokens?: number;\n  inputCostCents?: number;\n  outputCostCents?: number;\n  temperature?: number;\n  maxTokens?: number;\n  topP?: number;\n  promptTemplateId?: string;\n  promptVersion?: string;\n  inputPreview?: string;\n  outputPreview?: string;\n  fullInput?: Record<string, unknown>;\n  fullOutput?: Record<string, unknown>;\n  toolName?: string;\n  toolCategory?: string;\n  toolParams?: Record<string, unknown>;\n  toolResult?: Record<string, unknown>;\n  metadata?: Record<string, unknown>;\n  tags?: string[];\n}\n\nexport interface SpanEvent {\n  eventType: string;\n  eventName: string;\n  level?: \"debug\" | \"info\" | \"warn\" | \"error\" | \"critical\";\n  message?: string;\n  attributes?: Record<string, unknown>;\n  exceptionType?: string;\n  exceptionMessage?: string;\n  exceptionStack?: string;\n  durationMs?: number;\n}\n\n// Cost per 1M tokens (in cents) - update as pricing changes\nconst MODEL_COSTS: Record<string, { input: number; output: number }> = {\n  \"claude-3-5-sonnet-20241022\": { input: 300, output: 1500 },\n  \"claude-3-opus-20240229\": { input: 1500, output: 7500 },\n  \"claude-3-haiku-20240307\": { input: 25, output: 125 },\n  \"gpt-4-turbo\": { input: 1000, output: 3000 },\n  \"gpt-4o\": { input: 500, output: 1500 },\n  \"gpt-3.5-turbo\": { input: 50, output: 150 },\n};\n\n/**\n * Generate a new trace ID\n */\nexport function generateTraceId(): string {\n  return crypto.randomUUID();\n}\n\n/**\n * Create a new trace context\n */\nexport function createTraceContext(\n  companyId: string,\n  options?: { userId?: string; chatId?: string }\n): TraceContext {\n  return {\n    traceId: generateTraceId(),\n    companyId,\n    userId: options?.userId,\n    chatId: options?.chatId,\n  };\n}\n\n/**\n * Calculate cost from token counts\n */\nexport function calculateCost(\n  modelId: string,\n  inputTokens: number,\n  outputTokens: number\n): { inputCostCents: number; outputCostCents: number } {\n  const costs = MODEL_COSTS[modelId] || { input: 300, output: 1500 }; // Default to Sonnet pricing\n  return {\n    inputCostCents: (inputTokens / 1_000_000) * costs.input,\n    outputCostCents: (outputTokens / 1_000_000) * costs.output,\n  };\n}\n\n/**\n * Start a new span\n */\nexport async function startSpan(\n  context: TraceContext,\n  data: SpanData\n): Promise<string> {\n  const supabase = createServiceSupabaseClient();\n  const spanId = crypto.randomUUID();\n\n  const { error } = await supabase.from(\"ai_traces\").insert({\n    id: spanId,\n    trace_id: context.traceId,\n    company_id: context.companyId,\n    user_id: context.userId,\n    chat_id: context.chatId,\n    span_name: data.spanName,\n    span_type: data.spanType,\n    parent_span_id: data.parentSpanId,\n    model_id: data.modelId,\n    model_provider: data.modelProvider,\n    input_tokens: data.inputTokens || 0,\n    output_tokens: data.outputTokens || 0,\n    input_cost_cents: data.inputCostCents || 0,\n    output_cost_cents: data.outputCostCents || 0,\n    temperature: data.temperature,\n    max_tokens: data.maxTokens,\n    top_p: data.topP,\n    prompt_template_id: data.promptTemplateId,\n    prompt_version: data.promptVersion,\n    input_preview: data.inputPreview?.substring(0, 1000),\n    output_preview: data.outputPreview?.substring(0, 1000),\n    full_input: data.fullInput,\n    full_output: data.fullOutput,\n    tool_name: data.toolName,\n    tool_category: data.toolCategory,\n    tool_params: data.toolParams,\n    tool_result: data.toolResult,\n    metadata: data.metadata || {},\n    tags: data.tags || [],\n    status: \"running\",\n    started_at: new Date().toISOString(),\n  });\n\n  if (error) {\n    console.error(\"Failed to start span:\", error);\n    throw error;\n  }\n\n  return spanId;\n}\n\n/**\n * End a span with results\n */\nexport async function endSpan(\n  spanId: string,\n  companyId: string,\n  result: {\n    status: SpanStatus;\n    outputTokens?: number;\n    outputCostCents?: number;\n    outputPreview?: string;\n    fullOutput?: Record<string, unknown>;\n    toolResult?: Record<string, unknown>;\n    errorType?: string;\n    errorMessage?: string;\n    errorStack?: string;\n    durationMs?: number;\n    timeToFirstTokenMs?: number;\n  }\n): Promise<void> {\n  const supabase = createServiceSupabaseClient();\n  const endedAt = new Date().toISOString();\n\n  const { error } = await supabase\n    .from(\"ai_traces\")\n    .update({\n      status: result.status,\n      ended_at: endedAt,\n      duration_ms: result.durationMs,\n      time_to_first_token_ms: result.timeToFirstTokenMs,\n      output_tokens: result.outputTokens,\n      output_cost_cents: result.outputCostCents,\n      output_preview: result.outputPreview?.substring(0, 1000),\n      full_output: result.fullOutput,\n      tool_result: result.toolResult,\n      error_type: result.errorType,\n      error_message: result.errorMessage,\n      error_stack: result.errorStack,\n    })\n    .eq(\"id\", spanId)\n    .eq(\"company_id\", companyId);\n\n  if (error) {\n    console.error(\"Failed to end span:\", error);\n  }\n}\n\n/**\n * Record a span event\n */\nexport async function recordSpanEvent(\n  spanId: string,\n  traceId: string,\n  companyId: string,\n  event: SpanEvent\n): Promise<void> {\n  const supabase = createServiceSupabaseClient();\n\n  const { error } = await supabase.from(\"ai_span_events\").insert({\n    span_id: spanId,\n    trace_id: traceId,\n    company_id: companyId,\n    event_type: event.eventType,\n    event_name: event.eventName,\n    level: event.level || \"info\",\n    message: event.message,\n    attributes: event.attributes,\n    exception_type: event.exceptionType,\n    exception_message: event.exceptionMessage,\n    exception_stack: event.exceptionStack,\n    duration_ms: event.durationMs,\n    timestamp: new Date().toISOString(),\n  });\n\n  if (error) {\n    console.error(\"Failed to record span event:\", error);\n  }\n}\n\n/**\n * Get trace summary for a conversation\n */\nexport async function getTraceSummary(\n  companyId: string,\n  traceId: string\n): Promise<{\n  totalTokens: number;\n  totalCostCents: number;\n  totalDurationMs: number;\n  spanCount: number;\n  errorCount: number;\n}> {\n  const supabase = createServiceSupabaseClient();\n\n  const { data, error } = await supabase\n    .from(\"ai_traces\")\n    .select(\"input_tokens, output_tokens, input_cost_cents, output_cost_cents, duration_ms, status\")\n    .eq(\"company_id\", companyId)\n    .eq(\"trace_id\", traceId);\n\n  if (error || !data) {\n    return {\n      totalTokens: 0,\n      totalCostCents: 0,\n      totalDurationMs: 0,\n      spanCount: 0,\n      errorCount: 0,\n    };\n  }\n\n  return {\n    totalTokens: data.reduce((sum, s) => sum + (s.input_tokens || 0) + (s.output_tokens || 0), 0),\n    totalCostCents: data.reduce((sum, s) => sum + (s.input_cost_cents || 0) + (s.output_cost_cents || 0), 0),\n    totalDurationMs: data.reduce((sum, s) => sum + (s.duration_ms || 0), 0),\n    spanCount: data.length,\n    errorCount: data.filter(s => s.status === \"failed\" || s.status === \"timeout\").length,\n  };\n}\n\n/**\n * Get daily metrics for a company\n */\nexport async function getDailyMetrics(\n  companyId: string,\n  date: Date\n): Promise<{\n  totalTraces: number;\n  totalTokens: number;\n  totalCostCents: number;\n  avgLatencyMs: number;\n  errorRate: number;\n  topTools: Array<{ tool: string; count: number }>;\n}> {\n  const supabase = createServiceSupabaseClient();\n  const startOfDay = new Date(date);\n  startOfDay.setHours(0, 0, 0, 0);\n  const endOfDay = new Date(date);\n  endOfDay.setHours(23, 59, 59, 999);\n\n  const { data, error } = await supabase\n    .from(\"ai_traces\")\n    .select(\"trace_id, input_tokens, output_tokens, input_cost_cents, output_cost_cents, duration_ms, status, tool_name\")\n    .eq(\"company_id\", companyId)\n    .gte(\"created_at\", startOfDay.toISOString())\n    .lte(\"created_at\", endOfDay.toISOString());\n\n  if (error || !data) {\n    return {\n      totalTraces: 0,\n      totalTokens: 0,\n      totalCostCents: 0,\n      avgLatencyMs: 0,\n      errorRate: 0,\n      topTools: [],\n    };\n  }\n\n  const uniqueTraces = new Set(data.map(d => d.trace_id)).size;\n  const totalTokens = data.reduce((sum, s) => sum + (s.input_tokens || 0) + (s.output_tokens || 0), 0);\n  const totalCost = data.reduce((sum, s) => sum + (s.input_cost_cents || 0) + (s.output_cost_cents || 0), 0);\n  const durations = data.filter(s => s.duration_ms).map(s => s.duration_ms!);\n  const avgLatency = durations.length > 0 ? durations.reduce((a, b) => a + b, 0) / durations.length : 0;\n  const errors = data.filter(s => s.status === \"failed\" || s.status === \"timeout\").length;\n  const errorRate = data.length > 0 ? (errors / data.length) * 100 : 0;\n\n  // Count tool usage\n  const toolCounts: Record<string, number> = {};\n  data.filter(s => s.tool_name).forEach(s => {\n    toolCounts[s.tool_name!] = (toolCounts[s.tool_name!] || 0) + 1;\n  });\n  const topTools = Object.entries(toolCounts)\n    .map(([tool, count]) => ({ tool, count }))\n    .sort((a, b) => b.count - a.count)\n    .slice(0, 10);\n\n  return {\n    totalTraces: uniqueTraces,\n    totalTokens,\n    totalCostCents: totalCost,\n    avgLatencyMs: Math.round(avgLatency),\n    errorRate: Math.round(errorRate * 100) / 100,\n    topTools,\n  };\n}\n","import { AppRouteRouteModule } from \"next/dist/esm/server/route-modules/app-route/module.compiled\";\nimport { RouteKind } from \"next/dist/esm/server/route-kind\";\nimport { patchFetch as _patchFetch } from \"next/dist/esm/server/lib/patch-fetch\";\nimport { addRequestMeta, getRequestMeta } from \"next/dist/esm/server/request-meta\";\nimport { getTracer, SpanKind } from \"next/dist/esm/server/lib/trace/tracer\";\nimport { setReferenceManifestsSingleton } from \"next/dist/esm/server/app-render/encryption-utils\";\nimport { createServerModuleMap } from \"next/dist/esm/server/app-render/action-utils\";\nimport { normalizeAppPath } from \"next/dist/esm/shared/lib/router/utils/app-paths\";\nimport { NodeNextRequest, NodeNextResponse } from \"next/dist/esm/server/base-http/node\";\nimport { NextRequestAdapter, signalFromNodeResponse } from \"next/dist/esm/server/web/spec-extension/adapters/next-request\";\nimport { BaseServerSpan } from \"next/dist/esm/server/lib/trace/constants\";\nimport { getRevalidateReason } from \"next/dist/esm/server/instrumentation/utils\";\nimport { sendResponse } from \"next/dist/esm/server/send-response\";\nimport { fromNodeOutgoingHttpHeaders, toNodeOutgoingHttpHeaders } from \"next/dist/esm/server/web/utils\";\nimport { getCacheControlHeader } from \"next/dist/esm/server/lib/cache-control\";\nimport { INFINITE_CACHE, NEXT_CACHE_TAGS_HEADER } from \"next/dist/esm/lib/constants\";\nimport { NoFallbackError } from \"next/dist/esm/shared/lib/no-fallback-error.external\";\nimport { CachedRouteKind } from \"next/dist/esm/server/response-cache\";\nimport * as userland from \"INNER_APP_ROUTE\";\n// We inject the nextConfigOutput here so that we can use them in the route\n// module.\nconst nextConfigOutput = \"\"\nconst routeModule = new AppRouteRouteModule({\n    definition: {\n        kind: RouteKind.APP_ROUTE,\n        page: \"/api/chat/route\",\n        pathname: \"/api/chat\",\n        filename: \"route\",\n        bundlePath: \"\"\n    },\n    distDir: process.env.__NEXT_RELATIVE_DIST_DIR || '',\n    relativeProjectDir: process.env.__NEXT_RELATIVE_PROJECT_DIR || '',\n    resolvedPagePath: \"[project]/apps/web/src/app/api/chat/route.ts\",\n    nextConfigOutput,\n    userland\n});\n// Pull out the exports that we need to expose from the module. This should\n// be eliminated when we've moved the other routes to the new format. These\n// are used to hook into the route.\nconst { workAsyncStorage, workUnitAsyncStorage, serverHooks } = routeModule;\nfunction patchFetch() {\n    return _patchFetch({\n        workAsyncStorage,\n        workUnitAsyncStorage\n    });\n}\nexport { routeModule, workAsyncStorage, workUnitAsyncStorage, serverHooks, patchFetch,  };\nexport async function handler(req, res, ctx) {\n    if (routeModule.isDev) {\n        addRequestMeta(req, 'devRequestTimingInternalsEnd', process.hrtime.bigint());\n    }\n    let srcPage = \"/api/chat/route\";\n    // turbopack doesn't normalize `/index` in the page name\n    // so we need to to process dynamic routes properly\n    // TODO: fix turbopack providing differing value from webpack\n    if (process.env.TURBOPACK) {\n        srcPage = srcPage.replace(/\\/index$/, '') || '/';\n    } else if (srcPage === '/index') {\n        // we always normalize /index specifically\n        srcPage = '/';\n    }\n    const multiZoneDraftMode = process.env.__NEXT_MULTI_ZONE_DRAFT_MODE;\n    const prepareResult = await routeModule.prepare(req, res, {\n        srcPage,\n        multiZoneDraftMode\n    });\n    if (!prepareResult) {\n        res.statusCode = 400;\n        res.end('Bad Request');\n        ctx.waitUntil == null ? void 0 : ctx.waitUntil.call(ctx, Promise.resolve());\n        return null;\n    }\n    const { buildId, params, nextConfig, parsedUrl, isDraftMode, prerenderManifest, routerServerContext, isOnDemandRevalidate, revalidateOnlyGenerated, resolvedPathname, clientReferenceManifest, serverActionsManifest } = prepareResult;\n    const normalizedSrcPage = normalizeAppPath(srcPage);\n    let isIsr = Boolean(prerenderManifest.dynamicRoutes[normalizedSrcPage] || prerenderManifest.routes[resolvedPathname]);\n    const render404 = async ()=>{\n        // TODO: should route-module itself handle rendering the 404\n        if (routerServerContext == null ? void 0 : routerServerContext.render404) {\n            await routerServerContext.render404(req, res, parsedUrl, false);\n        } else {\n            res.end('This page could not be found');\n        }\n        return null;\n    };\n    if (isIsr && !isDraftMode) {\n        const isPrerendered = Boolean(prerenderManifest.routes[resolvedPathname]);\n        const prerenderInfo = prerenderManifest.dynamicRoutes[normalizedSrcPage];\n        if (prerenderInfo) {\n            if (prerenderInfo.fallback === false && !isPrerendered) {\n                if (nextConfig.experimental.adapterPath) {\n                    return await render404();\n                }\n                throw new NoFallbackError();\n            }\n        }\n    }\n    let cacheKey = null;\n    if (isIsr && !routeModule.isDev && !isDraftMode) {\n        cacheKey = resolvedPathname;\n        // ensure /index and / is normalized to one key\n        cacheKey = cacheKey === '/index' ? '/' : cacheKey;\n    }\n    const supportsDynamicResponse = // If we're in development, we always support dynamic HTML\n    routeModule.isDev === true || // If this is not SSG or does not have static paths, then it supports\n    // dynamic HTML.\n    !isIsr;\n    // This is a revalidation request if the request is for a static\n    // page and it is not being resumed from a postponed render and\n    // it is not a dynamic RSC request then it is a revalidation\n    // request.\n    const isStaticGeneration = isIsr && !supportsDynamicResponse;\n    // Before rendering (which initializes component tree modules), we have to\n    // set the reference manifests to our global store so Server Action's\n    // encryption util can access to them at the top level of the page module.\n    if (serverActionsManifest && clientReferenceManifest) {\n        setReferenceManifestsSingleton({\n            page: srcPage,\n            clientReferenceManifest,\n            serverActionsManifest,\n            serverModuleMap: createServerModuleMap({\n                serverActionsManifest\n            })\n        });\n    }\n    const method = req.method || 'GET';\n    const tracer = getTracer();\n    const activeSpan = tracer.getActiveScopeSpan();\n    const context = {\n        params,\n        prerenderManifest,\n        renderOpts: {\n            experimental: {\n                authInterrupts: Boolean(nextConfig.experimental.authInterrupts)\n            },\n            cacheComponents: Boolean(nextConfig.cacheComponents),\n            supportsDynamicResponse,\n            incrementalCache: getRequestMeta(req, 'incrementalCache'),\n            cacheLifeProfiles: nextConfig.cacheLife,\n            waitUntil: ctx.waitUntil,\n            onClose: (cb)=>{\n                res.on('close', cb);\n            },\n            onAfterTaskError: undefined,\n            onInstrumentationRequestError: (error, _request, errorContext)=>routeModule.onRequestError(req, error, errorContext, routerServerContext)\n        },\n        sharedContext: {\n            buildId\n        }\n    };\n    const nodeNextReq = new NodeNextRequest(req);\n    const nodeNextRes = new NodeNextResponse(res);\n    const nextReq = NextRequestAdapter.fromNodeNextRequest(nodeNextReq, signalFromNodeResponse(res));\n    try {\n        const invokeRouteModule = async (span)=>{\n            return routeModule.handle(nextReq, context).finally(()=>{\n                if (!span) return;\n                span.setAttributes({\n                    'http.status_code': res.statusCode,\n                    'next.rsc': false\n                });\n                const rootSpanAttributes = tracer.getRootSpanAttributes();\n                // We were unable to get attributes, probably OTEL is not enabled\n                if (!rootSpanAttributes) {\n                    return;\n                }\n                if (rootSpanAttributes.get('next.span_type') !== BaseServerSpan.handleRequest) {\n                    console.warn(`Unexpected root span type '${rootSpanAttributes.get('next.span_type')}'. Please report this Next.js issue https://github.com/vercel/next.js`);\n                    return;\n                }\n                const route = rootSpanAttributes.get('next.route');\n                if (route) {\n                    const name = `${method} ${route}`;\n                    span.setAttributes({\n                        'next.route': route,\n                        'http.route': route,\n                        'next.span_name': name\n                    });\n                    span.updateName(name);\n                } else {\n                    span.updateName(`${method} ${srcPage}`);\n                }\n            });\n        };\n        const isMinimalMode = Boolean(process.env.MINIMAL_MODE || getRequestMeta(req, 'minimalMode'));\n        const handleResponse = async (currentSpan)=>{\n            var _cacheEntry_value;\n            const responseGenerator = async ({ previousCacheEntry })=>{\n                try {\n                    if (!isMinimalMode && isOnDemandRevalidate && revalidateOnlyGenerated && !previousCacheEntry) {\n                        res.statusCode = 404;\n                        // on-demand revalidate always sets this header\n                        res.setHeader('x-nextjs-cache', 'REVALIDATED');\n                        res.end('This page could not be found');\n                        return null;\n                    }\n                    const response = await invokeRouteModule(currentSpan);\n                    req.fetchMetrics = context.renderOpts.fetchMetrics;\n                    let pendingWaitUntil = context.renderOpts.pendingWaitUntil;\n                    // Attempt using provided waitUntil if available\n                    // if it's not we fallback to sendResponse's handling\n                    if (pendingWaitUntil) {\n                        if (ctx.waitUntil) {\n                            ctx.waitUntil(pendingWaitUntil);\n                            pendingWaitUntil = undefined;\n                        }\n                    }\n                    const cacheTags = context.renderOpts.collectedTags;\n                    // If the request is for a static response, we can cache it so long\n                    // as it's not edge.\n                    if (isIsr) {\n                        const blob = await response.blob();\n                        // Copy the headers from the response.\n                        const headers = toNodeOutgoingHttpHeaders(response.headers);\n                        if (cacheTags) {\n                            headers[NEXT_CACHE_TAGS_HEADER] = cacheTags;\n                        }\n                        if (!headers['content-type'] && blob.type) {\n                            headers['content-type'] = blob.type;\n                        }\n                        const revalidate = typeof context.renderOpts.collectedRevalidate === 'undefined' || context.renderOpts.collectedRevalidate >= INFINITE_CACHE ? false : context.renderOpts.collectedRevalidate;\n                        const expire = typeof context.renderOpts.collectedExpire === 'undefined' || context.renderOpts.collectedExpire >= INFINITE_CACHE ? undefined : context.renderOpts.collectedExpire;\n                        // Create the cache entry for the response.\n                        const cacheEntry = {\n                            value: {\n                                kind: CachedRouteKind.APP_ROUTE,\n                                status: response.status,\n                                body: Buffer.from(await blob.arrayBuffer()),\n                                headers\n                            },\n                            cacheControl: {\n                                revalidate,\n                                expire\n                            }\n                        };\n                        return cacheEntry;\n                    } else {\n                        // send response without caching if not ISR\n                        await sendResponse(nodeNextReq, nodeNextRes, response, context.renderOpts.pendingWaitUntil);\n                        return null;\n                    }\n                } catch (err) {\n                    // if this is a background revalidate we need to report\n                    // the request error here as it won't be bubbled\n                    if (previousCacheEntry == null ? void 0 : previousCacheEntry.isStale) {\n                        await routeModule.onRequestError(req, err, {\n                            routerKind: 'App Router',\n                            routePath: srcPage,\n                            routeType: 'route',\n                            revalidateReason: getRevalidateReason({\n                                isStaticGeneration,\n                                isOnDemandRevalidate\n                            })\n                        }, routerServerContext);\n                    }\n                    throw err;\n                }\n            };\n            const cacheEntry = await routeModule.handleResponse({\n                req,\n                nextConfig,\n                cacheKey,\n                routeKind: RouteKind.APP_ROUTE,\n                isFallback: false,\n                prerenderManifest,\n                isRoutePPREnabled: false,\n                isOnDemandRevalidate,\n                revalidateOnlyGenerated,\n                responseGenerator,\n                waitUntil: ctx.waitUntil,\n                isMinimalMode\n            });\n            // we don't create a cacheEntry for ISR\n            if (!isIsr) {\n                return null;\n            }\n            if ((cacheEntry == null ? void 0 : (_cacheEntry_value = cacheEntry.value) == null ? void 0 : _cacheEntry_value.kind) !== CachedRouteKind.APP_ROUTE) {\n                var _cacheEntry_value1;\n                throw Object.defineProperty(new Error(`Invariant: app-route received invalid cache entry ${cacheEntry == null ? void 0 : (_cacheEntry_value1 = cacheEntry.value) == null ? void 0 : _cacheEntry_value1.kind}`), \"__NEXT_ERROR_CODE\", {\n                    value: \"E701\",\n                    enumerable: false,\n                    configurable: true\n                });\n            }\n            if (!isMinimalMode) {\n                res.setHeader('x-nextjs-cache', isOnDemandRevalidate ? 'REVALIDATED' : cacheEntry.isMiss ? 'MISS' : cacheEntry.isStale ? 'STALE' : 'HIT');\n            }\n            // Draft mode should never be cached\n            if (isDraftMode) {\n                res.setHeader('Cache-Control', 'private, no-cache, no-store, max-age=0, must-revalidate');\n            }\n            const headers = fromNodeOutgoingHttpHeaders(cacheEntry.value.headers);\n            if (!(isMinimalMode && isIsr)) {\n                headers.delete(NEXT_CACHE_TAGS_HEADER);\n            }\n            // If cache control is already set on the response we don't\n            // override it to allow users to customize it via next.config\n            if (cacheEntry.cacheControl && !res.getHeader('Cache-Control') && !headers.get('Cache-Control')) {\n                headers.set('Cache-Control', getCacheControlHeader(cacheEntry.cacheControl));\n            }\n            await sendResponse(nodeNextReq, nodeNextRes, // @ts-expect-error - Argument of type 'Buffer<ArrayBufferLike>' is not assignable to parameter of type 'BodyInit | null | undefined'.\n            new Response(cacheEntry.value.body, {\n                headers,\n                status: cacheEntry.value.status || 200\n            }));\n            return null;\n        };\n        // TODO: activeSpan code path is for when wrapped by\n        // next-server can be removed when this is no longer used\n        if (activeSpan) {\n            await handleResponse(activeSpan);\n        } else {\n            await tracer.withPropagatedContext(req.headers, ()=>tracer.trace(BaseServerSpan.handleRequest, {\n                    spanName: `${method} ${srcPage}`,\n                    kind: SpanKind.SERVER,\n                    attributes: {\n                        'http.method': method,\n                        'http.target': req.url\n                    }\n                }, handleResponse));\n        }\n    } catch (err) {\n        if (!(err instanceof NoFallbackError)) {\n            await routeModule.onRequestError(req, err, {\n                routerKind: 'App Router',\n                routePath: normalizedSrcPage,\n                routeType: 'route',\n                revalidateReason: getRevalidateReason({\n                    isStaticGeneration,\n                    isOnDemandRevalidate\n                })\n            });\n        }\n        // rethrow so that we can handle serving error page\n        // If this is during static generation, throw the error again.\n        if (isIsr) throw err;\n        // Otherwise, send a 500 response.\n        await sendResponse(nodeNextReq, nodeNextRes, new Response(null, {\n            status: 500\n        }));\n        return null;\n    }\n}\n\n//# sourceMappingURL=app-route.js.map\n","var __defProp = Object.defineProperty;\nvar __getOwnPropNames = Object.getOwnPropertyNames;\nvar __esm = (fn, res) => function __init() {\n  return fn && (res = (0, fn[__getOwnPropNames(fn)[0]])(fn = 0)), res;\n};\nvar __export = (target, all) => {\n  for (var name in all)\n    __defProp(target, name, { get: all[name], enumerable: true });\n};\n\n// src/context.ts\nvar context_exports = {};\n__export(context_exports, {\n  createExecutionContext: () => createExecutionContext,\n  getContext: () => getContext\n});\nfunction createExecutionContext(options) {\n  return {\n    ...options.context,\n    writer: options.writer,\n    metadata: {\n      startTime: /* @__PURE__ */ new Date(),\n      ...options.metadata\n    }\n  };\n}\nfunction getContext(executionOptions) {\n  return executionOptions?.experimental_context;\n}\nvar init_context = __esm({\n  \"src/context.ts\"() {\n    \"use strict\";\n  }\n});\n\n// ../debug/dist/index.js\nvar isDebugEnabled = process.env.DEBUG_AGENTS === \"true\";\nvar colors = {\n  reset: \"\\x1B[0m\",\n  gray: \"\\x1B[90m\",\n  blue: \"\\x1B[34m\",\n  cyan: \"\\x1B[36m\",\n  yellow: \"\\x1B[33m\",\n  red: \"\\x1B[31m\",\n  green: \"\\x1B[32m\",\n  magenta: \"\\x1B[35m\"\n};\nvar timestamp = () => (/* @__PURE__ */ new Date()).toISOString().slice(11, 23);\nfunction createLogger(category) {\n  if (!isDebugEnabled) {\n    return {\n      debug: () => {\n      },\n      info: () => {\n      },\n      warn: () => {\n      },\n      error: () => {\n      }\n    };\n  }\n  return {\n    debug: (message, data) => {\n      const ts = `${colors.gray}[${timestamp()}]${colors.reset}`;\n      const level = `${colors.blue}DEBUG${colors.reset}`;\n      const cat = `${colors.cyan}[${category}]${colors.reset}`;\n      const dataStr = data ? ` ${colors.gray}${JSON.stringify(data)}${colors.reset}` : \"\";\n      console.log(`${ts} ${level} ${cat} ${message}${dataStr}`);\n    },\n    info: (message, data) => {\n      const ts = `${colors.gray}[${timestamp()}]${colors.reset}`;\n      const level = `${colors.green}INFO${colors.reset}`;\n      const cat = `${colors.cyan}[${category}]${colors.reset}`;\n      const dataStr = data ? ` ${colors.gray}${JSON.stringify(data)}${colors.reset}` : \"\";\n      console.log(`${ts} ${level} ${cat} ${message}${dataStr}`);\n    },\n    warn: (message, data) => {\n      const ts = `${colors.gray}[${timestamp()}]${colors.reset}`;\n      const level = `${colors.yellow}WARN${colors.reset}`;\n      const cat = `${colors.cyan}[${category}]${colors.reset}`;\n      const dataStr = data ? ` ${colors.gray}${JSON.stringify(data)}${colors.reset}` : \"\";\n      console.warn(`${ts} ${level} ${cat} ${message}${dataStr}`);\n    },\n    error: (message, data) => {\n      const ts = `${colors.gray}[${timestamp()}]${colors.reset}`;\n      const level = `${colors.red}ERROR${colors.reset}`;\n      const cat = `${colors.cyan}[${category}]${colors.reset}`;\n      const dataStr = data ? ` ${colors.gray}${JSON.stringify(data)}${colors.reset}` : \"\";\n      console.error(`${ts} ${level} ${cat} ${message}${dataStr}`);\n    }\n  };\n}\n\n// ../memory/dist/index.js\nvar DEFAULT_TEMPLATE = `# Working Memory\n\n## Key Facts\n- [Important information goes here]\n\n## Current Focus\n- [What the user is working on]\n\n## Preferences\n- [User preferences and settings]\n`;\nfunction formatWorkingMemory(memory) {\n  if (!memory?.content) return \"\";\n  return `\n## Working Memory\n\n${memory.content}\n`;\n}\nfunction getWorkingMemoryInstructions(template) {\n  return `\n## Working Memory\n\nYou have access to persistent working memory that stores user preferences, context, and important facts across conversations.\n\n**ALWAYS call updateWorkingMemory when:**\n- User shares OR corrects their name, role, company, or preferences\n- User provides OR updates important facts you should remember\n- User corrects previous information about themselves\n- Any new or changed context that should persist for future conversations\n\n**Template structure to follow:**\n\\`\\`\\`\n${template}\n\\`\\`\\`\n\n**Critical:** After calling updateWorkingMemory, respond to the user confirming the update.\n`.trim();\n}\n\n// src/agent.ts\ninit_context();\nimport {\n  Experimental_Agent as AISDKAgent,\n  convertToModelMessages,\n  createUIMessageStream,\n  createUIMessageStreamResponse,\n  generateObject,\n  generateText,\n  stepCountIs,\n  tool as tool2\n} from \"ai\";\nimport { z as z2 } from \"zod\";\n\n// src/handoff.ts\nimport { tool } from \"ai\";\nimport { z } from \"zod\";\nfunction createHandoff(targetAgent, context, reason) {\n  const targetName = typeof targetAgent === \"string\" ? targetAgent : targetAgent.name;\n  return {\n    targetAgent: targetName,\n    context,\n    reason\n  };\n}\nfunction handoff(agent, config) {\n  return {\n    agent,\n    config\n  };\n}\nfunction getTransferMessage(agent) {\n  return JSON.stringify({ assistant: agent.name });\n}\nfunction createHandoffTool(availableHandoffs) {\n  const agentNames = availableHandoffs.map(\n    (h) => \"agent\" in h ? h.agent.name : h.name\n  );\n  return tool({\n    description: `Transfer the conversation to another specialized agent.\n    \nAvailable agents: ${agentNames.join(\", \")}`,\n    inputSchema: z.object({\n      targetAgent: z.enum(agentNames),\n      context: z.string().optional().describe(\"Context or summary to pass to the target agent\"),\n      reason: z.string().optional().describe(\"Reason for the handoff\")\n    }),\n    execute: async ({ targetAgent, context, reason }) => {\n      return createHandoff(targetAgent, context, reason);\n    }\n  });\n}\nvar HANDOFF_TOOL_NAME = \"handoff_to_agent\";\nfunction isHandoffTool(toolName) {\n  return toolName === HANDOFF_TOOL_NAME;\n}\nfunction isHandoffResult(result) {\n  return typeof result === \"object\" && result !== null && \"targetAgent\" in result && typeof result.targetAgent === \"string\";\n}\n\n// src/handoff-prompt.ts\nvar RECOMMENDED_PROMPT_PREFIX = `<system_context>\nYou are part of a multi-agent system called AI SDK Agents, designed to make agent coordination and execution easy. This system uses two primary abstractions: **Agents** and **Handoffs**. An agent encompasses instructions and tools and can hand off a conversation to another agent when appropriate. Handoffs are achieved by calling a handoff function, generally named \\`handoff_to_agent\\`. Transfers between agents are handled seamlessly in the background; do not mention or draw attention to these transfers in your conversation with the user.\n</system_context>\n\n<tool_calling_guidelines>\nWhen you need to call multiple tools, call them ALL at once using parallel tool calling.\n</tool_calling_guidelines>`;\nfunction promptWithHandoffInstructions(prompt) {\n  return `${RECOMMENDED_PROMPT_PREFIX}\n\n${prompt}`;\n}\n\n// src/run-context.ts\nvar AgentRunContext = class {\n  /**\n   * The context object passed to the agent workflow\n   */\n  context;\n  /**\n   * Additional metadata for the run\n   */\n  metadata;\n  constructor(context) {\n    this.context = context || {};\n    this.metadata = {};\n  }\n  /**\n   * Serialize the run context to JSON\n   */\n  toJSON() {\n    return {\n      context: this.context,\n      metadata: this.metadata\n    };\n  }\n};\n\n// src/streaming.ts\nfunction writeDataPart(writer, type, data, options) {\n  writer.write({\n    type,\n    data,\n    ...options\n  });\n}\nfunction writeAgentStatus(writer, status) {\n  writeDataPart(writer, \"data-agent-status\", status, { transient: true });\n}\nfunction writeRateLimit(writer, rateLimit) {\n  writeDataPart(writer, \"data-rate-limit\", rateLimit, { transient: true });\n}\nfunction writeSuggestions(writer, prompts) {\n  writeDataPart(writer, \"data-suggestions\", { prompts }, { transient: true });\n}\n\n// src/tool-result-extractor.ts\nvar logger = createLogger(\"TOOL_EXTRACTOR\");\nfunction createDefaultInputFilter() {\n  return (input) => {\n    logger.debug(`Processing input history with ${input.inputHistory.length} messages`, {\n      historyCount: input.inputHistory.length\n    });\n    logger.debug(`Processing newItems with ${input.newItems.length} items`, {\n      newItemsCount: input.newItems.length\n    });\n    const toolResults = {};\n    for (const item of input.newItems) {\n      logger.debug(`Processing newItem: ${typeof item}`, { itemType: typeof item });\n      if (item && typeof item === \"object\") {\n        if (\"toolName\" in item && \"result\" in item) {\n          const toolName = item.toolName;\n          const result = item.result;\n          if (toolName && result) {\n            toolResults[toolName] = result;\n            logger.debug(`Found tool result in newItems: ${toolName}`, { toolName });\n          }\n        }\n        if (\"content\" in item && Array.isArray(item.content)) {\n          const content = item.content;\n          for (const contentItem of content) {\n            if (contentItem.type === \"tool-result\" && contentItem.toolName && contentItem.result) {\n              toolResults[contentItem.toolName] = contentItem.result;\n              logger.debug(`Found nested tool result: ${contentItem.toolName}`, { toolName: contentItem.toolName });\n            }\n          }\n        }\n      }\n    }\n    logger.debug(\"Extracted tool results from newItems\", { tools: Object.keys(toolResults) });\n    if (Object.keys(toolResults).length > 0) {\n      const dataSummary = Object.entries(toolResults).map(([key, value]) => {\n        if (Array.isArray(value)) {\n          return `Available ${key} data: ${value.length} items found`;\n        }\n        if (typeof value === \"object\" && value !== null) {\n          return `Available ${key} data: ${JSON.stringify(value)}`;\n        }\n        return `Available ${key} data: ${value}`;\n      }).join(\"\\n\");\n      const dataMessage = {\n        role: \"system\",\n        content: `Available data from previous agent:\n${dataSummary}\n\n**IMPORTANT**: Only use this data if it's DIRECTLY relevant to the current user question. If the user is asking about something different, ignore this data and call the appropriate tools.`\n      };\n      const enhancedHistory = [...input.inputHistory];\n      if (enhancedHistory.length === 0) {\n        enhancedHistory.push({\n          role: \"user\",\n          content: \"Please help with the request using the available data.\"\n        });\n      }\n      enhancedHistory.push(dataMessage);\n      return {\n        ...input,\n        inputHistory: enhancedHistory\n      };\n    }\n    return input;\n  };\n}\n\n// src/utils.ts\nimport { isToolUIPart } from \"ai\";\nfunction extractTextFromMessage(message) {\n  if (!message?.content) return \"\";\n  const { content } = message;\n  if (typeof content === \"string\") return content;\n  if (Array.isArray(content)) {\n    return content.filter(\n      (part) => typeof part === \"object\" && part !== null && part.type === \"text\"\n    ).map((part) => part.text).join(\"\");\n  }\n  return \"\";\n}\nfunction stripMetadata(messages) {\n  return messages.map((msg) => ({\n    ...msg,\n    parts: msg.parts?.map((part) => {\n      const sanitizedPart = { ...part };\n      if (\"providerMetadata\" in sanitizedPart) {\n        sanitizedPart.providerMetadata = void 0;\n      }\n      if (isToolUIPart(sanitizedPart) && \"callProviderMetadata\" in sanitizedPart) {\n        sanitizedPart.callProviderMetadata = void 0;\n      }\n      return sanitizedPart;\n    })\n  }));\n}\n\n// src/agent.ts\nvar logger2 = createLogger(\"AGENT\");\nvar Agent = class _Agent {\n  name;\n  instructions;\n  matchOn;\n  onEvent;\n  inputGuardrails;\n  outputGuardrails;\n  permissions;\n  lastMessages;\n  memory;\n  model;\n  aiAgent;\n  handoffAgents;\n  configuredTools;\n  modelSettings;\n  // Cache for system prompt construction\n  _cachedSystemPrompt;\n  _cacheKey;\n  constructor(config) {\n    this.name = config.name;\n    this.instructions = config.instructions;\n    this.matchOn = config.matchOn;\n    this.onEvent = config.onEvent;\n    this.inputGuardrails = config.inputGuardrails;\n    this.outputGuardrails = config.outputGuardrails;\n    this.permissions = config.permissions;\n    this.lastMessages = config.lastMessages;\n    this.memory = config.memory;\n    this.model = config.model;\n    this.handoffAgents = config.handoffs || [];\n    this.modelSettings = config.modelSettings;\n    this.configuredTools = config.tools || {};\n    const { toolChoice, ...otherModelSettings } = config.modelSettings || {};\n    this.aiAgent = new AISDKAgent({\n      model: config.model,\n      system: \"\",\n      // Will be overridden per-request with resolved instructions\n      tools: {},\n      // Will be overridden per-request with resolved tools\n      stopWhen: stepCountIs(config.maxTurns || 10),\n      temperature: config.temperature,\n      toolChoice,\n      // Pass toolChoice as top-level param\n      ...otherModelSettings\n    });\n  }\n  async generate(options) {\n    const startTime = /* @__PURE__ */ new Date();\n    try {\n      const result = options.messages && options.messages.length > 0 ? await this.aiAgent.generate({\n        messages: [\n          ...options.messages,\n          { role: \"user\", content: options.prompt || \"Continue\" }\n        ]\n      }) : await this.aiAgent.generate({\n        prompt: options.prompt\n      });\n      const endTime = /* @__PURE__ */ new Date();\n      const handoffs = [];\n      if (result.steps) {\n        for (const step of result.steps) {\n          if (step.toolResults) {\n            for (const toolResult of step.toolResults) {\n              if (isHandoffResult(toolResult.output)) {\n                handoffs.push(toolResult.output);\n              }\n            }\n          }\n        }\n      }\n      return {\n        text: result.text || \"\",\n        finalAgent: this.name,\n        finalOutput: result.text || \"\",\n        handoffs,\n        metadata: {\n          startTime,\n          endTime,\n          duration: endTime.getTime() - startTime.getTime()\n        },\n        steps: result.steps,\n        finishReason: result.finishReason,\n        usage: result.usage,\n        toolCalls: result.toolCalls?.map((tc) => ({\n          toolCallId: tc.toolCallId,\n          toolName: tc.toolName,\n          args: \"args\" in tc ? tc.args : void 0\n        }))\n      };\n    } catch (error) {\n      throw new Error(\n        `Agent ${this.name} failed: ${error instanceof Error ? error.message : \"Unknown error\"}`\n      );\n    }\n  }\n  stream(options) {\n    logger2.debug(`${this.name} stream called`, { name: this.name });\n    const executionContext = options.executionContext;\n    const maxSteps = options.maxSteps;\n    const onStepFinish = options.onStepFinish;\n    const toolChoice = options.toolChoice;\n    const resolvedInstructions = typeof this.instructions === \"function\" ? this.instructions(executionContext) : this.instructions;\n    const extendedContext = executionContext;\n    const memoryAddition = extendedContext._memoryAddition || \"\";\n    const cacheKey = `${typeof this.instructions === \"string\" ? this.instructions : \"dynamic\"}_${this.handoffAgents.length}_${this.memory?.workingMemory?.enabled || false}`;\n    let systemPrompt;\n    if (this._cacheKey === cacheKey && this._cachedSystemPrompt && !memoryAddition) {\n      systemPrompt = this._cachedSystemPrompt;\n    } else {\n      let basePrompt = this.handoffAgents.length > 0 ? promptWithHandoffInstructions(resolvedInstructions) : resolvedInstructions;\n      if (this.memory?.workingMemory?.enabled) {\n        const workingMemoryInstructions = getWorkingMemoryInstructions(\n          this.memory.workingMemory.template || DEFAULT_TEMPLATE\n        );\n        basePrompt += `\n\n${workingMemoryInstructions}`;\n      }\n      if (typeof this.instructions === \"string\" && !memoryAddition) {\n        this._cachedSystemPrompt = basePrompt;\n        this._cacheKey = cacheKey;\n      }\n      systemPrompt = basePrompt + memoryAddition;\n    }\n    const resolvedTools = typeof this.configuredTools === \"function\" ? this.configuredTools(executionContext) : { ...this.configuredTools };\n    if (this.handoffAgents.length > 0) {\n      resolvedTools[HANDOFF_TOOL_NAME] = createHandoffTool(this.handoffAgents);\n    }\n    const hasOtherTools = Object.keys(resolvedTools).some(\n      (key) => key !== HANDOFF_TOOL_NAME\n    );\n    const isPureOrchestrator = this.handoffAgents.length > 0 && !hasOtherTools;\n    if (this.memory?.workingMemory?.enabled && !isPureOrchestrator) {\n      resolvedTools.updateWorkingMemory = this.createWorkingMemoryTool();\n    }\n    const { toolChoice: configuredToolChoice, ...otherSettings } = this.modelSettings || {};\n    const effectiveToolChoice = toolChoice ? { type: \"tool\", toolName: toolChoice } : configuredToolChoice;\n    const additionalOptions = {\n      system: systemPrompt,\n      // Override system prompt per call\n      tools: resolvedTools,\n      // Add resolved tools here\n      toolChoice: effectiveToolChoice,\n      // Pass toolChoice as top-level param\n      ...otherSettings\n      // Include other model settings\n    };\n    if (executionContext) {\n      additionalOptions.experimental_context = executionContext;\n    }\n    if (maxSteps) additionalOptions.maxSteps = maxSteps;\n    if (onStepFinish) additionalOptions.onStepFinish = onStepFinish;\n    if (\"messages\" in options && !(\"prompt\" in options) && options.messages) {\n      logger2.debug(`Stream with messages only`, {\n        messageCount: options.messages.length\n      });\n      return this.aiAgent.stream({\n        messages: options.messages,\n        ...additionalOptions\n      });\n    }\n    const opts = options;\n    logger2.debug(`Stream options for ${this.name}`, {\n      hasPrompt: !!opts.prompt,\n      messageCount: opts.messages?.length || 0\n    });\n    if (!opts.prompt && (!opts.messages || opts.messages.length === 0)) {\n      throw new Error(\"No prompt or messages provided to stream method\");\n    }\n    if (opts.messages && opts.messages.length > 0 && opts.prompt) {\n      return this.aiAgent.stream({\n        messages: [...opts.messages, { role: \"user\", content: opts.prompt }],\n        ...additionalOptions\n      });\n    }\n    if (opts.prompt) {\n      return this.aiAgent.stream({\n        prompt: opts.prompt,\n        ...additionalOptions\n      });\n    }\n    throw new Error(\"No valid options provided to stream method\");\n  }\n  getHandoffs() {\n    return this.handoffAgents.map((h) => \"agent\" in h ? h.agent : h);\n  }\n  getConfiguredHandoffs() {\n    return this.handoffAgents.map((h) => \"agent\" in h ? h : { agent: h });\n  }\n  /**\n   * Convert agent execution to UI Message Stream Response\n   * High-level API for Next.js route handlers\n   *\n   * This follows the working pattern from the route.ts reference code\n   */\n  toUIMessageStream(options) {\n    const {\n      message,\n      strategy = \"auto\",\n      maxRounds = 5,\n      maxSteps = 10,\n      context,\n      agentChoice,\n      toolChoice,\n      beforeStream,\n      onEvent,\n      // AI SDK createUIMessageStream options\n      onFinish,\n      onError,\n      generateId,\n      // AI SDK toUIMessageStream options\n      sendReasoning,\n      sendSources,\n      sendFinish,\n      sendStart,\n      messageMetadata,\n      // Response options\n      status,\n      statusText,\n      headers\n    } = options;\n    let existingChatForSave = null;\n    const wrappedOnFinish = async (event) => {\n      if (this.memory?.history?.enabled && context) {\n        const { chatId, userId } = this.extractMemoryIdentifiers(\n          context\n        );\n        if (!chatId) {\n          logger2.warn(\"Cannot save messages: chatId is missing from context\");\n        } else {\n          try {\n            const userMsg = event.messages[event.messages.length - 2];\n            const assistantMsg = event.messages[event.messages.length - 1];\n            let userMsgToSave = userMsg;\n            if (userMsg && Array.isArray(userMsg.content)) {\n              const filteredContent = userMsg.content.filter(\n                (part) => part.type !== \"file\"\n              );\n              userMsgToSave = {\n                ...userMsg,\n                content: filteredContent.length > 0 ? filteredContent : \"\"\n              };\n            }\n            logger2.debug(`Saving messages (files excluded from storage)`);\n            await this.saveConversation(\n              chatId,\n              userId,\n              JSON.stringify(userMsgToSave),\n              JSON.stringify(assistantMsg),\n              existingChatForSave\n            );\n          } catch (err) {\n            logger2.error(\"Failed to save conversation\", { error: err });\n          }\n        }\n      }\n      await onFinish?.(event);\n    };\n    const stream = createUIMessageStream({\n      originalMessages: [message],\n      onFinish: wrappedOnFinish,\n      onError,\n      generateId,\n      execute: async ({ writer }) => {\n        const [messages, memoryAddition] = await Promise.all([\n          this.loadMessagesWithHistory(message, context),\n          context && this.memory?.workingMemory?.enabled ? this.loadWorkingMemory(context) : Promise.resolve(\"\")\n        ]);\n        const { chatId } = this.extractMemoryIdentifiers(context);\n        if (this.memory?.chats?.enabled && chatId) {\n          existingChatForSave = await this.memory.provider?.getChat?.(chatId);\n        }\n        const lastMessage = messages[messages.length - 1];\n        const input = extractTextFromMessage(lastMessage);\n        await this.maybeGenerateChatTitle(\n          context,\n          input,\n          writer,\n          existingChatForSave\n        );\n        const runContext = new AgentRunContext(context || {});\n        runContext.metadata = {\n          agent: this.name,\n          requestId: `req_${Date.now()}_${Math.random().toString(36).substring(7)}`\n        };\n        const executionContext = createExecutionContext({\n          context: context || {},\n          writer,\n          metadata: {\n            agent: this.name,\n            requestId: runContext.metadata.requestId\n          }\n        });\n        executionContext.runContext = runContext;\n        if (memoryAddition) {\n          const extendedExecContext = executionContext;\n          extendedExecContext._memoryAddition = memoryAddition;\n        }\n        try {\n          if (beforeStream) {\n            const shouldContinue = await beforeStream({ writer });\n            if (shouldContinue === false) {\n              writer.write({ type: \"finish\" });\n              return;\n            }\n          }\n          const conversationMessages = [...messages];\n          const specialists = this.getHandoffs();\n          writeAgentStatus(writer, {\n            status: \"routing\",\n            agent: this.name\n          });\n          if (onEvent) {\n            await onEvent({\n              type: \"agent-start\",\n              agent: this.name,\n              round: 0\n            });\n          }\n          let currentAgent = this;\n          if (agentChoice && specialists.length > 0) {\n            const chosenAgent = specialists.find(\n              (agent) => agent.name === agentChoice\n            );\n            if (chosenAgent) {\n              currentAgent = chosenAgent;\n              logger2.debug(`Explicit agent choice: ${currentAgent.name}`, {\n                agent: currentAgent.name\n              });\n              writeAgentStatus(writer, {\n                status: \"completing\",\n                agent: this.name\n              });\n              if (onEvent) {\n                await onEvent({\n                  type: \"agent-finish\",\n                  agent: this.name,\n                  round: 0\n                });\n              }\n              writer.write({\n                type: \"data-agent-handoff\",\n                data: {\n                  from: this.name,\n                  to: chosenAgent.name,\n                  reason: \"User selected agent\",\n                  routingStrategy: \"explicit\"\n                },\n                transient: true\n              });\n              if (onEvent) {\n                await onEvent({\n                  type: \"agent-handoff\",\n                  from: this.name,\n                  to: chosenAgent.name,\n                  reason: \"User selected agent\"\n                });\n              }\n            }\n          } else if (toolChoice && specialists.length > 0) {\n            const agentWithTool = specialists.find((agent) => {\n              const agentImpl = agent;\n              return agentImpl.configuredTools && toolChoice in agentImpl.configuredTools;\n            });\n            if (agentWithTool) {\n              currentAgent = agentWithTool;\n              logger2.debug(\n                `Tool choice routing: ${toolChoice} \\u2192 ${currentAgent.name}`,\n                { toolChoice, agent: currentAgent.name }\n              );\n              writeAgentStatus(writer, {\n                status: \"completing\",\n                agent: this.name\n              });\n              if (onEvent) {\n                await onEvent({\n                  type: \"agent-finish\",\n                  agent: this.name,\n                  round: 0\n                });\n              }\n              writer.write({\n                type: \"data-agent-handoff\",\n                data: {\n                  from: this.name,\n                  to: agentWithTool.name,\n                  reason: `User requested tool: ${toolChoice}`,\n                  routingStrategy: \"tool-choice\",\n                  preferredTool: toolChoice\n                },\n                transient: true\n              });\n              if (onEvent) {\n                await onEvent({\n                  type: \"agent-handoff\",\n                  from: this.name,\n                  to: agentWithTool.name,\n                  reason: `User requested tool: ${toolChoice}`\n                });\n              }\n            }\n          } else if (strategy === \"auto\" && specialists.length > 0) {\n            const matchedAgent = specialists.find((agent) => {\n              if (!agent.matchOn) return false;\n              if (typeof agent.matchOn === \"function\") {\n                return agent.matchOn(input);\n              }\n              if (Array.isArray(agent.matchOn)) {\n                return agent.matchOn.some((pattern) => {\n                  if (typeof pattern === \"string\") {\n                    return input.toLowerCase().includes(pattern.toLowerCase());\n                  }\n                  if (pattern instanceof RegExp) {\n                    return pattern.test(input);\n                  }\n                  return false;\n                });\n              }\n              return false;\n            });\n            if (matchedAgent) {\n              currentAgent = matchedAgent;\n              logger2.debug(`Programmatic match: ${currentAgent.name}`, {\n                agent: currentAgent.name\n              });\n              writeAgentStatus(writer, {\n                status: \"completing\",\n                agent: this.name\n              });\n              if (onEvent) {\n                await onEvent({\n                  type: \"agent-finish\",\n                  agent: this.name,\n                  round: 0\n                });\n              }\n              writer.write({\n                type: \"data-agent-handoff\",\n                data: {\n                  from: this.name,\n                  to: matchedAgent.name,\n                  reason: \"Programmatic routing match\",\n                  routingStrategy: \"programmatic\"\n                },\n                transient: true\n              });\n              if (onEvent) {\n                await onEvent({\n                  type: \"agent-handoff\",\n                  from: this.name,\n                  to: matchedAgent.name,\n                  reason: \"Programmatic routing match\"\n                });\n              }\n            }\n          }\n          let round = 0;\n          const usedSpecialists = /* @__PURE__ */ new Set();\n          if (currentAgent !== this) {\n            usedSpecialists.add(currentAgent.name);\n          }\n          while (round++ < maxRounds) {\n            writeAgentStatus(writer, {\n              status: \"executing\",\n              agent: currentAgent.name\n            });\n            const defaultLastMessages = currentAgent.getHandoffs().length > 0 ? 10 : 5;\n            const lastMessages = currentAgent.lastMessages ?? defaultLastMessages;\n            let messagesToSend = conversationMessages.slice(-lastMessages);\n            if (messagesToSend.length === 0 && messages.length > 0) {\n              messagesToSend = messages.slice(-1);\n            }\n            if (onEvent) {\n              await onEvent({\n                type: \"agent-start\",\n                agent: currentAgent.name,\n                round\n              });\n            }\n            const result = currentAgent.stream({\n              messages: messagesToSend,\n              executionContext,\n              maxSteps,\n              // Limit tool calls per round\n              onStepFinish: async (step) => {\n                if (onEvent) {\n                  await onEvent({\n                    type: \"agent-step\",\n                    agent: currentAgent.name,\n                    step\n                  });\n                }\n              }\n            });\n            const uiStream = result.toUIMessageStream({\n              sendReasoning,\n              sendSources,\n              sendFinish,\n              sendStart,\n              messageMetadata\n            });\n            let textAccumulated = \"\";\n            let handoffData = null;\n            const toolCallNames = /* @__PURE__ */ new Map();\n            const toolResults = /* @__PURE__ */ new Map();\n            let hasStartedContent = false;\n            const handoffToolNames = /* @__PURE__ */ new Set([HANDOFF_TOOL_NAME]);\n            for await (const chunk of uiStream) {\n              if (!chunk) {\n                logger2.warn(\"Received null/undefined chunk from uiStream\");\n                continue;\n              }\n              if (chunk.type === \"tool-input-start\") {\n                toolCallNames.set(chunk.toolCallId, chunk.toolName);\n                logger2.debug(\n                  `Tool call started: ${chunk.toolName} (${chunk.toolCallId})`,\n                  {\n                    toolName: chunk.toolName,\n                    toolCallId: chunk.toolCallId,\n                    agent: currentAgent.name,\n                    round\n                  }\n                );\n              }\n              let isHandoffChunk = false;\n              if (chunk.type === \"tool-input-start\") {\n                isHandoffChunk = handoffToolNames.has(chunk.toolName);\n              } else if (chunk.type === \"tool-input-delta\" || chunk.type === \"tool-input-available\") {\n                const toolName = toolCallNames.get(chunk.toolCallId);\n                isHandoffChunk = toolName ? handoffToolNames.has(toolName) : false;\n              } else if (chunk.type === \"tool-output-available\") {\n                const toolName = toolCallNames.get(chunk.toolCallId);\n                isHandoffChunk = toolName ? handoffToolNames.has(toolName) : false;\n              }\n              if (!hasStartedContent && (chunk.type === \"text-delta\" || chunk.type === \"tool-input-start\" && !isHandoffChunk)) {\n                hasStartedContent = true;\n              }\n              if (chunk.type === \"error\") {\n                logger2.error(\"Stream error\", {\n                  error: chunk.errorText || chunk.error || chunk\n                });\n              }\n              if (chunk.type === \"tool-output-available\") {\n                const toolName = toolCallNames.get(chunk.toolCallId);\n                if (toolName) {\n                  toolResults.set(toolName, chunk.output);\n                  logger2.debug(`Captured ${toolName}`, {\n                    toolName,\n                    outputType: typeof chunk.output\n                  });\n                  if (handoffToolNames.has(toolName)) {\n                    handoffData = chunk.output;\n                    logger2.debug(\"Handoff detected\", handoffData);\n                  }\n                }\n              }\n              if (!isHandoffChunk) {\n                try {\n                  writer.write(chunk);\n                } catch (error) {\n                  logger2.error(\"Failed to write chunk to stream\", {\n                    chunkType: chunk.type,\n                    error\n                  });\n                }\n              }\n              if (chunk.type === \"text-delta\") {\n                textAccumulated += chunk.delta;\n              }\n            }\n            if (textAccumulated && !handoffData) {\n              conversationMessages.push({\n                role: \"assistant\",\n                content: textAccumulated\n              });\n            } else if (textAccumulated && handoffData) {\n              logger2.debug(\"Skipping intermediate text due to handoff\", {\n                textLength: textAccumulated.length,\n                handoffTarget: handoffData.targetAgent\n              });\n            }\n            if (onEvent) {\n              await onEvent({\n                type: \"agent-finish\",\n                agent: currentAgent.name,\n                round\n              });\n            }\n            if (currentAgent === this) {\n              if (handoffData) {\n                if (usedSpecialists.has(handoffData.targetAgent)) {\n                  break;\n                }\n                writeAgentStatus(writer, {\n                  status: \"routing\",\n                  agent: this.name\n                });\n                usedSpecialists.add(handoffData.targetAgent);\n                const nextAgent = specialists.find(\n                  (a) => a.name === handoffData.targetAgent\n                );\n                if (nextAgent) {\n                  const configuredHandoffs = this.getConfiguredHandoffs();\n                  const configuredHandoff = configuredHandoffs.find(\n                    (ch) => ch.agent.name === handoffData.targetAgent\n                  );\n                  const inputFilter = configuredHandoff?.config?.inputFilter;\n                  if (inputFilter) {\n                    try {\n                      const handoffInputData = {\n                        inputHistory: conversationMessages,\n                        preHandoffItems: [],\n                        newItems: Array.from(toolResults.entries()).map(\n                          ([name, result2]) => ({\n                            toolName: name,\n                            result: result2\n                          })\n                        ),\n                        runContext\n                      };\n                      const filteredData = inputFilter(handoffInputData);\n                      conversationMessages.length = 0;\n                      conversationMessages.push(...filteredData.inputHistory);\n                    } catch (error) {\n                      logger2.error(\"Error applying handoff input filter\", {\n                        error\n                      });\n                    }\n                  } else {\n                    logger2.debug(\"Applying default input filter for\", {\n                      targetAgent: handoffData.targetAgent\n                    });\n                    const defaultFilter = createDefaultInputFilter();\n                    const handoffInputData = {\n                      inputHistory: conversationMessages,\n                      preHandoffItems: [],\n                      newItems: Array.from(toolResults.entries()).map(\n                        ([name, result2]) => ({\n                          toolName: name,\n                          result: result2\n                        })\n                      ),\n                      runContext\n                    };\n                    logger2.debug(\"Input history length\", {\n                      length: handoffInputData.inputHistory.length\n                    });\n                    logger2.debug(\"Input history messages\", {\n                      messages: handoffInputData.inputHistory.map((m) => ({\n                        role: m.role,\n                        contentType: typeof m.content\n                      }))\n                    });\n                    const filteredData = defaultFilter(handoffInputData);\n                    logger2.debug(\"Filtered history length\", {\n                      length: filteredData.inputHistory.length\n                    });\n                    conversationMessages.length = 0;\n                    conversationMessages.push(...filteredData.inputHistory);\n                    logger2.debug(\"Updated conversation messages length\", {\n                      length: conversationMessages.length\n                    });\n                  }\n                  if (configuredHandoff?.config?.onHandoff) {\n                    try {\n                      await configuredHandoff.config.onHandoff(runContext);\n                    } catch (error) {\n                      logger2.error(\"Error in onHandoff callback\", { error });\n                    }\n                  }\n                  currentAgent = nextAgent;\n                  writer.write({\n                    type: \"data-agent-handoff\",\n                    data: {\n                      from: this.name,\n                      to: nextAgent.name,\n                      reason: handoffData.reason,\n                      routingStrategy: \"llm\"\n                    },\n                    transient: true\n                  });\n                  if (onEvent) {\n                    await onEvent({\n                      type: \"agent-handoff\",\n                      from: this.name,\n                      to: nextAgent.name,\n                      reason: handoffData.reason\n                    });\n                  }\n                }\n              } else {\n                break;\n              }\n            } else {\n              if (handoffData) {\n                if (usedSpecialists.has(handoffData.targetAgent)) {\n                  break;\n                }\n                usedSpecialists.add(handoffData.targetAgent);\n                const nextAgent = specialists.find(\n                  (a) => a.name === handoffData.targetAgent\n                );\n                if (nextAgent) {\n                  const configuredHandoffs = this.getConfiguredHandoffs();\n                  const configuredHandoff = configuredHandoffs.find(\n                    (ch) => ch.agent.name === handoffData.targetAgent\n                  );\n                  if (configuredHandoff?.config?.inputFilter) {\n                    try {\n                      const handoffInputData = {\n                        inputHistory: conversationMessages.slice(0, -1),\n                        // All messages except the last assistant message\n                        preHandoffItems: [],\n                        // No pre-handoff items for specialist-to-specialist\n                        newItems: conversationMessages.slice(-1),\n                        // The last assistant message\n                        runContext\n                      };\n                      const filteredData = configuredHandoff.config.inputFilter(handoffInputData);\n                      conversationMessages.length = 0;\n                      conversationMessages.push(\n                        ...filteredData.inputHistory,\n                        ...filteredData.newItems\n                      );\n                    } catch (error) {\n                      logger2.error(\"Error applying handoff input filter\", {\n                        error\n                      });\n                    }\n                  }\n                  if (configuredHandoff?.config?.onHandoff) {\n                    try {\n                      await configuredHandoff.config.onHandoff(runContext);\n                    } catch (error) {\n                      logger2.error(\"Error in onHandoff callback\", { error });\n                    }\n                  }\n                  const previousAgent = currentAgent;\n                  currentAgent = nextAgent;\n                  writer.write({\n                    type: \"data-agent-handoff\",\n                    data: {\n                      from: previousAgent.name,\n                      to: nextAgent.name,\n                      reason: handoffData.reason,\n                      routingStrategy: \"llm\"\n                    },\n                    transient: true\n                  });\n                  if (onEvent) {\n                    await onEvent({\n                      type: \"agent-handoff\",\n                      from: previousAgent.name,\n                      to: nextAgent.name,\n                      reason: handoffData.reason\n                    });\n                  }\n                }\n              } else {\n                break;\n              }\n            }\n          }\n          if (onEvent) {\n            await onEvent({\n              type: \"agent-complete\",\n              totalRounds: round\n            });\n          }\n          const config = this.memory?.chats?.generateSuggestions;\n          const minLength = typeof config === \"object\" && config.minResponseLength ? config.minResponseLength : 100;\n          const assistantMessages = conversationMessages.filter(\n            (m) => m.role === \"assistant\"\n          );\n          const totalTextLength = assistantMessages.reduce((sum, m) => {\n            return sum + (typeof m.content === \"string\" ? m.content.length : 0);\n          }, 0);\n          if (totalTextLength >= minLength) {\n            const contextWindow = typeof config === \"object\" && config.contextWindow ? config.contextWindow : 1;\n            const recentMessages = conversationMessages.slice(\n              -(contextWindow * 2)\n            );\n            const conversationContext = recentMessages.map((msg) => {\n              const role = msg.role === \"user\" ? \"User\" : \"Assistant\";\n              return `${role}: ${typeof msg.content === \"string\" ? msg.content : JSON.stringify(msg.content)}`;\n            }).join(\"\\n\\n\");\n            await this.generateSuggestions(\n              conversationContext,\n              conversationMessages,\n              writer,\n              context\n            ).catch(\n              (err) => logger2.error(\"Suggestion generation error\", { error: err })\n            );\n          }\n          writer.write({ type: \"finish\" });\n        } catch (error) {\n          logger2.error(\"Error in toUIMessageStream\", { error });\n          if (onEvent) {\n            await onEvent({\n              type: \"agent-error\",\n              error: error instanceof Error ? error : new Error(String(error))\n            });\n          }\n          writer.write({\n            type: \"error\",\n            error: error instanceof Error ? error.message : String(error)\n          });\n          writer.write({ type: \"finish\" });\n        }\n      }\n    });\n    const response = createUIMessageStreamResponse({\n      stream,\n      status,\n      statusText,\n      headers\n    });\n    return response;\n  }\n  /**\n   * Extract chatId and userId from context for memory operations\n   */\n  extractMemoryIdentifiers(context) {\n    const ctx = context;\n    const chatId = ctx.chatId || ctx.metadata?.chatId;\n    const userId = ctx.userId || ctx.metadata?.userId;\n    return { chatId, userId };\n  }\n  /**\n   * Generate a title for the chat based on the first user message\n   */\n  async generateChatTitle(chatId, userMessage, writer, _context) {\n    if (!this.memory?.chats?.generateTitle) return;\n    const config = this.memory.chats.generateTitle;\n    const model = typeof config === \"object\" ? config.model : this.model;\n    const instructions = typeof config === \"object\" && config.instructions ? config.instructions : `<task_context>\nYou are a helpful assistant that can generate titles for conversations.\n</task_context>\n\n<rules>\nFind the most concise title that captures what the user is asking for.\nTitles should be at most 30 characters.\nTitles should be formatted in sentence case, with capital letters at the start of each word. Do not provide a period at the end.\n</rules>\n\n<task>\nGenerate a title for the conversation.\n</task>\n\n<output_format>\nReturn only the title.\n</output_format>`;\n    try {\n      const { text } = await generateText({\n        model,\n        system: instructions,\n        prompt: userMessage,\n        temperature: 0\n      });\n      await this.memory.provider?.updateChatTitle?.(chatId, text);\n      writer.write({\n        type: \"data-chat-title\",\n        data: { chatId, title: text }\n      });\n      logger2.debug(`Generated title for ${chatId}`, { chatId, title: text });\n    } catch (err) {\n      logger2.error(\"Title generation failed\", { error: err });\n    }\n  }\n  /**\n   * Build capabilities description from available tools and agents\n   */\n  buildCapabilitiesDescription(context) {\n    const capabilities = [];\n    if (this.configuredTools) {\n      const resolvedTools = typeof this.configuredTools === \"function\" && context ? this.configuredTools(context) : typeof this.configuredTools === \"object\" ? this.configuredTools : {};\n      const toolNames = Object.keys(resolvedTools).filter(\n        (name) => name !== \"handoff_to_agent\" && name !== \"updateWorkingMemory\"\n      );\n      if (toolNames.length > 0) {\n        capabilities.push(\"Available tools:\");\n        for (const toolName of toolNames) {\n          const tool3 = resolvedTools[toolName];\n          const description = tool3?.spec?.description || toolName;\n          capabilities.push(`- ${toolName}: ${description}`);\n        }\n      }\n    }\n    const handoffs = this.getHandoffs();\n    if (handoffs.length > 0) {\n      if (capabilities.length > 0) capabilities.push(\"\");\n      capabilities.push(\"Can route to specialist agents:\");\n      for (const agent of handoffs) {\n        const description = agent.handoffDescription || `${agent.name} agent`;\n        capabilities.push(`- ${agent.name}: ${description}`);\n      }\n    }\n    return capabilities.join(\"\\n\");\n  }\n  /**\n   * Generate contextual prompt suggestions after agent response\n   */\n  async generateSuggestions(conversationContext, conversationMessages, writer, context) {\n    const config = this.memory?.chats?.generateSuggestions;\n    if (!config) return;\n    let enabled;\n    if (typeof config === \"boolean\") {\n      enabled = config;\n    } else if (typeof config.enabled === \"function\") {\n      enabled = await config.enabled({\n        messages: conversationMessages,\n        context\n      });\n    } else {\n      enabled = config.enabled;\n    }\n    if (!enabled) return;\n    const model = typeof config === \"object\" && config.model ? config.model : this.model;\n    const limit = typeof config === \"object\" && config.limit ? config.limit : 5;\n    const defaultInstructions = `Generate ${limit} contextual follow-up suggestions based on what was JUST discussed.\n\n${this.buildCapabilitiesDescription(context)}\n\nGuidelines:\n1. Analyze what the assistant just showed/discussed (data, analysis, insights)\n2. Suggest logical NEXT STEPS that build on this specific response\n3. Keep suggestions ultra-brief (2-3 words ideal, max 5 words)\n4. Use action verbs (\"Show\", \"Compare\", \"Analyze\", \"Check\", \"List\", \"Explore\")\n5. Make suggestions specific to the context, not generic\n6. Focus on available capabilities that provide value\n\nGood suggestions are:\n- Specific to what was just discussed\n- Actionable using available capabilities\n- Brief and clear (2-3 words)\n- Natural next steps, not repetitive`;\n    const instructions = typeof config === \"object\" && config.instructions ? config.instructions : defaultInstructions;\n    try {\n      const suggestionsSchema = z2.object({\n        prompts: z2.array(z2.string().max(40)).min(3).max(limit).describe(`Array of prompt suggestions (2-5 words each)`)\n      });\n      const { object } = await generateObject({\n        model,\n        system: instructions,\n        prompt: conversationContext,\n        schema: suggestionsSchema,\n        mode: \"json\"\n      });\n      const { prompts } = object;\n      writeSuggestions(writer, prompts);\n    } catch (err) {\n      logger2.error(\"Suggestion generation failed\", { error: err });\n    }\n  }\n  /**\n   * Create the updateWorkingMemory tool\n   */\n  createWorkingMemoryTool() {\n    const scope = this.memory?.workingMemory?.scope || \"chat\";\n    const memory = this.memory;\n    const extractMemoryIdentifiers = this.extractMemoryIdentifiers.bind(this);\n    return tool2({\n      description: `Save user information to persistent memory for future conversations.`,\n      inputSchema: z2.object({\n        content: z2.string().describe(\n          \"Updated working memory content in markdown format. Include user preferences and any important facts to remember.\"\n        )\n      }),\n      execute: async ({ content }, options) => {\n        logger2.debug(\"updateWorkingMemory tool called\", {\n          contentLength: content.length\n        });\n        if (!memory?.provider) {\n          logger2.warn(\"Memory provider not configured\");\n          return \"Memory system not configured\";\n        }\n        const { getContext: getContext2 } = await Promise.resolve().then(() => (init_context(), context_exports));\n        const ctx = getContext2(\n          options\n        );\n        const contextData = ctx;\n        if (!contextData) {\n          logger2.warn(\"Context not available for working memory update\");\n          return \"Context not available\";\n        }\n        const { chatId, userId } = extractMemoryIdentifiers(contextData);\n        logger2.debug(\"Updating working memory\", { chatId, userId, scope });\n        try {\n          await memory.provider.updateWorkingMemory({\n            chatId,\n            userId,\n            scope,\n            content\n          });\n          logger2.debug(\"Working memory updated successfully\");\n          return \"success\";\n        } catch (error) {\n          logger2.error(\"Failed to update working memory\", {\n            error: error instanceof Error ? error.message : error\n          });\n          return \"error\";\n        }\n      }\n    });\n  }\n  /**\n   * Load working memory and inject into system prompt\n   */\n  async loadWorkingMemory(context) {\n    if (!this.memory?.workingMemory?.enabled || !this.memory?.provider) {\n      return \"\";\n    }\n    const { chatId, userId } = this.extractMemoryIdentifiers(context);\n    const scope = this.memory.workingMemory.scope;\n    try {\n      const memory = await this.memory.provider.getWorkingMemory({\n        chatId,\n        userId,\n        scope\n      });\n      if (!memory) return \"\";\n      return formatWorkingMemory(memory);\n    } catch (error) {\n      logger2.error(\"Failed to load working memory\", {\n        error: error instanceof Error ? error.message : error\n      });\n      return \"\";\n    }\n  }\n  /**\n   * Load message history from memory and prepend to the current message.\n   * Falls back to just the current message if history is disabled or unavailable.\n   *\n   * @param message - The current user message\n   * @param context - Execution context containing chatId\n   * @returns Array of ModelMessages including history + current message\n   */\n  async loadMessagesWithHistory(message, context) {\n    if (!this.memory?.history?.enabled || !context) {\n      logger2.debug(\n        \"History disabled or no context - using single message only\"\n      );\n      return convertToModelMessages([message]);\n    }\n    const { chatId } = this.extractMemoryIdentifiers(context);\n    if (!chatId) {\n      logger2.warn(\"Cannot load history: chatId missing from context\");\n      return convertToModelMessages([message]);\n    }\n    if (!this.memory.provider) {\n      logger2.warn(\"No memory provider configured - using single message only\");\n      return convertToModelMessages([message]);\n    }\n    try {\n      const previousMessages = await this.memory.provider.getMessages?.({\n        chatId,\n        limit: this.memory.history.limit\n      }) || [];\n      logger2.debug(`Loading history for chatId=${chatId}`, {\n        chatId,\n        count: previousMessages.length\n      });\n      if (previousMessages.length === 0) {\n        logger2.debug(\"No previous messages found - starting new conversation\");\n        return convertToModelMessages([message]);\n      }\n      const historyMessages = convertToModelMessages(\n        stripMetadata(previousMessages)\n      );\n      logger2.debug(\n        `Loaded ${historyMessages.length} history messages for context`,\n        {\n          count: historyMessages.length\n        }\n      );\n      return [...historyMessages, ...convertToModelMessages([message])];\n    } catch (err) {\n      logger2.error(`Load history failed for chatId=${chatId}`, {\n        chatId,\n        error: err\n      });\n      return convertToModelMessages([message]);\n    }\n  }\n  /**\n   * Save user and assistant messages, then update chat session.\n   * Messages are saved in parallel for better performance.\n   *\n   * @param chatId - The chat identifier\n   * @param userId - Optional user identifier\n   * @param userMessage - The user's message text\n   * @param assistantMessage - The assistant's response text\n   * @param existingChat - Pre-loaded chat object to avoid duplicate queries\n   */\n  async saveConversation(chatId, userId, userMessage, assistantMessage, existingChat) {\n    if (!this.memory?.provider || !this.memory?.history?.enabled) return;\n    logger2.debug(`Saving conversation for chatId=${chatId}`, {\n      chatId,\n      userLength: userMessage.length,\n      assistantLength: assistantMessage.length\n    });\n    try {\n      const savePromises = [\n        this.memory.provider.saveMessage?.({\n          chatId,\n          userId,\n          role: \"user\",\n          content: userMessage,\n          timestamp: /* @__PURE__ */ new Date()\n        })\n      ];\n      if (assistantMessage && assistantMessage.length > 0) {\n        logger2.debug(`Will save assistant message`, {\n          length: assistantMessage.length\n        });\n        savePromises.push(\n          this.memory.provider.saveMessage?.({\n            chatId,\n            userId,\n            role: \"assistant\",\n            content: assistantMessage,\n            timestamp: /* @__PURE__ */ new Date()\n          })\n        );\n      } else {\n        logger2.warn(`Skipping assistant message save - empty or undefined`);\n      }\n      if (this.memory?.chats?.enabled) {\n        const messageCount = savePromises.length;\n        savePromises.push(\n          this.memory.provider.saveChat?.({\n            ...existingChat || { chatId, userId, createdAt: /* @__PURE__ */ new Date() },\n            messageCount: (existingChat?.messageCount || 0) + messageCount,\n            updatedAt: /* @__PURE__ */ new Date()\n          })\n        );\n      }\n      await Promise.all(savePromises);\n      logger2.debug(`Successfully saved ${savePromises.length} items`, {\n        chatId,\n        count: savePromises.length\n      });\n    } catch (error) {\n      logger2.error(`Failed to save messages for chatId=${chatId}`, {\n        chatId,\n        error\n      });\n      throw error;\n    }\n  }\n  /**\n   * Generate a chat title if this is the first message.\n   * Runs asynchronously without blocking the response.\n   *\n   * @param context - Execution context containing chatId\n   * @param userMessage - The user's message to generate title from\n   * @param writer - Stream writer for sending title update\n   * @param existingChat - Pre-loaded chat object to avoid duplicate queries\n   */\n  async maybeGenerateChatTitle(context, userMessage, writer, existingChat) {\n    if (!this.memory?.chats?.enabled || !this.memory?.chats?.generateTitle || !context) {\n      return;\n    }\n    const { chatId } = this.extractMemoryIdentifiers(context);\n    if (!chatId) {\n      logger2.warn(\"Cannot generate title: chatId missing from context\");\n      return;\n    }\n    const isFirstMessage = !existingChat || existingChat.messageCount === 0;\n    if (isFirstMessage) {\n      this.generateChatTitle(chatId, userMessage, writer, context).catch(\n        (err) => logger2.error(\"Title generation error\", { error: err })\n      );\n    }\n  }\n  static create(config) {\n    return new _Agent(config);\n  }\n};\n\n// src/index.ts\ninit_context();\n\n// src/guardrails.ts\nvar AgentsError = class extends Error {\n  constructor(message, state) {\n    super(message);\n    this.state = state;\n    this.name = \"AgentsError\";\n  }\n};\nvar InputGuardrailTripwireTriggered = class extends AgentsError {\n  constructor(guardrailName, outputInfo, state) {\n    super(`Input guardrail tripwire triggered: ${guardrailName}`, state);\n    this.guardrailName = guardrailName;\n    this.outputInfo = outputInfo;\n    this.name = \"InputGuardrailTripwireTriggered\";\n  }\n};\nvar OutputGuardrailTripwireTriggered = class extends AgentsError {\n  constructor(guardrailName, outputInfo, state) {\n    super(`Output guardrail tripwire triggered: ${guardrailName}`, state);\n    this.guardrailName = guardrailName;\n    this.outputInfo = outputInfo;\n    this.name = \"OutputGuardrailTripwireTriggered\";\n  }\n};\nvar GuardrailExecutionError = class extends AgentsError {\n  constructor(guardrailName, originalError, state) {\n    super(\n      `Guardrail execution failed: ${guardrailName} - ${originalError.message}`,\n      state\n    );\n    this.guardrailName = guardrailName;\n    this.originalError = originalError;\n    this.name = \"GuardrailExecutionError\";\n  }\n};\nvar MaxTurnsExceededError = class extends AgentsError {\n  constructor(currentTurns, maxTurns, state) {\n    super(`Maximum turns exceeded: ${currentTurns}/${maxTurns}`, state);\n    this.currentTurns = currentTurns;\n    this.maxTurns = maxTurns;\n    this.name = \"MaxTurnsExceededError\";\n  }\n};\nvar ToolCallError = class extends AgentsError {\n  constructor(toolName, originalError, state) {\n    super(`Tool call failed: ${toolName} - ${originalError.message}`, state);\n    this.toolName = toolName;\n    this.originalError = originalError;\n    this.name = \"ToolCallError\";\n  }\n};\nvar ToolPermissionDeniedError = class extends AgentsError {\n  constructor(toolName, reason, state) {\n    super(`Tool permission denied: ${toolName} - ${reason}`, state);\n    this.toolName = toolName;\n    this.reason = reason;\n    this.name = \"ToolPermissionDeniedError\";\n  }\n};\nasync function runInputGuardrails(guardrails, input, context) {\n  if (!guardrails || guardrails.length === 0) return;\n  const results = await Promise.allSettled(\n    guardrails.map(async (guardrail) => {\n      try {\n        const result = await guardrail.execute({ input, context });\n        if (result.tripwireTriggered) {\n          throw new InputGuardrailTripwireTriggered(\n            guardrail.name,\n            result.outputInfo\n          );\n        }\n        return result;\n      } catch (error) {\n        if (error instanceof InputGuardrailTripwireTriggered) {\n          throw error;\n        }\n        throw new GuardrailExecutionError(\n          guardrail.name,\n          error instanceof Error ? error : new Error(String(error))\n        );\n      }\n    })\n  );\n  for (const result of results) {\n    if (result.status === \"rejected\") {\n      throw result.reason;\n    }\n  }\n}\nasync function runOutputGuardrails(guardrails, agentOutput, context) {\n  if (!guardrails || guardrails.length === 0) return;\n  const results = await Promise.allSettled(\n    guardrails.map(async (guardrail) => {\n      try {\n        const result = await guardrail.execute({ agentOutput, context });\n        if (result.tripwireTriggered) {\n          throw new OutputGuardrailTripwireTriggered(\n            guardrail.name,\n            result.outputInfo\n          );\n        }\n        return result;\n      } catch (error) {\n        if (error instanceof OutputGuardrailTripwireTriggered) {\n          throw error;\n        }\n        throw new GuardrailExecutionError(\n          guardrail.name,\n          error instanceof Error ? error : new Error(String(error))\n        );\n      }\n    })\n  );\n  for (const result of results) {\n    if (result.status === \"rejected\") {\n      throw result.reason;\n    }\n  }\n}\n\n// src/permissions.ts\nasync function checkToolPermission(permissions, toolName, args, context) {\n  if (!permissions) return;\n  try {\n    const result = await permissions.check({ toolName, args, context });\n    if (!result.allowed) {\n      throw new ToolPermissionDeniedError(\n        toolName,\n        result.reason || \"Permission denied\"\n      );\n    }\n  } catch (error) {\n    if (error instanceof ToolPermissionDeniedError) {\n      throw error;\n    }\n    throw error;\n  }\n}\nfunction createUsageTracker() {\n  return {\n    toolCalls: {},\n    tokens: 0\n  };\n}\nfunction trackToolCall(usage, toolName) {\n  usage.toolCalls[toolName] = (usage.toolCalls[toolName] || 0) + 1;\n}\n\n// src/routing.ts\nvar logger3 = createLogger(\"ROUTING\");\nfunction normalizeText(text) {\n  return text.toLowerCase().trim().replace(/\\d+/g, \"\").replace(/\\s+/g, \" \").trim();\n}\nfunction matchAgent(agent, message, matchOn) {\n  if (!matchOn) {\n    return { matched: false, score: 0 };\n  }\n  const normalizedMessage = normalizeText(message);\n  let score = 0;\n  if (typeof matchOn === \"function\") {\n    try {\n      const result = matchOn(message);\n      return { matched: result, score: result ? 10 : 0 };\n    } catch (error) {\n      logger3.error(`Error in matchOn function for ${agent.name}`, {\n        agent: agent.name,\n        error\n      });\n      return { matched: false, score: 0 };\n    }\n  }\n  for (const pattern of matchOn) {\n    if (typeof pattern === \"string\") {\n      const normalizedPattern = normalizeText(pattern);\n      if (normalizedMessage.includes(normalizedPattern)) {\n        const weight = normalizedPattern.split(\" \").length;\n        score += weight;\n      }\n    } else if (pattern instanceof RegExp) {\n      if (pattern.test(normalizedMessage)) {\n        score += 2;\n      }\n    }\n  }\n  return { matched: score > 0, score };\n}\nfunction findBestMatch(agents, message, getMatchOn) {\n  const scores = [];\n  for (const agent of agents) {\n    const matchOn = getMatchOn ? getMatchOn(agent) : void 0;\n    const { matched, score } = matchAgent(agent, message, matchOn);\n    if (matched && score > 0) {\n      scores.push({ agent, score });\n    }\n  }\n  if (scores.length === 0) {\n    return null;\n  }\n  scores.sort((a, b) => b.score - a.score);\n  return scores[0].agent;\n}\nexport {\n  Agent,\n  AgentRunContext,\n  AgentsError,\n  GuardrailExecutionError,\n  HANDOFF_TOOL_NAME,\n  InputGuardrailTripwireTriggered,\n  MaxTurnsExceededError,\n  OutputGuardrailTripwireTriggered,\n  ToolCallError,\n  ToolPermissionDeniedError,\n  checkToolPermission,\n  createExecutionContext,\n  createHandoff,\n  createHandoffTool,\n  createUsageTracker,\n  extractTextFromMessage,\n  findBestMatch,\n  getContext,\n  getTransferMessage,\n  handoff,\n  isHandoffResult,\n  isHandoffTool,\n  matchAgent,\n  runInputGuardrails,\n  runOutputGuardrails,\n  trackToolCall,\n  writeAgentStatus,\n  writeDataPart,\n  writeRateLimit\n};\n//# sourceMappingURL=index.js.map","import { streamText, tool } from \"ai\";\nimport { z } from \"zod\";\nimport { createAIProvider } from \"@/lib/ai\";\n\nexport const maxDuration = 30;\n\n// Weather tool\nconst weatherTool = tool({\n\tdescription: \"Get the current weather for a location\",\n\tinputSchema: z.object({\n\t\tlocation: z.string().describe(\"The city and state, e.g. San Francisco, CA\"),\n\t}),\n\texecute: async ({ location }) => {\n\t\t// Mock weather data\n\t\treturn {\n\t\t\tlocation,\n\t\t\ttemperature: 72,\n\t\t\tconditions: \"Sunny\",\n\t\t\thumidity: 45,\n\t\t};\n\t},\n});\n\n// Document creation tool\nconst createDocumentTool = tool({\n\tdescription: \"Create a new document (code, text, or other artifact)\",\n\tinputSchema: z.object({\n\t\ttitle: z.string().describe(\"The title of the document\"),\n\t\tcontent: z.string().describe(\"The content of the document\"),\n\t\tkind: z\n\t\t\t.enum([\"text\", \"code\", \"image\", \"sheet\"])\n\t\t\t.describe(\"The type of document\"),\n\t}),\n\texecute: async ({ title, content, kind }) => {\n\t\t// This would normally save to database\n\t\t// For now, just return the document data\n\t\treturn {\n\t\t\tid: `doc-${Date.now()}`,\n\t\t\ttitle,\n\t\t\tcontent,\n\t\t\tkind,\n\t\t\tcreatedAt: new Date().toISOString(),\n\t\t};\n\t},\n});\n\nexport async function POST(request: Request) {\n\ttry {\n\t\tconst { messages, model = \"gpt-4o\" } = await request.json();\n\n\t\t// Determine provider based on model\n\t\tlet provider: \"openai\" | \"anthropic\" | \"google\" = \"openai\";\n\t\tif (model.includes(\"claude\")) {\n\t\t\tprovider = \"anthropic\";\n\t\t} else if (model.includes(\"gemini\")) {\n\t\t\tprovider = \"google\";\n\t\t}\n\n\t\t// Create AI provider\n\t\tconst aiModel = createAIProvider({\n\t\t\tprovider,\n\t\t\tmodel,\n\t\t});\n\n\t\t// Stream the response with tools\n\t\tconst result = await streamText({\n\t\t\tmodel: aiModel,\n\t\t\tmessages,\n\t\t\ttools: {\n\t\t\t\tgetWeather: weatherTool,\n\t\t\t\tcreateDocument: createDocumentTool,\n\t\t\t},\n\t\t\ttemperature: 0.7,\n\t\t});\n\n\t\treturn result.toTextStreamResponse();\n\t} catch (error) {\n\t\treturn new Response(\n\t\t\tJSON.stringify({\n\t\t\t\terror: error instanceof Error ? error.message : \"An error occurred\",\n\t\t\t}),\n\t\t\t{\n\t\t\t\tstatus: 500,\n\t\t\t\theaders: {\n\t\t\t\t\t\"Content-Type\": \"application/json\",\n\t\t\t\t},\n\t\t\t},\n\t\t);\n\t}\n}\n","// src/streaming.ts\nvar StreamingArtifact = class {\n  constructor(config, instance, writer) {\n    this.config = config;\n    this.instance = instance;\n    this.writer = writer;\n    this.stream();\n  }\n  get data() {\n    return this.instance.payload;\n  }\n  get id() {\n    return this.instance.id;\n  }\n  get progress() {\n    return this.instance.progress;\n  }\n  set progress(value) {\n    this.instance.progress = value;\n    this.instance.updatedAt = Date.now();\n    this.stream();\n  }\n  async update(updates) {\n    if (\"progress\" in updates) {\n      this.instance.progress = updates.progress;\n      delete updates.progress;\n    }\n    this.instance.payload = { ...this.instance.payload, ...updates };\n    this.instance.status = \"streaming\";\n    this.instance.version++;\n    this.instance.updatedAt = Date.now();\n    this.stream();\n  }\n  async complete(finalData) {\n    if (finalData) {\n      this.instance.payload = finalData;\n    }\n    this.instance.status = \"complete\";\n    this.instance.progress = 1;\n    this.instance.version++;\n    this.instance.updatedAt = Date.now();\n    this.stream();\n  }\n  async error(message) {\n    this.instance.status = \"error\";\n    this.instance.error = message;\n    this.instance.version++;\n    this.instance.updatedAt = Date.now();\n    this.stream();\n  }\n  async cancel() {\n    this.instance.status = \"error\";\n    this.instance.error = \"Artifact was cancelled\";\n    this.instance.version++;\n    this.instance.updatedAt = Date.now();\n    this.stream();\n  }\n  timeout(ms) {\n    setTimeout(() => {\n      if (this.instance.status === \"loading\" || this.instance.status === \"streaming\") {\n        this.error(`Artifact timed out after ${ms}ms`);\n      }\n    }, ms);\n  }\n  stream() {\n    this.writer.write({\n      type: `data-artifact-${this.config.id}`,\n      id: this.instance.id,\n      data: this.instance\n    });\n  }\n};\n\n// src/utils.ts\nimport { generateId as generateIdAi } from \"ai\";\nfunction generateId() {\n  return `artifact_${Date.now()}_${generateIdAi()}`;\n}\nfunction getDefaults(schema) {\n  try {\n    return schema.parse({});\n  } catch {\n    return {};\n  }\n}\n\n// src/artifact.ts\nfunction artifact(id, schema) {\n  const config = { id, schema };\n  return {\n    id,\n    schema,\n    create(data = {}) {\n      const defaults = getDefaults(schema);\n      const validated = schema.parse({ ...defaults, ...data });\n      return {\n        id: generateId(),\n        type: id,\n        status: \"idle\",\n        payload: validated,\n        version: 1,\n        createdAt: Date.now(),\n        updatedAt: Date.now()\n      };\n    },\n    stream(data, writer) {\n      const instance = this.create(data);\n      instance.status = \"loading\";\n      return new StreamingArtifact(config, instance, writer);\n    },\n    validate(data) {\n      return schema.parse(data);\n    },\n    isValid(data) {\n      try {\n        schema.parse(data);\n        return true;\n      } catch {\n        return false;\n      }\n    }\n  };\n}\n\n// src/context.ts\nfunction getWriter(executionOptions) {\n  const writer = executionOptions?.experimental_context?.writer;\n  if (!writer) {\n    throw new Error(\n      \"Writer not available. Make sure you're passing executionOptions: getWriter(executionOptions)\"\n    );\n  }\n  return writer;\n}\n\n// src/types.ts\nvar ArtifactError = class extends Error {\n  constructor(code, message) {\n    super(message);\n    this.code = code;\n    this.name = \"ArtifactError\";\n  }\n};\nexport {\n  ArtifactError,\n  StreamingArtifact,\n  artifact,\n  getWriter\n};\n//# sourceMappingURL=index.mjs.map","/**\n * AI Audit Trail Service - Tamper-evident logging for AI actions\n * Based on industry best practices from Langfuse, Datadog, and compliance standards\n */\n\nimport { createServiceSupabaseClient } from \"@/lib/supabase/service-client\";\nimport crypto from \"crypto\";\n\nexport type AuditAction =\n  | \"create\"\n  | \"update\"\n  | \"delete\"\n  | \"query\"\n  | \"tool_call\"\n  | \"api_call\"\n  | \"file_access\"\n  | \"permission_change\"\n  | \"configuration_change\"\n  | \"data_export\"\n  | \"bulk_operation\";\n\nexport type AuditSeverity = \"low\" | \"medium\" | \"high\" | \"critical\";\n\nexport interface AuditContext {\n  companyId: string;\n  userId?: string;\n  chatId?: string;\n  messageId?: string;\n  traceId?: string;\n  spanId?: string;\n  sessionId?: string;\n}\n\nexport interface AuditLogEntry {\n  action: AuditAction;\n  entityType: string;\n  entityId?: string;\n  entityIds?: string[];\n  beforeState?: Record<string, unknown>;\n  afterState?: Record<string, unknown>;\n  changedFields?: string[];\n  toolName?: string;\n  toolParams?: Record<string, unknown>;\n  toolResult?: Record<string, unknown>;\n  severity?: AuditSeverity;\n  ipAddress?: string;\n  userAgent?: string;\n  metadata?: Record<string, unknown>;\n}\n\nexport interface ReversalRequest {\n  auditLogId: string;\n  reason: string;\n  reversedBy: string;\n  reversalMethod: \"automatic\" | \"manual\" | \"partial\";\n  partialFields?: string[];\n}\n\n/**\n * Calculate SHA-256 checksum for tamper detection\n */\nfunction calculateChecksum(data: Record<string, unknown>): string {\n  const normalized = JSON.stringify(data, Object.keys(data).sort());\n  return crypto.createHash(\"sha256\").update(normalized).digest(\"hex\");\n}\n\n/**\n * Determine severity based on action and entity type\n */\nfunction determineSeverity(action: AuditAction, entityType: string): AuditSeverity {\n  // Critical actions\n  if (action === \"delete\" || action === \"permission_change\") return \"critical\";\n  if (action === \"bulk_operation\") return \"high\";\n  if (entityType.includes(\"payment\") || entityType.includes(\"invoice\")) return \"high\";\n  if (action === \"configuration_change\") return \"high\";\n  if (action === \"data_export\") return \"high\";\n  if (action === \"update\") return \"medium\";\n  if (action === \"create\") return \"medium\";\n  return \"low\";\n}\n\n/**\n * Extract changed fields from before/after states\n */\nfunction extractChangedFields(\n  before?: Record<string, unknown>,\n  after?: Record<string, unknown>\n): string[] {\n  if (!before || !after) return [];\n\n  const changedFields: string[] = [];\n  const allKeys = new Set([...Object.keys(before), ...Object.keys(after)]);\n\n  for (const key of allKeys) {\n    if (JSON.stringify(before[key]) !== JSON.stringify(after[key])) {\n      changedFields.push(key);\n    }\n  }\n\n  return changedFields;\n}\n\n/**\n * Create an audit log entry with tamper-evident checksum\n */\nexport async function createAuditLog(\n  context: AuditContext,\n  entry: AuditLogEntry\n): Promise<string> {\n  const supabase = createServiceSupabaseClient();\n  const auditId = crypto.randomUUID();\n  const timestamp = new Date().toISOString();\n\n  // Calculate changed fields if not provided\n  const changedFields =\n    entry.changedFields || extractChangedFields(entry.beforeState, entry.afterState);\n\n  // Determine severity if not provided\n  const severity = entry.severity || determineSeverity(entry.action, entry.entityType);\n\n  // Prepare the data for checksum calculation\n  const checksumData = {\n    id: auditId,\n    company_id: context.companyId,\n    user_id: context.userId,\n    chat_id: context.chatId,\n    message_id: context.messageId,\n    trace_id: context.traceId,\n    span_id: context.spanId,\n    action: entry.action,\n    entity_type: entry.entityType,\n    entity_id: entry.entityId,\n    entity_ids: entry.entityIds,\n    before_state: entry.beforeState,\n    after_state: entry.afterState,\n    changed_fields: changedFields,\n    tool_name: entry.toolName,\n    tool_params: entry.toolParams,\n    tool_result: entry.toolResult,\n    timestamp,\n  };\n\n  const checksum = calculateChecksum(checksumData);\n\n  const { error } = await supabase.from(\"ai_audit_log\").insert({\n    id: auditId,\n    company_id: context.companyId,\n    user_id: context.userId,\n    chat_id: context.chatId,\n    message_id: context.messageId,\n    trace_id: context.traceId,\n    span_id: context.spanId,\n    action: entry.action,\n    entity_type: entry.entityType,\n    entity_id: entry.entityId,\n    entity_ids: entry.entityIds || [],\n    before_state: entry.beforeState,\n    after_state: entry.afterState,\n    changed_fields: changedFields,\n    tool_name: entry.toolName,\n    tool_params: entry.toolParams,\n    tool_result: entry.toolResult,\n    severity,\n    ip_address: entry.ipAddress,\n    user_agent: entry.userAgent,\n    metadata: entry.metadata || {},\n    checksum,\n    is_reversible: entry.action !== \"query\" && entry.beforeState !== undefined,\n    reversed: false,\n    created_at: timestamp,\n  });\n\n  if (error) {\n    console.error(\"Failed to create audit log:\", error);\n    throw error;\n  }\n\n  return auditId;\n}\n\n/**\n * Verify audit log integrity by recalculating checksum\n */\nexport async function verifyAuditLogIntegrity(\n  companyId: string,\n  auditLogId: string\n): Promise<{ valid: boolean; reason?: string }> {\n  const supabase = createServiceSupabaseClient();\n\n  const { data, error } = await supabase\n    .from(\"ai_audit_log\")\n    .select(\"*\")\n    .eq(\"id\", auditLogId)\n    .eq(\"company_id\", companyId)\n    .single();\n\n  if (error || !data) {\n    return { valid: false, reason: \"Audit log not found\" };\n  }\n\n  // Recalculate checksum\n  const checksumData = {\n    id: data.id,\n    company_id: data.company_id,\n    user_id: data.user_id,\n    chat_id: data.chat_id,\n    message_id: data.message_id,\n    trace_id: data.trace_id,\n    span_id: data.span_id,\n    action: data.action,\n    entity_type: data.entity_type,\n    entity_id: data.entity_id,\n    entity_ids: data.entity_ids,\n    before_state: data.before_state,\n    after_state: data.after_state,\n    changed_fields: data.changed_fields,\n    tool_name: data.tool_name,\n    tool_params: data.tool_params,\n    tool_result: data.tool_result,\n    timestamp: data.created_at,\n  };\n\n  const calculatedChecksum = calculateChecksum(checksumData);\n\n  if (calculatedChecksum !== data.checksum) {\n    return { valid: false, reason: \"Checksum mismatch - data may have been tampered\" };\n  }\n\n  return { valid: true };\n}\n\n/**\n * Get audit trail for a specific entity\n */\nexport async function getEntityAuditTrail(\n  companyId: string,\n  entityType: string,\n  entityId: string,\n  options?: { limit?: number; offset?: number }\n): Promise<{\n  entries: Array<{\n    id: string;\n    action: string;\n    changedFields: string[];\n    beforeState: Record<string, unknown> | null;\n    afterState: Record<string, unknown> | null;\n    userId: string | null;\n    toolName: string | null;\n    severity: string;\n    reversed: boolean;\n    createdAt: string;\n  }>;\n  total: number;\n}> {\n  const supabase = createServiceSupabaseClient();\n  const limit = options?.limit || 50;\n  const offset = options?.offset || 0;\n\n  // Get total count\n  const { count } = await supabase\n    .from(\"ai_audit_log\")\n    .select(\"*\", { count: \"exact\", head: true })\n    .eq(\"company_id\", companyId)\n    .eq(\"entity_type\", entityType)\n    .eq(\"entity_id\", entityId);\n\n  // Get entries\n  const { data, error } = await supabase\n    .from(\"ai_audit_log\")\n    .select(\n      \"id, action, changed_fields, before_state, after_state, user_id, tool_name, severity, reversed, created_at\"\n    )\n    .eq(\"company_id\", companyId)\n    .eq(\"entity_type\", entityType)\n    .eq(\"entity_id\", entityId)\n    .order(\"created_at\", { ascending: false })\n    .range(offset, offset + limit - 1);\n\n  if (error) {\n    console.error(\"Failed to get entity audit trail:\", error);\n    return { entries: [], total: 0 };\n  }\n\n  return {\n    entries: (data || []).map((entry) => ({\n      id: entry.id,\n      action: entry.action,\n      changedFields: entry.changed_fields || [],\n      beforeState: entry.before_state as Record<string, unknown> | null,\n      afterState: entry.after_state as Record<string, unknown> | null,\n      userId: entry.user_id,\n      toolName: entry.tool_name,\n      severity: entry.severity,\n      reversed: entry.reversed,\n      createdAt: entry.created_at,\n    })),\n    total: count || 0,\n  };\n}\n\n/**\n * Get audit trail for a chat session\n */\nexport async function getChatAuditTrail(\n  companyId: string,\n  chatId: string,\n  options?: { limit?: number; offset?: number; severityFilter?: AuditSeverity[] }\n): Promise<{\n  entries: Array<{\n    id: string;\n    action: string;\n    entityType: string;\n    entityId: string | null;\n    toolName: string | null;\n    severity: string;\n    isReversible: boolean;\n    reversed: boolean;\n    createdAt: string;\n  }>;\n  total: number;\n}> {\n  const supabase = createServiceSupabaseClient();\n  const limit = options?.limit || 50;\n  const offset = options?.offset || 0;\n\n  let query = supabase\n    .from(\"ai_audit_log\")\n    .select(\"*\", { count: \"exact\" })\n    .eq(\"company_id\", companyId)\n    .eq(\"chat_id\", chatId);\n\n  if (options?.severityFilter && options.severityFilter.length > 0) {\n    query = query.in(\"severity\", options.severityFilter);\n  }\n\n  const { data, error, count } = await query\n    .order(\"created_at\", { ascending: false })\n    .range(offset, offset + limit - 1);\n\n  if (error) {\n    console.error(\"Failed to get chat audit trail:\", error);\n    return { entries: [], total: 0 };\n  }\n\n  return {\n    entries: (data || []).map((entry) => ({\n      id: entry.id,\n      action: entry.action,\n      entityType: entry.entity_type,\n      entityId: entry.entity_id,\n      toolName: entry.tool_name,\n      severity: entry.severity,\n      isReversible: entry.is_reversible,\n      reversed: entry.reversed,\n      createdAt: entry.created_at,\n    })),\n    total: count || 0,\n  };\n}\n\n/**\n * Get high-severity audit entries for monitoring\n */\nexport async function getHighSeverityAuditEntries(\n  companyId: string,\n  options?: {\n    since?: Date;\n    limit?: number;\n    includeReversed?: boolean;\n  }\n): Promise<\n  Array<{\n    id: string;\n    action: string;\n    entityType: string;\n    entityId: string | null;\n    userId: string | null;\n    toolName: string | null;\n    severity: string;\n    reversed: boolean;\n    createdAt: string;\n  }>\n> {\n  const supabase = createServiceSupabaseClient();\n  const since = options?.since || new Date(Date.now() - 24 * 60 * 60 * 1000); // Last 24 hours\n\n  let query = supabase\n    .from(\"ai_audit_log\")\n    .select(\n      \"id, action, entity_type, entity_id, user_id, tool_name, severity, reversed, created_at\"\n    )\n    .eq(\"company_id\", companyId)\n    .in(\"severity\", [\"high\", \"critical\"])\n    .gte(\"created_at\", since.toISOString())\n    .order(\"created_at\", { ascending: false })\n    .limit(options?.limit || 100);\n\n  if (!options?.includeReversed) {\n    query = query.eq(\"reversed\", false);\n  }\n\n  const { data, error } = await query;\n\n  if (error) {\n    console.error(\"Failed to get high severity audit entries:\", error);\n    return [];\n  }\n\n  return (data || []).map((entry) => ({\n    id: entry.id,\n    action: entry.action,\n    entityType: entry.entity_type,\n    entityId: entry.entity_id,\n    userId: entry.user_id,\n    toolName: entry.tool_name,\n    severity: entry.severity,\n    reversed: entry.reversed,\n    createdAt: entry.created_at,\n  }));\n}\n\n/**\n * Record a reversal action\n */\nexport async function recordReversal(\n  companyId: string,\n  request: ReversalRequest\n): Promise<string> {\n  const supabase = createServiceSupabaseClient();\n  const reversalId = crypto.randomUUID();\n\n  // Get the original audit log entry\n  const { data: auditLog, error: fetchError } = await supabase\n    .from(\"ai_audit_log\")\n    .select(\"*\")\n    .eq(\"id\", request.auditLogId)\n    .eq(\"company_id\", companyId)\n    .single();\n\n  if (fetchError || !auditLog) {\n    throw new Error(\"Audit log entry not found\");\n  }\n\n  if (!auditLog.is_reversible) {\n    throw new Error(\"This action is not reversible\");\n  }\n\n  if (auditLog.reversed) {\n    throw new Error(\"This action has already been reversed\");\n  }\n\n  // Create reversal record\n  const { error: insertError } = await supabase.from(\"ai_audit_reversal\").insert({\n    id: reversalId,\n    company_id: companyId,\n    audit_log_id: request.auditLogId,\n    reversed_by: request.reversedBy,\n    reversal_reason: request.reason,\n    reversal_method: request.reversalMethod,\n    original_action: auditLog.action,\n    original_entity_type: auditLog.entity_type,\n    original_entity_id: auditLog.entity_id,\n    restored_state: auditLog.before_state,\n    partial_fields: request.partialFields,\n    created_at: new Date().toISOString(),\n  });\n\n  if (insertError) {\n    console.error(\"Failed to record reversal:\", insertError);\n    throw insertError;\n  }\n\n  // Mark original audit log as reversed\n  const { error: updateError } = await supabase\n    .from(\"ai_audit_log\")\n    .update({\n      reversed: true,\n      reversed_at: new Date().toISOString(),\n      reversed_by: request.reversedBy,\n      reversal_id: reversalId,\n    })\n    .eq(\"id\", request.auditLogId)\n    .eq(\"company_id\", companyId);\n\n  if (updateError) {\n    console.error(\"Failed to update audit log:\", updateError);\n  }\n\n  return reversalId;\n}\n\n/**\n * Get audit statistics for monitoring dashboard\n */\nexport async function getAuditStatistics(\n  companyId: string,\n  dateRange: { start: Date; end: Date }\n): Promise<{\n  totalActions: number;\n  byAction: Record<string, number>;\n  bySeverity: Record<string, number>;\n  byEntityType: Record<string, number>;\n  reversalRate: number;\n  criticalActionsCount: number;\n  topTools: Array<{ tool: string; count: number }>;\n}> {\n  const supabase = createServiceSupabaseClient();\n\n  const { data, error } = await supabase\n    .from(\"ai_audit_log\")\n    .select(\"action, severity, entity_type, tool_name, reversed\")\n    .eq(\"company_id\", companyId)\n    .gte(\"created_at\", dateRange.start.toISOString())\n    .lte(\"created_at\", dateRange.end.toISOString());\n\n  if (error || !data) {\n    return {\n      totalActions: 0,\n      byAction: {},\n      bySeverity: {},\n      byEntityType: {},\n      reversalRate: 0,\n      criticalActionsCount: 0,\n      topTools: [],\n    };\n  }\n\n  const byAction: Record<string, number> = {};\n  const bySeverity: Record<string, number> = {};\n  const byEntityType: Record<string, number> = {};\n  const toolCounts: Record<string, number> = {};\n  let reversedCount = 0;\n  let criticalCount = 0;\n\n  for (const entry of data) {\n    byAction[entry.action] = (byAction[entry.action] || 0) + 1;\n    bySeverity[entry.severity] = (bySeverity[entry.severity] || 0) + 1;\n    byEntityType[entry.entity_type] = (byEntityType[entry.entity_type] || 0) + 1;\n\n    if (entry.tool_name) {\n      toolCounts[entry.tool_name] = (toolCounts[entry.tool_name] || 0) + 1;\n    }\n\n    if (entry.reversed) reversedCount++;\n    if (entry.severity === \"critical\") criticalCount++;\n  }\n\n  const topTools = Object.entries(toolCounts)\n    .map(([tool, count]) => ({ tool, count }))\n    .sort((a, b) => b.count - a.count)\n    .slice(0, 10);\n\n  return {\n    totalActions: data.length,\n    byAction,\n    bySeverity,\n    byEntityType,\n    reversalRate: data.length > 0 ? (reversedCount / data.length) * 100 : 0,\n    criticalActionsCount: criticalCount,\n    topTools,\n  };\n}\n","/**\n * AI Caching Layer\n *\n * Universal caching for AI SDK tools using @ai-sdk-tools/cache\n * Supports LRU in-memory caching with optional Redis backend\n */\n\nimport { cached, createCached, type CachedTool } from \"@ai-sdk-tools/cache\";\nimport type { Tool } from \"ai\";\n\n/**\n * Default cache configuration\n */\nconst DEFAULT_CACHE_CONFIG = {\n\tttl: 5 * 60 * 1000, // 5 minutes\n\tmaxSize: 1000, // Max 1000 entries\n\tdebug: process.env.NODE_ENV === \"development\",\n};\n\n/**\n * Create a cached version of an AI tool\n *\n * @param tool - The AI SDK tool to cache\n * @param options - Cache options\n * @returns Cached tool with statistics\n *\n * @example\n * ```ts\n * import { cacheAITool } from '@/lib/ai/cache';\n * import { searchCustomers } from './tools';\n *\n * const cachedSearch = cacheAITool(searchCustomers, {\n *   ttl: 60000, // 1 minute cache\n * });\n *\n * // Use like normal tool\n * const results = await cachedSearch.execute({ query: 'john' });\n *\n * // Get cache stats\n * console.log(cachedSearch.getStats());\n * // { hits: 5, misses: 2, hitRate: 0.71, size: 7, maxSize: 1000 }\n * ```\n */\nexport function cacheAITool<T extends Tool>(\n\ttool: T,\n\toptions?: {\n\t\tttl?: number;\n\t\tmaxSize?: number;\n\t\tkeyGenerator?: (params: unknown, context?: unknown) => string;\n\t\tshouldCache?: (params: unknown, result: unknown) => boolean;\n\t\tonHit?: (key: string) => void;\n\t\tonMiss?: (key: string) => void;\n\t}\n): CachedTool<T> {\n\treturn cached(tool, {\n\t\t...DEFAULT_CACHE_CONFIG,\n\t\t...options,\n\t});\n}\n\n/**\n * Create a cached tool factory with shared configuration\n *\n * Useful for caching multiple tools with the same backend (e.g., Redis)\n *\n * @param options - Shared cache options\n * @returns Function to create cached tools\n *\n * @example\n * ```ts\n * import { createCachedToolFactory } from '@/lib/ai/cache';\n * import { Redis } from '@upstash/redis';\n *\n * // Create factory with Redis backend\n * const cacheTool = createCachedToolFactory({\n *   cache: Redis.fromEnv(),\n *   keyPrefix: 'ai:tools:',\n *   ttl: 300000, // 5 minutes\n * });\n *\n * // Cache multiple tools\n * const cachedSearchCustomers = cacheTool(searchCustomers);\n * const cachedGetJobDetails = cacheTool(getJobDetails);\n * ```\n */\nexport function createCachedToolFactory(options?: {\n\tcache?: unknown; // Redis client or similar\n\tkeyPrefix?: string;\n\tttl?: number;\n\tdebug?: boolean;\n\tonHit?: (key: string) => void;\n\tonMiss?: (key: string) => void;\n}) {\n\treturn createCached({\n\t\t...DEFAULT_CACHE_CONFIG,\n\t\t...options,\n\t});\n}\n\n/**\n * Pre-configured cache factory for Stratos AI tools\n *\n * Uses in-memory LRU cache by default\n * Can be upgraded to Redis for production\n */\nexport const stratosCache = createCachedToolFactory({\n\tkeyPrefix: \"stratos:ai:\",\n\tttl: DEFAULT_CACHE_CONFIG.ttl,\n\tdebug: DEFAULT_CACHE_CONFIG.debug,\n\tonHit: (key) => {\n\t\tif (process.env.NODE_ENV === \"development\") {\n\t\t\tconsole.log(`[Cache HIT] ${key}`);\n\t\t}\n\t},\n\tonMiss: (key) => {\n\t\tif (process.env.NODE_ENV === \"development\") {\n\t\t\tconsole.log(`[Cache MISS] ${key}`);\n\t\t}\n\t},\n});\n\n/**\n * Cache key generators for common patterns\n */\nexport const cacheKeyGenerators = {\n\t/**\n\t * Generate cache key from customer ID\n\t */\n\tbyCustomerId: (params: { customerId?: string }) =>\n\t\tparams.customerId ? `customer:${params.customerId}` : \"customer:unknown\",\n\n\t/**\n\t * Generate cache key from job ID\n\t */\n\tbyJobId: (params: { jobId?: string }) =>\n\t\tparams.jobId ? `job:${params.jobId}` : \"job:unknown\",\n\n\t/**\n\t * Generate cache key from invoice ID\n\t */\n\tbyInvoiceId: (params: { invoiceId?: string }) =>\n\t\tparams.invoiceId ? `invoice:${params.invoiceId}` : \"invoice:unknown\",\n\n\t/**\n\t * Generate cache key from search query\n\t */\n\tbySearchQuery: (params: { query?: string; limit?: number }) =>\n\t\t`search:${params.query || \"\"}:${params.limit || 10}`,\n\n\t/**\n\t * Generate cache key from date range\n\t */\n\tbyDateRange: (params: { startDate?: string; endDate?: string }) =>\n\t\t`range:${params.startDate || \"\"}:${params.endDate || \"\"}`,\n};\n\n/**\n * Cache invalidation helpers\n */\nexport const cacheInvalidation = {\n\t/**\n\t * Invalidate all cached data for a customer\n\t */\n\tinvalidateCustomer: (cachedTool: CachedTool<Tool>, customerId: string) => {\n\t\tcachedTool.clearCache(`customer:${customerId}`);\n\t},\n\n\t/**\n\t * Invalidate all cached data for a job\n\t */\n\tinvalidateJob: (cachedTool: CachedTool<Tool>, jobId: string) => {\n\t\tcachedTool.clearCache(`job:${jobId}`);\n\t},\n\n\t/**\n\t * Clear all cache entries\n\t */\n\tclearAll: (cachedTool: CachedTool<Tool>) => {\n\t\tcachedTool.clearCache();\n\t},\n};\n\n/**\n * Conditional caching predicates\n */\nexport const shouldCachePredicates = {\n\t/**\n\t * Only cache successful results\n\t */\n\tonSuccess: (_params: unknown, result: unknown) => {\n\t\tif (typeof result === \"object\" && result !== null) {\n\t\t\tconst r = result as { error?: unknown; success?: boolean };\n\t\t\treturn !r.error && r.success !== false;\n\t\t}\n\t\treturn true;\n\t},\n\n\t/**\n\t * Only cache results with data\n\t */\n\thasData: (_params: unknown, result: unknown) => {\n\t\tif (typeof result === \"object\" && result !== null) {\n\t\t\tconst r = result as { data?: unknown };\n\t\t\treturn r.data !== undefined && r.data !== null;\n\t\t}\n\t\treturn false;\n\t},\n\n\t/**\n\t * Only cache non-empty arrays\n\t */\n\tnonEmptyArray: (_params: unknown, result: unknown) => {\n\t\tif (Array.isArray(result)) {\n\t\t\treturn result.length > 0;\n\t\t}\n\t\tif (typeof result === \"object\" && result !== null) {\n\t\t\tconst r = result as { data?: unknown[] };\n\t\t\treturn Array.isArray(r.data) && r.data.length > 0;\n\t\t}\n\t\treturn false;\n\t},\n};\n","/**\n * AI Module - Vercel AI SDK with Gateway Integration\n * Plus comprehensive AI agent infrastructure including:\n * - OpenTelemetry-style tracing and observability\n * - Tamper-evident audit trails\n * - Rubrik-style undo/rollback\n * - User feedback collection (RLHF/RLUF)\n * - Semantic memory with embeddings\n * - Multi-step planning with approval workflow\n * - Proactive analysis and insights\n */\n\n// Core AI Configuration\nexport type { AIConfig, AIProvider } from \"./config\";\nexport { createAIProvider } from \"./config\";\n\n// Workflow Types\nexport type {\n  AgentContext,\n  AgentMessage,\n  AgentResult,\n  AgentRole,\n  ToolDefinition,\n  WorkflowContext,\n  WorkflowDefinition,\n  WorkflowResult,\n  WorkflowStatus,\n  WorkflowStep,\n  WorkflowStepResult,\n} from \"./workflows\";\n\n// Tracing - OpenTelemetry-style trace and span management\nexport {\n  type SpanType,\n  type SpanStatus,\n  type TraceContext,\n  type SpanData,\n  type SpanEvent,\n  generateTraceId,\n  createTraceContext,\n  calculateCost,\n  startSpan,\n  endSpan,\n  recordSpanEvent,\n  getTraceSummary,\n  getDailyMetrics,\n} from \"./tracing\";\n\n// Audit Trail - Tamper-evident logging\nexport {\n  type AuditAction,\n  type AuditSeverity,\n  type AuditContext,\n  type AuditLogEntry,\n  type ReversalRequest,\n  createAuditLog,\n  verifyAuditLogIntegrity,\n  getEntityAuditTrail,\n  getChatAuditTrail,\n  getHighSeverityAuditEntries,\n  recordReversal,\n  getAuditStatistics,\n} from \"./audit-trail\";\n\n// Action Reverter - Rubrik-style selective rollback\nexport {\n  type SnapshotType,\n  type RevertStatus,\n  type ActionSnapshot,\n  type RevertResult,\n  createActionSnapshot,\n  createBulkSnapshots,\n  getMessageSnapshots,\n  getRevertableActions,\n  revertSnapshot,\n  revertMessageActions,\n  previewRevert,\n  getEntityRevertHistory,\n  batchRevert,\n} from \"./action-reverter\";\n\n// Feedback Service - User feedback and RLHF\nexport {\n  type FeedbackType,\n  type FeedbackCategory,\n  type FeedbackStatus,\n  type FeedbackSubmission,\n  type FeedbackResponse,\n  submitFeedback,\n  submitQuickFeedback,\n  submitCorrection,\n  flagResponse,\n  getMessageFeedback,\n  getChatFeedbackSummary,\n  getCompanyFeedbackAnalytics,\n  getPendingFeedbackReview,\n  updateFeedbackStatus,\n  exportCorrectionsForTraining,\n} from \"./feedback-service\";\n\n// Memory Service - Semantic memory with embeddings\nexport {\n  type MemoryType,\n  type MemoryScope,\n  type MemoryEntry,\n  type MemorySearchResult,\n  storeMemory,\n  storeMemories,\n  searchMemories,\n  getEntityMemories,\n  updateMemoryImportance,\n  deleteMemory,\n  extractMemoriesFromConversation,\n  getMemoryStatistics,\n  consolidateMemories,\n  decayOldMemories,\n} from \"./memory-service\";\n\n// Planner - Multi-step planning with approval workflow\nexport {\n  type PlanStatus,\n  type StepStatus,\n  type StepType,\n  type PlanStep,\n  type Plan,\n  type PlanExecutionResult,\n  createPlan,\n  getPlan,\n  approvePlan,\n  rejectPlan,\n  updatePlanProgress,\n  startPlanExecution,\n  cancelPlan,\n  getChatPlans,\n  getPendingApprovalPlans,\n  getPlanStatistics,\n  generatePlanFromDescription,\n} from \"./planner\";\n\n// Proactive Analyzer - Background analysis and insights\nexport {\n  type InsightType,\n  type InsightPriority,\n  type InsightStatus,\n  type InsightCategory,\n  type Insight,\n  type InsightResult,\n  createInsight,\n  getActiveInsights,\n  acknowledgeInsight,\n  dismissInsight,\n  resolveInsight,\n  analyzeRevenue,\n  analyzeCustomers,\n  analyzeScheduling,\n  runFullAnalysis,\n  getInsightStatistics,\n} from \"./proactive-analyzer\";\n\n// Action Approval - Owner-only approval for destructive AI actions\nexport {\n  type PendingAction,\n  type CreatePendingActionInput,\n  type ApprovalResult,\n  type DestructiveToolMetadata,\n  type DestructiveActionType,\n  type RiskLevel,\n  isCompanyOwner,\n  getCompanyOwners,\n  createPendingAction,\n  getPendingActionsForChat,\n  getPendingActionsForCompany,\n  getPendingAction,\n  approveAction,\n  rejectAction,\n  markActionExecuted,\n  markActionFailed,\n  expireOldActions,\n  shouldInterceptTool,\n  isDestructiveTool,\n  getDestructiveToolMetadata,\n} from \"./action-approval\";\n\n// ==========================================\n// NEW: ai-sdk-tools Integration (2024)\n// ==========================================\n\n// Memory Provider (Supabase backend for @ai-sdk-tools/memory)\nexport {\n\tcreateSupabaseMemoryProvider,\n\tDEFAULT_WORKING_MEMORY_TEMPLATE,\n} from \"./memory-provider\";\n\n// Multi-Agent System (@ai-sdk-tools/agents)\nexport { createAgentSystem, Agent, type AgentConfig } from \"./agents\";\n\n// Semantic Memory Tools (for agent use)\nexport {\n\tstoreMemoryTool,\n\tsearchMemoriesTool,\n\tgetEntityMemoriesTool,\n\trecallContextTool,\n} from \"./agent-tools\";\n\n// Communication Learning Tools (learn from customer interactions)\nexport {\n\tsearchCommunicationsFullTextTool,\n\tgetCallTranscriptTool,\n\tsearchVoicemailTranscriptsTool,\n\tgetCustomerCommunicationHistoryTool,\n\textractCommunicationInsightsTool,\n} from \"./agent-tools\";\n\n// External Data Tools (weather, traffic, GPS)\nexport {\n\tgetWeatherForLocationTool,\n\tcheckWeatherForJobTool,\n\tgetWeatherAlertsTool,\n\tgetTrafficConditionsTool,\n\tgeocodeAddressTool,\n\tgetPropertyConditionsTool,\n} from \"./agent-tools\";\n\n// Code Search Tools (building, plumbing, electrical codes)\nexport {\n\tsearchBuildingCodesTool,\n\tgetPermitRequirementsTool,\n\tgetCodeComplianceChecklistTool,\n} from \"./agent-tools\";\n\n// Proactive Learning System (auto-learn from interactions)\nexport {\n\tanalyzeRecentCommunicationsTool,\n\tlearnFromCompletedJobsTool,\n\tbuildCustomerProfileTool,\n} from \"./agent-tools\";\n\n// Route Optimization Tools (directions and supplier finding)\nexport {\n\tgetRouteTool,\n\tfindNearbySuppliersTool,\n} from \"./agent-tools\";\n\n// Inventory & Parts Tools\nexport {\n\tsearchInventoryTool,\n\tcheckPartsAvailabilityTool,\n\tgetLowStockAlertsTool,\n} from \"./agent-tools\";\n\n// Equipment History Tools\nexport {\n\tgetPropertyEquipmentTool,\n\tgetEquipmentServiceHistoryTool,\n\tcheckEquipmentWarrantyTool,\n} from \"./agent-tools\";\n\n// Technician Matching Tools\nexport {\n\tfindTechniciansBySkillsTool,\n\tgetTechnicianWorkloadTool,\n} from \"./agent-tools\";\n\n// Pricing & Estimation Tools\nexport {\n\tsearchPriceBookTool,\n\tcalculateEstimateTool,\n} from \"./agent-tools\";\n\n// Smart Scheduling Tools\nexport {\n\tsuggestTechnicianForJobTool,\n\toptimizeJobOrderTool,\n} from \"./agent-tools\";\n\n// Caching Layer (@ai-sdk-tools/cache)\nexport {\n\tcacheAITool,\n\tcreateCachedToolFactory,\n\tstratosCache,\n\tcacheKeyGenerators,\n\tcacheInvalidation,\n\tshouldCachePredicates,\n} from \"./cache\";\n\n// Artifacts (@ai-sdk-tools/artifacts)\nexport {\n\t// Schemas\n\tcustomerCardSchema,\n\tjobSummarySchema,\n\tinvoiceArtifactSchema,\n\tscheduleViewSchema,\n\tchartDataSchema,\n\ttableDataSchema,\n\testimateArtifactSchema,\n\t// Artifact instances\n\tcustomerCardArtifact,\n\tjobSummaryArtifact,\n\tinvoiceArtifact,\n\tscheduleViewArtifact,\n\tchartDataArtifact,\n\ttableDataArtifact,\n\testimateArtifact,\n\tstratosArtifacts,\n\tARTIFACT_IDS,\n\tgetWriter,\n\t// Types\n\ttype CustomerCardArtifact,\n\ttype JobSummaryArtifact,\n\ttype InvoiceArtifact,\n\ttype ScheduleViewArtifact,\n\ttype ChartDataArtifact,\n\ttype TableDataArtifact,\n\ttype EstimateArtifact,\n\ttype ArtifactId,\n} from \"./artifacts\";\n\n// Structured Output (generateObject/streamObject)\nexport {\n\t// Schemas\n\tcustomerInsightsSchema,\n\tjobAnalysisSchema,\n\tscheduleOptimizationSchema,\n\tfinancialSummarySchema,\n\temailDraftSchema,\n\tresponseSuggestionsSchema,\n\t// Generator functions\n\tgenerateCustomerInsights,\n\tstreamJobAnalysis,\n\tgenerateScheduleOptimization,\n\tgenerateFinancialSummary,\n\tgenerateEmailDraft,\n\tstreamResponseSuggestions,\n\t// Types\n\ttype CustomerInsights,\n\ttype JobAnalysis,\n\ttype ScheduleOptimization,\n\ttype FinancialSummary,\n\ttype EmailDraft,\n\ttype ResponseSuggestions,\n} from \"./structured-output\";\n\n// Re-export types from ai-sdk-tools packages\nexport type {\n\tMemoryProvider as AIToolsMemoryProvider,\n\tWorkingMemory as AIToolsWorkingMemory,\n\tConversationMessage as AIToolsConversationMessage,\n\tChatSession as AIToolsChatSession,\n} from \"@ai-sdk-tools/memory\";\n\nexport type { CachedTool, CacheOptions } from \"@ai-sdk-tools/cache\";\n\n// Store (@ai-sdk-tools/store) - Chat state management\nexport {\n\tcreateStratosChatStore,\n\tStratosChatProvider,\n\tuseChatStore,\n\tuseChatMessages,\n\tuseChatStatus,\n\tuseChatError,\n\tuseChatId,\n\tuseChatActions,\n\tuseChatReset,\n\tuseMessageById,\n\tuseMessageIds,\n\tuseMessageCount,\n\tuseVirtualMessages,\n\tuseSelector,\n\tuseDataPart,\n\tuseDataParts,\n\t// Custom hooks\n\tuseAgentStatus,\n\tuseAgentHandoff,\n\tuseRateLimit,\n\tuseSuggestions,\n\tuseLastAssistantMessage,\n\tuseMessageCountByRole,\n\tuseIsStreaming,\n\tuseArtifacts,\n\t// Types\n\ttype StratosMessage,\n\ttype StoreState,\n\ttype ChatActions,\n} from \"./store\";\n","/**\n * Multi-Agent Orchestration System\n *\n * Specialized AI agents for Stratos field service management:\n * - Triage Agent: Routes requests to specialized agents\n * - Customer Agent: Customer management and communication\n * - Scheduling Agent: Job scheduling and dispatch\n * - Financial Agent: Invoices, payments, and estimates\n * - Communication Agent: Email, SMS, and internal messaging\n *\n * Uses @ai-sdk-tools/agents for automatic handoffs and routing\n * Powered by Google Gemini\n */\n\nimport { Agent, handoff, type AgentConfig } from \"@ai-sdk-tools/agents\";\nimport { createGoogleGenerativeAI } from \"@ai-sdk/google\";\nimport { tool } from \"ai\";\nimport { z } from \"zod\";\nimport {\n\tcreateSupabaseMemoryProvider,\n\tDEFAULT_WORKING_MEMORY_TEMPLATE,\n} from \"../memory-provider\";\nimport {\n\t// Memory tools\n\tstoreMemoryTool,\n\tsearchMemoriesTool,\n\tgetEntityMemoriesTool,\n\trecallContextTool,\n\t// Communication learning tools\n\tsearchCommunicationsFullTextTool,\n\tgetCallTranscriptTool,\n\tsearchVoicemailTranscriptsTool,\n\tgetCustomerCommunicationHistoryTool,\n\textractCommunicationInsightsTool,\n\t// External data tools\n\tgetWeatherForLocationTool,\n\tcheckWeatherForJobTool,\n\tgetWeatherAlertsTool,\n\tgetTrafficConditionsTool,\n\tgeocodeAddressTool,\n\tgetPropertyConditionsTool,\n\t// Code search tools\n\tsearchBuildingCodesTool,\n\tgetPermitRequirementsTool,\n\tgetCodeComplianceChecklistTool,\n\t// Proactive learning tools\n\tanalyzeRecentCommunicationsTool,\n\tlearnFromCompletedJobsTool,\n\tbuildCustomerProfileTool,\n\t// Route optimization tools\n\tgetRouteTool,\n\tfindNearbySuppliersTool,\n\t// Inventory & parts tools\n\tsearchInventoryTool,\n\tcheckPartsAvailabilityTool,\n\tgetLowStockAlertsTool,\n\t// Equipment history tools\n\tgetPropertyEquipmentTool,\n\tgetEquipmentServiceHistoryTool,\n\tcheckEquipmentWarrantyTool,\n\t// Technician matching tools\n\tfindTechniciansBySkillsTool,\n\tgetTechnicianWorkloadTool,\n\t// Pricing & estimation tools\n\tsearchPriceBookTool,\n\tcalculateEstimateTool,\n\t// Smart scheduling tools\n\tsuggestTechnicianForJobTool,\n\toptimizeJobOrderTool,\n\t// Customer tools (properly implemented)\n\tsearchCustomersTool,\n\tgetCustomerDetailsTool,\n\tupdateCustomerTool,\n\t// Company overview tool (properly implemented)\n\tgetCompanyOverviewTool,\n\t// Job/Scheduling tools\n\tsearchJobsTool,\n\tcreateAppointmentTool,\n\tgetAvailableSlotsTool,\n\t// Invoice tools\n\tsearchInvoicesTool,\n\tcreateInvoiceTool,\n\t// Communication tools\n\tsendEmailTool,\n\tsendSmsTool,\n\tscheduleReminderTool,\n\t// Web search & research tools\n\twebSearchTool,\n\twebSearchNewsTool,\n\twebSearchTechnicalTool,\n\twebSearchSiteTool,\n} from \"../agent-tools\";\n\n// Initialize Google Gemini provider\nconst googleAI = createGoogleGenerativeAI();\nconst geminiFlash = googleAI(\"gemini-2.0-flash-exp\");\n\n/**\n * Create the multi-agent system for a company\n *\n * @param companyId - The company ID to scope all operations\n * @returns The triage agent that orchestrates all specialized agents\n *\n * @example\n * ```ts\n * import { createAgentSystem } from '@/lib/ai/agents';\n *\n * const triageAgent = createAgentSystem(companyId);\n *\n * // In API route:\n * return triageAgent.toUIMessageStream({\n *   message: userMessage,\n *   context: { userId, companyId }\n * });\n * ```\n */\nexport function createAgentSystem(companyId: string) {\n\tconst memoryProvider = createSupabaseMemoryProvider(companyId);\n\n\t// Shared memory config\n\tconst memoryConfig = {\n\t\tprovider: memoryProvider,\n\t\tworkingMemory: {\n\t\t\tenabled: true,\n\t\t\tscope: \"chat\" as const,\n\t\t\ttemplate: DEFAULT_WORKING_MEMORY_TEMPLATE,\n\t\t},\n\t\thistory: {\n\t\t\tenabled: true,\n\t\t\tlimit: 20,\n\t\t},\n\t\tchats: {\n\t\t\tenabled: true,\n\t\t\tgenerateTitle: true,\n\t\t},\n\t};\n\n\t// Customer Agent - handles customer lookups, updates, and management\n\tconst customerAgent = Agent.create({\n\t\tname: \"customer-agent\",\n\t\tmodel: geminiFlash,\n\t\tinstructions: `You are a Customer Management specialist for a field service company.\n\nYour responsibilities:\n- Look up customer information and history\n- Update customer details (contact info, preferences)\n- View customer's jobs, invoices, and service history\n- Add notes to customer profiles\n- Link communications to customers\n\nAlways be helpful and provide complete information about customers.\nWhen updating customer data, confirm the changes with the user.`,\n\t\thandoffDescription:\n\t\t\t\"Handles customer lookups, profile updates, and customer history\",\n\t\tmatchOn: [\n\t\t\t\"customer\",\n\t\t\t\"client\",\n\t\t\t\"profile\",\n\t\t\t\"contact\",\n\t\t\t/look.*up.*customer/i,\n\t\t\t/customer.*history/i,\n\t\t\t/update.*customer/i,\n\t\t],\n\t\ttools: {\n\t\t\t// Use properly implemented customer tools from agent-tools\n\t\t\tsearchCustomers: searchCustomersTool,\n\t\t\tgetCustomerDetails: getCustomerDetailsTool,\n\t\t\tupdateCustomer: updateCustomerTool,\n\t\t\t// Memory tools for customer-specific memories\n\t\t\tstoreMemory: storeMemoryTool,\n\t\t\tsearchMemories: searchMemoriesTool,\n\t\t\tgetEntityMemories: getEntityMemoriesTool,\n\t\t\t// Communication history tools\n\t\t\tgetCustomerCommunicationHistory: getCustomerCommunicationHistoryTool,\n\t\t\tsearchCommunications: searchCommunicationsFullTextTool,\n\t\t\tgetCallTranscript: getCallTranscriptTool,\n\t\t\t// Profile building\n\t\t\tbuildCustomerProfile: buildCustomerProfileTool,\n\t\t\t// Equipment history tools\n\t\t\tgetPropertyEquipment: getPropertyEquipmentTool,\n\t\t\tgetEquipmentServiceHistory: getEquipmentServiceHistoryTool,\n\t\t\tcheckEquipmentWarranty: checkEquipmentWarrantyTool,\n\t\t},\n\t\tmemory: memoryConfig,\n\t});\n\n\t// Scheduling Agent - handles job scheduling and dispatch\n\tconst schedulingAgent = Agent.create({\n\t\tname: \"scheduling-agent\",\n\t\tmodel: geminiFlash,\n\t\tinstructions: `You are a Scheduling and Dispatch specialist for a field service company.\n\nYour responsibilities:\n- Schedule new jobs and appointments\n- Reschedule existing jobs\n- View technician availability\n- Assign jobs to technicians\n- Manage the dispatch board\n- Handle scheduling conflicts\n\nConsider technician skills, location, and availability when scheduling.\nAlways confirm scheduling changes with the user.`,\n\t\thandoffDescription:\n\t\t\t\"Handles job scheduling, technician dispatch, and calendar management\",\n\t\tmatchOn: [\n\t\t\t\"schedule\",\n\t\t\t\"appointment\",\n\t\t\t\"dispatch\",\n\t\t\t\"availability\",\n\t\t\t\"calendar\",\n\t\t\t/schedule.*job/i,\n\t\t\t/reschedule/i,\n\t\t\t/available.*tech/i,\n\t\t\t/assign.*job/i,\n\t\t],\n\t\ttools: {\n\t\t\t// Use properly implemented scheduling tools\n\t\t\tsearchJobs: searchJobsTool,\n\t\t\tgetAvailableSlots: getAvailableSlotsTool,\n\t\t\tscheduleAppointment: createAppointmentTool,\n\t\t\t// Weather and traffic tools for scheduling decisions\n\t\t\tgetWeather: getWeatherForLocationTool,\n\t\t\tcheckWeatherForJob: checkWeatherForJobTool,\n\t\t\tgetWeatherAlerts: getWeatherAlertsTool,\n\t\t\tgetTrafficConditions: getTrafficConditionsTool,\n\t\t\tgetPropertyConditions: getPropertyConditionsTool,\n\t\t\tgeocodeAddress: geocodeAddressTool,\n\t\t\t// Job analysis for scheduling optimization\n\t\t\tlearnFromCompletedJobs: learnFromCompletedJobsTool,\n\t\t\t// Route optimization tools\n\t\t\tgetRoute: getRouteTool,\n\t\t\tfindNearbySuppliers: findNearbySuppliersTool,\n\t\t\t// Technician matching and workload\n\t\t\tfindTechniciansBySkills: findTechniciansBySkillsTool,\n\t\t\tgetTechnicianWorkload: getTechnicianWorkloadTool,\n\t\t\t// Smart scheduling tools\n\t\t\tsuggestTechnicianForJob: suggestTechnicianForJobTool,\n\t\t\toptimizeJobOrder: optimizeJobOrderTool,\n\t\t},\n\t\tmemory: memoryConfig,\n\t});\n\n\t// Financial Agent - handles invoices, payments, and estimates\n\tconst financialAgent = Agent.create({\n\t\tname: \"financial-agent\",\n\t\tmodel: geminiFlash,\n\t\tinstructions: `You are a Financial Operations specialist for a field service company.\n\nYour responsibilities:\n- Create and send invoices\n- Track payments and payment status\n- Create estimates and quotes\n- View financial reports\n- Handle payment reminders\n- Manage payment plans\n\nAlways be precise with financial amounts and dates.\nConfirm all financial transactions with the user before executing.`,\n\t\thandoffDescription:\n\t\t\t\"Handles invoices, payments, estimates, and financial reporting\",\n\t\tmatchOn: [\n\t\t\t\"invoice\",\n\t\t\t\"payment\",\n\t\t\t\"estimate\",\n\t\t\t\"quote\",\n\t\t\t\"billing\",\n\t\t\t\"financial\",\n\t\t\t\"money\",\n\t\t\t/create.*invoice/i,\n\t\t\t/send.*invoice/i,\n\t\t\t/payment.*status/i,\n\t\t\t/create.*estimate/i,\n\t\t],\n\t\ttools: {\n\t\t\t// Use properly implemented financial tools\n\t\t\tsearchInvoices: searchInvoicesTool,\n\t\t\tcreateInvoice: createInvoiceTool,\n\t\t\t// Pricing & estimation tools\n\t\t\tsearchPriceBook: searchPriceBookTool,\n\t\t\tcalculateEstimate: calculateEstimateTool,\n\t\t\t// Payment reminders via email\n\t\t\tsendPaymentReminder: sendEmailTool,\n\t\t},\n\t\tmemory: memoryConfig,\n\t});\n\n\t// Communication Agent - handles email, SMS, and messaging\n\tconst communicationAgent = Agent.create({\n\t\tname: \"communication-agent\",\n\t\tmodel: geminiFlash,\n\t\tinstructions: `You are a Communication specialist for a field service company.\n\nYour responsibilities:\n- Draft and send emails to customers\n- Send SMS notifications\n- Manage internal team messages\n- Handle appointment reminders\n- Create communication templates\n\nAlways maintain a professional tone appropriate for the business.\nConfirm message content before sending.`,\n\t\thandoffDescription:\n\t\t\t\"Handles email, SMS, and internal communications\",\n\t\tmatchOn: [\n\t\t\t\"email\",\n\t\t\t\"sms\",\n\t\t\t\"text\",\n\t\t\t\"message\",\n\t\t\t\"send\",\n\t\t\t\"notify\",\n\t\t\t\"reminder\",\n\t\t\t/send.*email/i,\n\t\t\t/send.*text/i,\n\t\t\t/notify.*customer/i,\n\t\t\t/draft.*message/i,\n\t\t],\n\t\ttools: {\n\t\t\t// Use properly implemented communication tools\n\t\t\tsendEmail: sendEmailTool,\n\t\t\tsendSMS: sendSmsTool,\n\t\t\tscheduleReminder: scheduleReminderTool,\n\t\t},\n\t\tmemory: memoryConfig,\n\t});\n\n\t// Triage Agent - orchestrates all specialized agents\n\tconst triageAgent = Agent.create({\n\t\tname: \"triage-agent\",\n\t\tmodel: geminiFlash,\n\t\tinstructions: (context) => `You are Stratos AI, an intelligent assistant for a field service management company.\n\nYou orchestrate a team of specialized agents to help with:\n- **Customer Agent**: Customer lookups, profile updates, service history, communication history\n- **Scheduling Agent**: Job scheduling, technician dispatch, weather/traffic conditions\n- **Financial Agent**: Invoices, payments, estimates, billing\n- **Communication Agent**: Email, SMS, notifications, reminders\n\nYour role:\n1. Understand the user's request\n2. Route to the appropriate specialist agent\n3. For general questions or multi-domain requests, handle directly\n4. Provide helpful, accurate responses\n\n**Memory Capabilities**:\n- Use \\`recallContext\\` at conversation start to get relevant background information\n- Use \\`searchMemories\\` to find facts/preferences about customers, jobs, or properties\n- Use \\`storeMemory\\` to remember important facts (customer preferences, service notes, etc.)\n- Use \\`getEntityMemories\\` to retrieve all stored info about a specific customer/job\n\n**Code & Permit Knowledge**:\n- Use \\`searchBuildingCodes\\` to look up code requirements (plumbing, electrical, HVAC, roofing)\n- Use \\`getPermitRequirements\\` to determine if permits are needed for specific work\n- Use \\`getCodeComplianceChecklist\\` to generate checklists for jobs\n\n**Learning & Insights**:\n- Use \\`analyzeRecentCommunications\\` to extract insights from customer interactions\n- Use \\`learnFromCompletedJobs\\` to improve scheduling recommendations\n- Use \\`extractCommunicationInsights\\` to find customer preferences and issues\n- Use \\`searchVoicemails\\` to search voicemail transcriptions\n\n**Web Search & Research**:\n- Use \\`webSearch\\` to find answers to general questions, look up information, or research topics\n- Use \\`webSearchNews\\` to find recent industry news, regulation changes, or current events\n- Use \\`webSearchTechnical\\` to find technical documentation, guides, and troubleshooting help\n- Use \\`webSearchSite\\` to search within specific websites (e.g., manufacturer docs, gov sites)\n\nAlways be friendly, professional, and efficient.\nIf a request spans multiple domains, coordinate between agents.\nProactively use memory tools to provide personalized, context-aware assistance.\nUse code search tools to provide accurate technical guidance to technicians.\n\nCurrent context: ${JSON.stringify(context || {})}`,\n\t\thandoffs: [\n\t\t\thandoff(customerAgent, {\n\t\t\t\tonHandoff: async (ctx) => {\n\t\t\t\t\tconsole.log(\"Handing off to customer agent\", ctx);\n\t\t\t\t},\n\t\t\t}),\n\t\t\thandoff(schedulingAgent, {\n\t\t\t\tonHandoff: async (ctx) => {\n\t\t\t\t\tconsole.log(\"Handing off to scheduling agent\", ctx);\n\t\t\t\t},\n\t\t\t}),\n\t\t\thandoff(financialAgent, {\n\t\t\t\tonHandoff: async (ctx) => {\n\t\t\t\t\tconsole.log(\"Handing off to financial agent\", ctx);\n\t\t\t\t},\n\t\t\t}),\n\t\t\thandoff(communicationAgent, {\n\t\t\t\tonHandoff: async (ctx) => {\n\t\t\t\t\tconsole.log(\"Handing off to communication agent\", ctx);\n\t\t\t\t},\n\t\t\t}),\n\t\t],\n\t\ttools: {\n\t\t\t// Use properly implemented company overview tool\n\t\t\tgetCompanyOverview: getCompanyOverviewTool,\n\t\t\t// Memory tools for long-term semantic memory\n\t\t\tstoreMemory: storeMemoryTool,\n\t\t\tsearchMemories: searchMemoriesTool,\n\t\t\tgetEntityMemories: getEntityMemoriesTool,\n\t\t\trecallContext: recallContextTool,\n\t\t\t// Code search tools for technical guidance\n\t\t\tsearchBuildingCodes: searchBuildingCodesTool,\n\t\t\tgetPermitRequirements: getPermitRequirementsTool,\n\t\t\tgetCodeComplianceChecklist: getCodeComplianceChecklistTool,\n\t\t\t// Proactive learning tools\n\t\t\tanalyzeRecentCommunications: analyzeRecentCommunicationsTool,\n\t\t\tlearnFromCompletedJobs: learnFromCompletedJobsTool,\n\t\t\t// Communication insight extraction\n\t\t\textractCommunicationInsights: extractCommunicationInsightsTool,\n\t\t\tsearchVoicemails: searchVoicemailTranscriptsTool,\n\t\t\t// Inventory & parts tools\n\t\t\tsearchInventory: searchInventoryTool,\n\t\t\tcheckPartsAvailability: checkPartsAvailabilityTool,\n\t\t\tgetLowStockAlerts: getLowStockAlertsTool,\n\t\t\t// Web search & research tools\n\t\t\twebSearch: webSearchTool,\n\t\t\twebSearchNews: webSearchNewsTool,\n\t\t\twebSearchTechnical: webSearchTechnicalTool,\n\t\t\twebSearchSite: webSearchSiteTool,\n\t\t},\n\t\tmemory: memoryConfig,\n\t\tmaxTurns: 10,\n\t\ttemperature: 0.7,\n\t\tonEvent: (event) => {\n\t\t\t// Log agent events for debugging\n\t\t\tif (process.env.NODE_ENV === \"development\") {\n\t\t\t\tconsole.log(\"[Agent Event]\", event);\n\t\t\t}\n\t\t},\n\t});\n\n\treturn triageAgent;\n}\n\n// Export individual agent factories for direct use\nexport { Agent };\nexport type { AgentConfig };\n","/**\n * AI Artifacts System\n *\n * Type-safe streaming artifacts from AI tools to React components\n * Uses @ai-sdk-tools/artifacts for structured data streaming\n */\n\nimport { artifact, getWriter } from \"@ai-sdk-tools/artifacts\";\nimport { z } from \"zod\";\n\n/**\n * Stratos Artifact Schemas\n *\n * Define the structure of data that can be streamed from AI tools\n */\n\n// Customer card artifact\nexport const customerCardSchema = z.object({\n\tid: z.string(),\n\tname: z.string(),\n\temail: z.string().email().optional(),\n\tphone: z.string().optional(),\n\taddress: z.string().optional(),\n\ttotalJobs: z.number().default(0),\n\ttotalRevenue: z.number().default(0),\n\tlastServiceDate: z.string().optional(),\n\tstatus: z.enum([\"active\", \"inactive\", \"lead\"]).default(\"active\"),\n});\n\n// Job summary artifact\nexport const jobSummarySchema = z.object({\n\tid: z.string(),\n\ttitle: z.string(),\n\tstatus: z.enum([\n\t\t\"scheduled\",\n\t\t\"in_progress\",\n\t\t\"completed\",\n\t\t\"cancelled\",\n\t\t\"on_hold\",\n\t]),\n\tcustomerId: z.string(),\n\tcustomerName: z.string(),\n\tscheduledDate: z.string().optional(),\n\tscheduledTime: z.string().optional(),\n\tassignedTechnician: z.string().optional(),\n\testimatedDuration: z.number().optional(),\n\taddress: z.string().optional(),\n});\n\n// Invoice artifact\nexport const invoiceArtifactSchema = z.object({\n\tid: z.string(),\n\tinvoiceNumber: z.string(),\n\tcustomerId: z.string(),\n\tcustomerName: z.string(),\n\tstatus: z.enum([\"draft\", \"sent\", \"viewed\", \"paid\", \"overdue\", \"cancelled\"]),\n\tsubtotal: z.number(),\n\ttax: z.number(),\n\ttotal: z.number(),\n\tdueDate: z.string().optional(),\n\tlineItems: z.array(\n\t\tz.object({\n\t\t\tdescription: z.string(),\n\t\t\tquantity: z.number(),\n\t\t\tunitPrice: z.number(),\n\t\t\ttotal: z.number(),\n\t\t})\n\t),\n});\n\n// Schedule view artifact\nexport const scheduleViewSchema = z.object({\n\tdate: z.string(),\n\tjobs: z.array(\n\t\tz.object({\n\t\t\tid: z.string(),\n\t\t\ttitle: z.string(),\n\t\t\ttime: z.string(),\n\t\t\tduration: z.number(),\n\t\t\ttechnician: z.string(),\n\t\t\tcustomer: z.string(),\n\t\t\taddress: z.string().optional(),\n\t\t\tstatus: z.enum([\"scheduled\", \"in_progress\", \"completed\"]),\n\t\t})\n\t),\n\tavailableSlots: z.array(\n\t\tz.object({\n\t\t\ttime: z.string(),\n\t\t\tduration: z.number(),\n\t\t\ttechnicians: z.array(z.string()),\n\t\t})\n\t),\n});\n\n// Chart data artifact\nexport const chartDataSchema = z.object({\n\ttitle: z.string(),\n\ttype: z.enum([\"bar\", \"line\", \"pie\", \"area\"]),\n\tdata: z.array(\n\t\tz.object({\n\t\t\tlabel: z.string(),\n\t\t\tvalue: z.number(),\n\t\t\tcolor: z.string().optional(),\n\t\t})\n\t),\n\txAxisLabel: z.string().optional(),\n\tyAxisLabel: z.string().optional(),\n});\n\n// Table data artifact\nexport const tableDataSchema = z.object({\n\ttitle: z.string(),\n\tcolumns: z.array(\n\t\tz.object({\n\t\t\tkey: z.string(),\n\t\t\tlabel: z.string(),\n\t\t\ttype: z.enum([\"string\", \"number\", \"date\", \"currency\", \"badge\"]).default(\"string\"),\n\t\t})\n\t),\n\trows: z.array(z.record(z.unknown())),\n\ttotalRows: z.number().optional(),\n});\n\n// Estimate artifact\nexport const estimateArtifactSchema = z.object({\n\tid: z.string(),\n\testimateNumber: z.string(),\n\tcustomerId: z.string(),\n\tcustomerName: z.string(),\n\tstatus: z.enum([\"draft\", \"sent\", \"accepted\", \"declined\", \"expired\"]),\n\tsubtotal: z.number(),\n\ttax: z.number(),\n\ttotal: z.number(),\n\tvalidUntil: z.string().optional(),\n\tlineItems: z.array(\n\t\tz.object({\n\t\t\tdescription: z.string(),\n\t\t\tquantity: z.number(),\n\t\t\tunitPrice: z.number(),\n\t\t\ttotal: z.number(),\n\t\t})\n\t),\n});\n\n/**\n * Artifact type definitions\n */\nexport type CustomerCardArtifact = z.infer<typeof customerCardSchema>;\nexport type JobSummaryArtifact = z.infer<typeof jobSummarySchema>;\nexport type InvoiceArtifact = z.infer<typeof invoiceArtifactSchema>;\nexport type ScheduleViewArtifact = z.infer<typeof scheduleViewSchema>;\nexport type ChartDataArtifact = z.infer<typeof chartDataSchema>;\nexport type TableDataArtifact = z.infer<typeof tableDataSchema>;\nexport type EstimateArtifact = z.infer<typeof estimateArtifactSchema>;\n\n/**\n * Create artifact tools for streaming structured data\n */\n\nexport const customerCardArtifact = artifact({\n\tid: \"customer-card\",\n\tdisplayName: \"Customer Card\",\n\tdescription: \"Display a customer profile card with key information\",\n\tschema: customerCardSchema,\n});\n\nexport const jobSummaryArtifact = artifact({\n\tid: \"job-summary\",\n\tdisplayName: \"Job Summary\",\n\tdescription: \"Display a job summary card\",\n\tschema: jobSummarySchema,\n});\n\nexport const invoiceArtifact = artifact({\n\tid: \"invoice\",\n\tdisplayName: \"Invoice\",\n\tdescription: \"Display an invoice with line items\",\n\tschema: invoiceArtifactSchema,\n});\n\nexport const scheduleViewArtifact = artifact({\n\tid: \"schedule-view\",\n\tdisplayName: \"Schedule View\",\n\tdescription: \"Display a day's schedule with jobs and availability\",\n\tschema: scheduleViewSchema,\n});\n\nexport const chartDataArtifact = artifact({\n\tid: \"chart\",\n\tdisplayName: \"Chart\",\n\tdescription: \"Display a data visualization chart\",\n\tschema: chartDataSchema,\n});\n\nexport const tableDataArtifact = artifact({\n\tid: \"table\",\n\tdisplayName: \"Data Table\",\n\tdescription: \"Display tabular data with columns and rows\",\n\tschema: tableDataSchema,\n});\n\nexport const estimateArtifact = artifact({\n\tid: \"estimate\",\n\tdisplayName: \"Estimate\",\n\tdescription: \"Display an estimate/quote with line items\",\n\tschema: estimateArtifactSchema,\n});\n\n/**\n * All Stratos artifacts bundled together\n */\nexport const stratosArtifacts = {\n\tcustomerCard: customerCardArtifact,\n\tjobSummary: jobSummaryArtifact,\n\tinvoice: invoiceArtifact,\n\tscheduleView: scheduleViewArtifact,\n\tchart: chartDataArtifact,\n\ttable: tableDataArtifact,\n\testimate: estimateArtifact,\n};\n\n/**\n * Artifact IDs for reference\n */\nexport const ARTIFACT_IDS = {\n\tCUSTOMER_CARD: \"customer-card\",\n\tJOB_SUMMARY: \"job-summary\",\n\tINVOICE: \"invoice\",\n\tSCHEDULE_VIEW: \"schedule-view\",\n\tCHART: \"chart\",\n\tTABLE: \"table\",\n\tESTIMATE: \"estimate\",\n} as const;\n\nexport type ArtifactId = (typeof ARTIFACT_IDS)[keyof typeof ARTIFACT_IDS];\n\n// Re-export getWriter for use in tools\nexport { getWriter };\n","import { generateId as generateIdAi } from \"ai\";\nimport type { z } from \"zod\";\n\nexport function generateId(): string {\n  return `artifact_${Date.now()}_${generateIdAi()}`;\n}\n\nexport function getDefaults<T>(schema: z.ZodSchema<T>): Partial<T> {\n  try {\n    return schema.parse({});\n  } catch {\n    return {};\n  }\n}\n","import type { UIMessageStreamWriter } from \"ai\";\nimport type { z } from \"zod\";\nimport { StreamingArtifact } from \"./streaming\";\nimport type { ArtifactConfig, ArtifactData } from \"./types\";\nimport { generateId, getDefaults } from \"./utils\";\n\nexport function artifact<T>(id: string, schema: z.ZodSchema<T>) {\n  const config: ArtifactConfig<T> = { id, schema };\n\n  return {\n    id,\n    schema,\n\n    create(data: Partial<T> = {}): ArtifactData<T> {\n      const defaults = getDefaults(schema);\n      const validated = schema.parse({ ...defaults, ...data });\n\n      return {\n        id: generateId(),\n        type: id,\n        status: \"idle\",\n        payload: validated,\n        version: 1,\n        createdAt: Date.now(),\n        updatedAt: Date.now(),\n      };\n    },\n\n    stream(\n      data: Partial<T>,\n      writer: UIMessageStreamWriter,\n    ): StreamingArtifact<T> {\n      const instance = this.create(data);\n      instance.status = \"loading\";\n      return new StreamingArtifact(config, instance, writer);\n    },\n\n    validate(data: unknown): T {\n      return schema.parse(data);\n    },\n\n    isValid(data: unknown): data is T {\n      try {\n        schema.parse(data);\n        return true;\n      } catch {\n        return false;\n      }\n    },\n  };\n}\n","import {\n  AppRouteRouteModule,\n  type AppRouteRouteHandlerContext,\n  type AppRouteRouteModuleOptions,\n} from '../../server/route-modules/app-route/module.compiled'\nimport { RouteKind } from '../../server/route-kind'\nimport { patchFetch as _patchFetch } from '../../server/lib/patch-fetch'\nimport type { IncomingMessage, ServerResponse } from 'node:http'\nimport { addRequestMeta, getRequestMeta } from '../../server/request-meta'\nimport { getTracer, type Span, SpanKind } from '../../server/lib/trace/tracer'\nimport { setReferenceManifestsSingleton } from '../../server/app-render/encryption-utils'\nimport { createServerModuleMap } from '../../server/app-render/action-utils'\nimport { normalizeAppPath } from '../../shared/lib/router/utils/app-paths'\nimport { NodeNextRequest, NodeNextResponse } from '../../server/base-http/node'\nimport {\n  NextRequestAdapter,\n  signalFromNodeResponse,\n} from '../../server/web/spec-extension/adapters/next-request'\nimport { BaseServerSpan } from '../../server/lib/trace/constants'\nimport { getRevalidateReason } from '../../server/instrumentation/utils'\nimport { sendResponse } from '../../server/send-response'\nimport {\n  fromNodeOutgoingHttpHeaders,\n  toNodeOutgoingHttpHeaders,\n} from '../../server/web/utils'\nimport { getCacheControlHeader } from '../../server/lib/cache-control'\nimport { INFINITE_CACHE, NEXT_CACHE_TAGS_HEADER } from '../../lib/constants'\nimport { NoFallbackError } from '../../shared/lib/no-fallback-error.external'\nimport {\n  CachedRouteKind,\n  type ResponseCacheEntry,\n  type ResponseGenerator,\n} from '../../server/response-cache'\n\nimport * as userland from 'VAR_USERLAND'\n\n// These are injected by the loader afterwards. This is injected as a variable\n// instead of a replacement because this could also be `undefined` instead of\n// an empty string.\ndeclare const nextConfigOutput: AppRouteRouteModuleOptions['nextConfigOutput']\n\n// We inject the nextConfigOutput here so that we can use them in the route\n// module.\n// INJECT:nextConfigOutput\n\nconst routeModule = new AppRouteRouteModule({\n  definition: {\n    kind: RouteKind.APP_ROUTE,\n    page: 'VAR_DEFINITION_PAGE',\n    pathname: 'VAR_DEFINITION_PATHNAME',\n    filename: 'VAR_DEFINITION_FILENAME',\n    bundlePath: 'VAR_DEFINITION_BUNDLE_PATH',\n  },\n  distDir: process.env.__NEXT_RELATIVE_DIST_DIR || '',\n  relativeProjectDir: process.env.__NEXT_RELATIVE_PROJECT_DIR || '',\n  resolvedPagePath: 'VAR_RESOLVED_PAGE_PATH',\n  nextConfigOutput,\n  userland,\n})\n\n// Pull out the exports that we need to expose from the module. This should\n// be eliminated when we've moved the other routes to the new format. These\n// are used to hook into the route.\nconst { workAsyncStorage, workUnitAsyncStorage, serverHooks } = routeModule\n\nfunction patchFetch() {\n  return _patchFetch({\n    workAsyncStorage,\n    workUnitAsyncStorage,\n  })\n}\n\nexport {\n  routeModule,\n  workAsyncStorage,\n  workUnitAsyncStorage,\n  serverHooks,\n  patchFetch,\n}\n\nexport async function handler(\n  req: IncomingMessage,\n  res: ServerResponse,\n  ctx: {\n    waitUntil: (prom: Promise<void>) => void\n  }\n) {\n  if (routeModule.isDev) {\n    addRequestMeta(req, 'devRequestTimingInternalsEnd', process.hrtime.bigint())\n  }\n  let srcPage = 'VAR_DEFINITION_PAGE'\n\n  // turbopack doesn't normalize `/index` in the page name\n  // so we need to to process dynamic routes properly\n  // TODO: fix turbopack providing differing value from webpack\n  if (process.env.TURBOPACK) {\n    srcPage = srcPage.replace(/\\/index$/, '') || '/'\n  } else if (srcPage === '/index') {\n    // we always normalize /index specifically\n    srcPage = '/'\n  }\n  const multiZoneDraftMode = process.env\n    .__NEXT_MULTI_ZONE_DRAFT_MODE as any as boolean\n\n  const prepareResult = await routeModule.prepare(req, res, {\n    srcPage,\n    multiZoneDraftMode,\n  })\n\n  if (!prepareResult) {\n    res.statusCode = 400\n    res.end('Bad Request')\n    ctx.waitUntil?.(Promise.resolve())\n    return null\n  }\n\n  const {\n    buildId,\n    params,\n    nextConfig,\n    parsedUrl,\n    isDraftMode,\n    prerenderManifest,\n    routerServerContext,\n    isOnDemandRevalidate,\n    revalidateOnlyGenerated,\n    resolvedPathname,\n    clientReferenceManifest,\n    serverActionsManifest,\n  } = prepareResult\n\n  const normalizedSrcPage = normalizeAppPath(srcPage)\n\n  let isIsr = Boolean(\n    prerenderManifest.dynamicRoutes[normalizedSrcPage] ||\n      prerenderManifest.routes[resolvedPathname]\n  )\n\n  const render404 = async () => {\n    // TODO: should route-module itself handle rendering the 404\n    if (routerServerContext?.render404) {\n      await routerServerContext.render404(req, res, parsedUrl, false)\n    } else {\n      res.end('This page could not be found')\n    }\n    return null\n  }\n\n  if (isIsr && !isDraftMode) {\n    const isPrerendered = Boolean(prerenderManifest.routes[resolvedPathname])\n    const prerenderInfo = prerenderManifest.dynamicRoutes[normalizedSrcPage]\n\n    if (prerenderInfo) {\n      if (prerenderInfo.fallback === false && !isPrerendered) {\n        if (nextConfig.experimental.adapterPath) {\n          return await render404()\n        }\n        throw new NoFallbackError()\n      }\n    }\n  }\n\n  let cacheKey: string | null = null\n\n  if (isIsr && !routeModule.isDev && !isDraftMode) {\n    cacheKey = resolvedPathname\n    // ensure /index and / is normalized to one key\n    cacheKey = cacheKey === '/index' ? '/' : cacheKey\n  }\n\n  const supportsDynamicResponse: boolean =\n    // If we're in development, we always support dynamic HTML\n    routeModule.isDev === true ||\n    // If this is not SSG or does not have static paths, then it supports\n    // dynamic HTML.\n    !isIsr\n\n  // This is a revalidation request if the request is for a static\n  // page and it is not being resumed from a postponed render and\n  // it is not a dynamic RSC request then it is a revalidation\n  // request.\n  const isStaticGeneration = isIsr && !supportsDynamicResponse\n\n  // Before rendering (which initializes component tree modules), we have to\n  // set the reference manifests to our global store so Server Action's\n  // encryption util can access to them at the top level of the page module.\n  if (serverActionsManifest && clientReferenceManifest) {\n    setReferenceManifestsSingleton({\n      page: srcPage,\n      clientReferenceManifest,\n      serverActionsManifest,\n      serverModuleMap: createServerModuleMap({\n        serverActionsManifest,\n      }),\n    })\n  }\n\n  const method = req.method || 'GET'\n  const tracer = getTracer()\n  const activeSpan = tracer.getActiveScopeSpan()\n\n  const context: AppRouteRouteHandlerContext = {\n    params,\n    prerenderManifest,\n    renderOpts: {\n      experimental: {\n        authInterrupts: Boolean(nextConfig.experimental.authInterrupts),\n      },\n      cacheComponents: Boolean(nextConfig.cacheComponents),\n      supportsDynamicResponse,\n      incrementalCache: getRequestMeta(req, 'incrementalCache'),\n      cacheLifeProfiles: nextConfig.cacheLife,\n      waitUntil: ctx.waitUntil,\n      onClose: (cb) => {\n        res.on('close', cb)\n      },\n      onAfterTaskError: undefined,\n      onInstrumentationRequestError: (error, _request, errorContext) =>\n        routeModule.onRequestError(\n          req,\n          error,\n          errorContext,\n          routerServerContext\n        ),\n    },\n    sharedContext: {\n      buildId,\n    },\n  }\n  const nodeNextReq = new NodeNextRequest(req)\n  const nodeNextRes = new NodeNextResponse(res)\n\n  const nextReq = NextRequestAdapter.fromNodeNextRequest(\n    nodeNextReq,\n    signalFromNodeResponse(res)\n  )\n\n  try {\n    const invokeRouteModule = async (span?: Span) => {\n      return routeModule.handle(nextReq, context).finally(() => {\n        if (!span) return\n\n        span.setAttributes({\n          'http.status_code': res.statusCode,\n          'next.rsc': false,\n        })\n\n        const rootSpanAttributes = tracer.getRootSpanAttributes()\n        // We were unable to get attributes, probably OTEL is not enabled\n        if (!rootSpanAttributes) {\n          return\n        }\n\n        if (\n          rootSpanAttributes.get('next.span_type') !==\n          BaseServerSpan.handleRequest\n        ) {\n          console.warn(\n            `Unexpected root span type '${rootSpanAttributes.get(\n              'next.span_type'\n            )}'. Please report this Next.js issue https://github.com/vercel/next.js`\n          )\n          return\n        }\n\n        const route = rootSpanAttributes.get('next.route')\n        if (route) {\n          const name = `${method} ${route}`\n\n          span.setAttributes({\n            'next.route': route,\n            'http.route': route,\n            'next.span_name': name,\n          })\n          span.updateName(name)\n        } else {\n          span.updateName(`${method} ${srcPage}`)\n        }\n      })\n    }\n    const isMinimalMode = Boolean(\n      process.env.MINIMAL_MODE || getRequestMeta(req, 'minimalMode')\n    )\n\n    const handleResponse = async (currentSpan?: Span) => {\n      const responseGenerator: ResponseGenerator = async ({\n        previousCacheEntry,\n      }) => {\n        try {\n          if (\n            !isMinimalMode &&\n            isOnDemandRevalidate &&\n            revalidateOnlyGenerated &&\n            !previousCacheEntry\n          ) {\n            res.statusCode = 404\n            // on-demand revalidate always sets this header\n            res.setHeader('x-nextjs-cache', 'REVALIDATED')\n            res.end('This page could not be found')\n            return null\n          }\n\n          const response = await invokeRouteModule(currentSpan)\n\n          ;(req as any).fetchMetrics = (context.renderOpts as any).fetchMetrics\n          let pendingWaitUntil = context.renderOpts.pendingWaitUntil\n\n          // Attempt using provided waitUntil if available\n          // if it's not we fallback to sendResponse's handling\n          if (pendingWaitUntil) {\n            if (ctx.waitUntil) {\n              ctx.waitUntil(pendingWaitUntil)\n              pendingWaitUntil = undefined\n            }\n          }\n          const cacheTags = context.renderOpts.collectedTags\n\n          // If the request is for a static response, we can cache it so long\n          // as it's not edge.\n          if (isIsr) {\n            const blob = await response.blob()\n\n            // Copy the headers from the response.\n            const headers = toNodeOutgoingHttpHeaders(response.headers)\n\n            if (cacheTags) {\n              headers[NEXT_CACHE_TAGS_HEADER] = cacheTags\n            }\n\n            if (!headers['content-type'] && blob.type) {\n              headers['content-type'] = blob.type\n            }\n\n            const revalidate =\n              typeof context.renderOpts.collectedRevalidate === 'undefined' ||\n              context.renderOpts.collectedRevalidate >= INFINITE_CACHE\n                ? false\n                : context.renderOpts.collectedRevalidate\n\n            const expire =\n              typeof context.renderOpts.collectedExpire === 'undefined' ||\n              context.renderOpts.collectedExpire >= INFINITE_CACHE\n                ? undefined\n                : context.renderOpts.collectedExpire\n\n            // Create the cache entry for the response.\n            const cacheEntry: ResponseCacheEntry = {\n              value: {\n                kind: CachedRouteKind.APP_ROUTE,\n                status: response.status,\n                body: Buffer.from(await blob.arrayBuffer()),\n                headers,\n              },\n              cacheControl: { revalidate, expire },\n            }\n\n            return cacheEntry\n          } else {\n            // send response without caching if not ISR\n            await sendResponse(\n              nodeNextReq,\n              nodeNextRes,\n              response,\n              context.renderOpts.pendingWaitUntil\n            )\n            return null\n          }\n        } catch (err) {\n          // if this is a background revalidate we need to report\n          // the request error here as it won't be bubbled\n          if (previousCacheEntry?.isStale) {\n            await routeModule.onRequestError(\n              req,\n              err,\n              {\n                routerKind: 'App Router',\n                routePath: srcPage,\n                routeType: 'route',\n                revalidateReason: getRevalidateReason({\n                  isStaticGeneration,\n                  isOnDemandRevalidate,\n                }),\n              },\n              routerServerContext\n            )\n          }\n          throw err\n        }\n      }\n\n      const cacheEntry = await routeModule.handleResponse({\n        req,\n        nextConfig,\n        cacheKey,\n        routeKind: RouteKind.APP_ROUTE,\n        isFallback: false,\n        prerenderManifest,\n        isRoutePPREnabled: false,\n        isOnDemandRevalidate,\n        revalidateOnlyGenerated,\n        responseGenerator,\n        waitUntil: ctx.waitUntil,\n        isMinimalMode,\n      })\n\n      // we don't create a cacheEntry for ISR\n      if (!isIsr) {\n        return null\n      }\n\n      if (cacheEntry?.value?.kind !== CachedRouteKind.APP_ROUTE) {\n        throw new Error(\n          `Invariant: app-route received invalid cache entry ${cacheEntry?.value?.kind}`\n        )\n      }\n\n      if (!isMinimalMode) {\n        res.setHeader(\n          'x-nextjs-cache',\n          isOnDemandRevalidate\n            ? 'REVALIDATED'\n            : cacheEntry.isMiss\n              ? 'MISS'\n              : cacheEntry.isStale\n                ? 'STALE'\n                : 'HIT'\n        )\n      }\n\n      // Draft mode should never be cached\n      if (isDraftMode) {\n        res.setHeader(\n          'Cache-Control',\n          'private, no-cache, no-store, max-age=0, must-revalidate'\n        )\n      }\n\n      const headers = fromNodeOutgoingHttpHeaders(cacheEntry.value.headers)\n\n      if (!(isMinimalMode && isIsr)) {\n        headers.delete(NEXT_CACHE_TAGS_HEADER)\n      }\n\n      // If cache control is already set on the response we don't\n      // override it to allow users to customize it via next.config\n      if (\n        cacheEntry.cacheControl &&\n        !res.getHeader('Cache-Control') &&\n        !headers.get('Cache-Control')\n      ) {\n        headers.set(\n          'Cache-Control',\n          getCacheControlHeader(cacheEntry.cacheControl)\n        )\n      }\n\n      await sendResponse(\n        nodeNextReq,\n        nodeNextRes,\n        // @ts-expect-error - Argument of type 'Buffer<ArrayBufferLike>' is not assignable to parameter of type 'BodyInit | null | undefined'.\n        new Response(cacheEntry.value.body, {\n          headers,\n          status: cacheEntry.value.status || 200,\n        })\n      )\n      return null\n    }\n\n    // TODO: activeSpan code path is for when wrapped by\n    // next-server can be removed when this is no longer used\n    if (activeSpan) {\n      await handleResponse(activeSpan)\n    } else {\n      await tracer.withPropagatedContext(req.headers, () =>\n        tracer.trace(\n          BaseServerSpan.handleRequest,\n          {\n            spanName: `${method} ${srcPage}`,\n            kind: SpanKind.SERVER,\n            attributes: {\n              'http.method': method,\n              'http.target': req.url,\n            },\n          },\n          handleResponse\n        )\n      )\n    }\n  } catch (err) {\n    if (!(err instanceof NoFallbackError)) {\n      await routeModule.onRequestError(req, err, {\n        routerKind: 'App Router',\n        routePath: normalizedSrcPage,\n        routeType: 'route',\n        revalidateReason: getRevalidateReason({\n          isStaticGeneration,\n          isOnDemandRevalidate,\n        }),\n      })\n    }\n\n    // rethrow so that we can handle serving error page\n\n    // If this is during static generation, throw the error again.\n    if (isIsr) throw err\n\n    // Otherwise, send a 500 response.\n    await sendResponse(\n      nodeNextReq,\n      nodeNextRes,\n      new Response(null, { status: 500 })\n    )\n    return null\n  }\n}\n","/**\n * AI Action Reverter Service - Rubrik-style selective rollback for AI actions\n * Based on Rubrik Agent Rewind patterns for granular recovery\n */\n\nimport { createServiceSupabaseClient } from \"@/lib/supabase/service-client\";\nimport { recordReversal } from \"./audit-trail\";\nimport crypto from \"crypto\";\n\nexport type SnapshotType = \"full\" | \"partial\" | \"field_level\";\nexport type RevertStatus = \"pending\" | \"in_progress\" | \"completed\" | \"failed\" | \"partial\";\n\nexport interface ActionSnapshot {\n  entityType: string;\n  entityId: string;\n  beforeState: Record<string, unknown>;\n  afterState: Record<string, unknown>;\n  changedFields: string[];\n  operation: \"create\" | \"update\" | \"delete\";\n}\n\nexport interface RevertResult {\n  success: boolean;\n  revertedEntities: Array<{\n    entityType: string;\n    entityId: string;\n    revertedFields: string[];\n  }>;\n  failedEntities: Array<{\n    entityType: string;\n    entityId: string;\n    error: string;\n  }>;\n  reversalId?: string;\n}\n\n/**\n * Create an action snapshot before AI performs an action\n */\nexport async function createActionSnapshot(\n  companyId: string,\n  messageId: string,\n  chatId: string,\n  snapshot: ActionSnapshot\n): Promise<string> {\n  const supabase = createServiceSupabaseClient();\n  const snapshotId = crypto.randomUUID();\n\n  const { error } = await supabase.from(\"ai_action_snapshots\").insert({\n    id: snapshotId,\n    company_id: companyId,\n    message_id: messageId,\n    chat_id: chatId,\n    entity_type: snapshot.entityType,\n    entity_id: snapshot.entityId,\n    before_state: snapshot.beforeState,\n    after_state: snapshot.afterState,\n    changed_fields: snapshot.changedFields,\n    operation: snapshot.operation,\n    snapshot_type: snapshot.changedFields.length > 0 ? \"field_level\" : \"full\",\n    is_reverted: false,\n    created_at: new Date().toISOString(),\n  });\n\n  if (error) {\n    console.error(\"Failed to create action snapshot:\", error);\n    throw error;\n  }\n\n  return snapshotId;\n}\n\n/**\n * Create bulk snapshots for multiple entities (e.g., bulk operations)\n */\nexport async function createBulkSnapshots(\n  companyId: string,\n  messageId: string,\n  chatId: string,\n  snapshots: ActionSnapshot[]\n): Promise<string[]> {\n  const supabase = createServiceSupabaseClient();\n  const snapshotIds: string[] = [];\n\n  const records = snapshots.map((snapshot) => {\n    const id = crypto.randomUUID();\n    snapshotIds.push(id);\n    return {\n      id,\n      company_id: companyId,\n      message_id: messageId,\n      chat_id: chatId,\n      entity_type: snapshot.entityType,\n      entity_id: snapshot.entityId,\n      before_state: snapshot.beforeState,\n      after_state: snapshot.afterState,\n      changed_fields: snapshot.changedFields,\n      operation: snapshot.operation,\n      snapshot_type: \"full\" as const,\n      is_reverted: false,\n      created_at: new Date().toISOString(),\n    };\n  });\n\n  const { error } = await supabase.from(\"ai_action_snapshots\").insert(records);\n\n  if (error) {\n    console.error(\"Failed to create bulk snapshots:\", error);\n    throw error;\n  }\n\n  return snapshotIds;\n}\n\n/**\n * Get all snapshots for a specific message (for undo capability)\n */\nexport async function getMessageSnapshots(\n  companyId: string,\n  messageId: string\n): Promise<\n  Array<{\n    id: string;\n    entityType: string;\n    entityId: string;\n    operation: string;\n    changedFields: string[];\n    isReverted: boolean;\n    createdAt: string;\n  }>\n> {\n  const supabase = createServiceSupabaseClient();\n\n  const { data, error } = await supabase\n    .from(\"ai_action_snapshots\")\n    .select(\"id, entity_type, entity_id, operation, changed_fields, is_reverted, created_at\")\n    .eq(\"company_id\", companyId)\n    .eq(\"message_id\", messageId)\n    .order(\"created_at\", { ascending: false });\n\n  if (error) {\n    console.error(\"Failed to get message snapshots:\", error);\n    return [];\n  }\n\n  return (data || []).map((s) => ({\n    id: s.id,\n    entityType: s.entity_type,\n    entityId: s.entity_id,\n    operation: s.operation,\n    changedFields: s.changed_fields || [],\n    isReverted: s.is_reverted,\n    createdAt: s.created_at,\n  }));\n}\n\n/**\n * Get revertable actions for a chat session\n */\nexport async function getRevertableActions(\n  companyId: string,\n  chatId: string,\n  options?: { limit?: number; includeReverted?: boolean }\n): Promise<\n  Array<{\n    id: string;\n    messageId: string;\n    entityType: string;\n    entityId: string;\n    operation: string;\n    changedFields: string[];\n    isReverted: boolean;\n    createdAt: string;\n  }>\n> {\n  const supabase = createServiceSupabaseClient();\n  const limit = options?.limit || 50;\n\n  let query = supabase\n    .from(\"ai_action_snapshots\")\n    .select(\n      \"id, message_id, entity_type, entity_id, operation, changed_fields, is_reverted, created_at\"\n    )\n    .eq(\"company_id\", companyId)\n    .eq(\"chat_id\", chatId)\n    .order(\"created_at\", { ascending: false })\n    .limit(limit);\n\n  if (!options?.includeReverted) {\n    query = query.eq(\"is_reverted\", false);\n  }\n\n  const { data, error } = await query;\n\n  if (error) {\n    console.error(\"Failed to get revertable actions:\", error);\n    return [];\n  }\n\n  return (data || []).map((s) => ({\n    id: s.id,\n    messageId: s.message_id,\n    entityType: s.entity_type,\n    entityId: s.entity_id,\n    operation: s.operation,\n    changedFields: s.changed_fields || [],\n    isReverted: s.is_reverted,\n    createdAt: s.created_at,\n  }));\n}\n\n/**\n * Revert a single snapshot to its before state\n */\nexport async function revertSnapshot(\n  companyId: string,\n  snapshotId: string,\n  userId: string,\n  reason: string,\n  options?: { partialFields?: string[] }\n): Promise<RevertResult> {\n  const supabase = createServiceSupabaseClient();\n\n  // Get the snapshot\n  const { data: snapshot, error: fetchError } = await supabase\n    .from(\"ai_action_snapshots\")\n    .select(\"*\")\n    .eq(\"id\", snapshotId)\n    .eq(\"company_id\", companyId)\n    .single();\n\n  if (fetchError || !snapshot) {\n    return {\n      success: false,\n      revertedEntities: [],\n      failedEntities: [\n        { entityType: \"unknown\", entityId: \"unknown\", error: \"Snapshot not found\" },\n      ],\n    };\n  }\n\n  if (snapshot.is_reverted) {\n    return {\n      success: false,\n      revertedEntities: [],\n      failedEntities: [\n        {\n          entityType: snapshot.entity_type,\n          entityId: snapshot.entity_id,\n          error: \"Already reverted\",\n        },\n      ],\n    };\n  }\n\n  try {\n    // Determine what to restore\n    let stateToRestore = snapshot.before_state as Record<string, unknown>;\n    let revertedFields = snapshot.changed_fields as string[];\n\n    if (options?.partialFields && options.partialFields.length > 0) {\n      // Partial revert - only restore specific fields\n      const currentState = snapshot.after_state as Record<string, unknown>;\n      stateToRestore = { ...currentState };\n      for (const field of options.partialFields) {\n        if (field in (snapshot.before_state as Record<string, unknown>)) {\n          stateToRestore[field] = (snapshot.before_state as Record<string, unknown>)[field];\n        }\n      }\n      revertedFields = options.partialFields;\n    }\n\n    // Handle different operations\n    if (snapshot.operation === \"create\") {\n      // For creates, we need to soft-delete or restore deleted_at\n      const { error: deleteError } = await supabase\n        .from(snapshot.entity_type)\n        .update({ deleted_at: new Date().toISOString() })\n        .eq(\"id\", snapshot.entity_id)\n        .eq(\"company_id\", companyId);\n\n      if (deleteError) throw deleteError;\n    } else if (snapshot.operation === \"delete\") {\n      // For deletes, restore the record\n      const { error: restoreError } = await supabase\n        .from(snapshot.entity_type)\n        .update({ ...stateToRestore, deleted_at: null })\n        .eq(\"id\", snapshot.entity_id)\n        .eq(\"company_id\", companyId);\n\n      if (restoreError) throw restoreError;\n    } else {\n      // For updates, restore the before state\n      const { error: updateError } = await supabase\n        .from(snapshot.entity_type)\n        .update(stateToRestore)\n        .eq(\"id\", snapshot.entity_id)\n        .eq(\"company_id\", companyId);\n\n      if (updateError) throw updateError;\n    }\n\n    // Mark snapshot as reverted\n    await supabase\n      .from(\"ai_action_snapshots\")\n      .update({\n        is_reverted: true,\n        reverted_at: new Date().toISOString(),\n        reverted_by: userId,\n        revert_reason: reason,\n        partial_revert_fields: options?.partialFields,\n      })\n      .eq(\"id\", snapshotId)\n      .eq(\"company_id\", companyId);\n\n    // Record in audit trail\n    const reversalId = await recordReversal(companyId, {\n      auditLogId: snapshotId, // Using snapshot ID as reference\n      reason,\n      reversedBy: userId,\n      reversalMethod: options?.partialFields ? \"partial\" : \"automatic\",\n      partialFields: options?.partialFields,\n    }).catch(() => undefined);\n\n    return {\n      success: true,\n      revertedEntities: [\n        {\n          entityType: snapshot.entity_type,\n          entityId: snapshot.entity_id,\n          revertedFields,\n        },\n      ],\n      failedEntities: [],\n      reversalId,\n    };\n  } catch (error) {\n    console.error(\"Failed to revert snapshot:\", error);\n    return {\n      success: false,\n      revertedEntities: [],\n      failedEntities: [\n        {\n          entityType: snapshot.entity_type,\n          entityId: snapshot.entity_id,\n          error: error instanceof Error ? error.message : \"Unknown error\",\n        },\n      ],\n    };\n  }\n}\n\n/**\n * Revert all actions from a specific message\n */\nexport async function revertMessageActions(\n  companyId: string,\n  messageId: string,\n  userId: string,\n  reason: string\n): Promise<RevertResult> {\n  const snapshots = await getMessageSnapshots(companyId, messageId);\n  const unrevertedSnapshots = snapshots.filter((s) => !s.isReverted);\n\n  if (unrevertedSnapshots.length === 0) {\n    return {\n      success: true,\n      revertedEntities: [],\n      failedEntities: [],\n    };\n  }\n\n  const revertedEntities: RevertResult[\"revertedEntities\"] = [];\n  const failedEntities: RevertResult[\"failedEntities\"] = [];\n\n  // Revert in reverse order (last action first)\n  for (const snapshot of unrevertedSnapshots) {\n    const result = await revertSnapshot(companyId, snapshot.id, userId, reason);\n\n    if (result.success) {\n      revertedEntities.push(...result.revertedEntities);\n    } else {\n      failedEntities.push(...result.failedEntities);\n    }\n  }\n\n  return {\n    success: failedEntities.length === 0,\n    revertedEntities,\n    failedEntities,\n  };\n}\n\n/**\n * Preview what would be reverted without actually doing it\n */\nexport async function previewRevert(\n  companyId: string,\n  snapshotId: string\n): Promise<{\n  entityType: string;\n  entityId: string;\n  operation: string;\n  currentState: Record<string, unknown> | null;\n  willRestoreTo: Record<string, unknown>;\n  changedFields: string[];\n  canRevert: boolean;\n  reason?: string;\n}> {\n  const supabase = createServiceSupabaseClient();\n\n  // Get the snapshot\n  const { data: snapshot, error: fetchError } = await supabase\n    .from(\"ai_action_snapshots\")\n    .select(\"*\")\n    .eq(\"id\", snapshotId)\n    .eq(\"company_id\", companyId)\n    .single();\n\n  if (fetchError || !snapshot) {\n    return {\n      entityType: \"unknown\",\n      entityId: \"unknown\",\n      operation: \"unknown\",\n      currentState: null,\n      willRestoreTo: {},\n      changedFields: [],\n      canRevert: false,\n      reason: \"Snapshot not found\",\n    };\n  }\n\n  if (snapshot.is_reverted) {\n    return {\n      entityType: snapshot.entity_type,\n      entityId: snapshot.entity_id,\n      operation: snapshot.operation,\n      currentState: snapshot.after_state as Record<string, unknown>,\n      willRestoreTo: snapshot.before_state as Record<string, unknown>,\n      changedFields: snapshot.changed_fields as string[],\n      canRevert: false,\n      reason: \"Already reverted\",\n    };\n  }\n\n  // Get current state from database\n  const { data: currentRecord, error: currentError } = await supabase\n    .from(snapshot.entity_type)\n    .select(\"*\")\n    .eq(\"id\", snapshot.entity_id)\n    .eq(\"company_id\", companyId)\n    .single();\n\n  return {\n    entityType: snapshot.entity_type,\n    entityId: snapshot.entity_id,\n    operation: snapshot.operation,\n    currentState: currentError ? null : (currentRecord as Record<string, unknown>),\n    willRestoreTo: snapshot.before_state as Record<string, unknown>,\n    changedFields: snapshot.changed_fields as string[],\n    canRevert: !currentError,\n    reason: currentError ? \"Entity not found in database\" : undefined,\n  };\n}\n\n/**\n * Get revert history for an entity\n */\nexport async function getEntityRevertHistory(\n  companyId: string,\n  entityType: string,\n  entityId: string\n): Promise<\n  Array<{\n    id: string;\n    operation: string;\n    revertedAt: string;\n    revertedBy: string;\n    reason: string;\n    partialFields: string[] | null;\n  }>\n> {\n  const supabase = createServiceSupabaseClient();\n\n  const { data, error } = await supabase\n    .from(\"ai_action_snapshots\")\n    .select(\"id, operation, reverted_at, reverted_by, revert_reason, partial_revert_fields\")\n    .eq(\"company_id\", companyId)\n    .eq(\"entity_type\", entityType)\n    .eq(\"entity_id\", entityId)\n    .eq(\"is_reverted\", true)\n    .order(\"reverted_at\", { ascending: false });\n\n  if (error) {\n    console.error(\"Failed to get entity revert history:\", error);\n    return [];\n  }\n\n  return (data || []).map((r) => ({\n    id: r.id,\n    operation: r.operation,\n    revertedAt: r.reverted_at,\n    revertedBy: r.reverted_by,\n    reason: r.revert_reason,\n    partialFields: r.partial_revert_fields,\n  }));\n}\n\n/**\n * Batch revert multiple snapshots with transaction-like behavior\n */\nexport async function batchRevert(\n  companyId: string,\n  snapshotIds: string[],\n  userId: string,\n  reason: string\n): Promise<RevertResult> {\n  const revertedEntities: RevertResult[\"revertedEntities\"] = [];\n  const failedEntities: RevertResult[\"failedEntities\"] = [];\n\n  for (const snapshotId of snapshotIds) {\n    const result = await revertSnapshot(companyId, snapshotId, userId, reason);\n\n    if (result.success) {\n      revertedEntities.push(...result.revertedEntities);\n    } else {\n      failedEntities.push(...result.failedEntities);\n    }\n  }\n\n  return {\n    success: failedEntities.length === 0,\n    revertedEntities,\n    failedEntities,\n  };\n}\n","/**\n * Supabase Memory Provider for ai-sdk-tools\n *\n * Implements the MemoryProvider interface from @ai-sdk-tools/memory\n * to provide persistent memory storage using existing Supabase tables:\n * - chats: Chat session management\n * - messages_v2: Conversation history\n * - ai_memory: Working memory (facts, preferences, insights)\n */\n\nimport type {\n\tMemoryProvider,\n\tMemoryScope,\n\tWorkingMemory,\n\tConversationMessage,\n\tChatSession,\n} from \"@ai-sdk-tools/memory\";\nimport { createServiceSupabaseClient } from \"@/lib/supabase/service-client\";\nimport type { UIMessage } from \"ai\";\n\n/**\n * Creates a Supabase-backed memory provider for AI agents\n *\n * @param companyId - The company ID to scope all memory operations\n * @returns MemoryProvider compatible with ai-sdk-tools\n *\n * @example\n * ```ts\n * import { createSupabaseMemoryProvider } from '@/lib/ai/memory-provider';\n * import { Agent } from '@ai-sdk-tools/agents';\n *\n * const memory = createSupabaseMemoryProvider(companyId);\n *\n * const agent = Agent.create({\n *   name: 'assistant',\n *   model: anthropic('claude-sonnet-4-20250514'),\n *   memory: {\n *     provider: memory,\n *     workingMemory: { enabled: true, scope: 'chat' },\n *     history: { enabled: true, limit: 20 },\n *     chats: { enabled: true, generateTitle: true }\n *   }\n * });\n * ```\n */\nexport function createSupabaseMemoryProvider(\n\tcompanyId: string\n): MemoryProvider {\n\tconst supabase = createServiceSupabaseClient();\n\n\treturn {\n\t\t/**\n\t\t * Get persistent working memory for a chat or user\n\t\t */\n\t\tasync getWorkingMemory(params: {\n\t\t\tchatId?: string;\n\t\t\tuserId?: string;\n\t\t\tscope: MemoryScope;\n\t\t}): Promise<WorkingMemory | null> {\n\t\t\tconst { chatId, userId, scope } = params;\n\n\t\t\t// Query ai_memory table for working memory content\n\t\t\tlet query = supabase\n\t\t\t\t.from(\"ai_memory\")\n\t\t\t\t.select(\"content, updated_at\")\n\t\t\t\t.eq(\"company_id\", companyId)\n\t\t\t\t.eq(\"memory_type\", \"conversation_summary\")\n\t\t\t\t.eq(\"is_active\", true)\n\t\t\t\t.order(\"updated_at\", { ascending: false })\n\t\t\t\t.limit(1);\n\n\t\t\tif (scope === \"chat\" && chatId) {\n\t\t\t\tquery = query.eq(\"source_chat_id\", chatId);\n\t\t\t} else if (scope === \"user\" && userId) {\n\t\t\t\tquery = query.eq(\"user_id\", userId);\n\t\t\t}\n\n\t\t\tconst { data, error } = await query.single();\n\n\t\t\tif (error || !data) {\n\t\t\t\treturn null;\n\t\t\t}\n\n\t\t\treturn {\n\t\t\t\tcontent: data.content,\n\t\t\t\tupdatedAt: new Date(data.updated_at),\n\t\t\t};\n\t\t},\n\n\t\t/**\n\t\t * Update persistent working memory\n\t\t */\n\t\tasync updateWorkingMemory(params: {\n\t\t\tchatId?: string;\n\t\t\tuserId?: string;\n\t\t\tscope: MemoryScope;\n\t\t\tcontent: string;\n\t\t}): Promise<void> {\n\t\t\tconst { chatId, userId, scope, content } = params;\n\n\t\t\t// Check if working memory exists\n\t\t\tlet existingQuery = supabase\n\t\t\t\t.from(\"ai_memory\")\n\t\t\t\t.select(\"id\")\n\t\t\t\t.eq(\"company_id\", companyId)\n\t\t\t\t.eq(\"memory_type\", \"conversation_summary\")\n\t\t\t\t.eq(\"is_active\", true);\n\n\t\t\tif (scope === \"chat\" && chatId) {\n\t\t\t\texistingQuery = existingQuery.eq(\"source_chat_id\", chatId);\n\t\t\t} else if (scope === \"user\" && userId) {\n\t\t\t\texistingQuery = existingQuery.eq(\"user_id\", userId);\n\t\t\t}\n\n\t\t\tconst { data: existing } = await existingQuery.single();\n\n\t\t\tif (existing) {\n\t\t\t\t// Update existing\n\t\t\t\tawait supabase\n\t\t\t\t\t.from(\"ai_memory\")\n\t\t\t\t\t.update({\n\t\t\t\t\t\tcontent,\n\t\t\t\t\t\tupdated_at: new Date().toISOString(),\n\t\t\t\t\t})\n\t\t\t\t\t.eq(\"id\", existing.id);\n\t\t\t} else {\n\t\t\t\t// Create new\n\t\t\t\tawait supabase.from(\"ai_memory\").insert({\n\t\t\t\t\tcompany_id: companyId,\n\t\t\t\t\tuser_id: userId || null,\n\t\t\t\t\tmemory_type: \"conversation_summary\",\n\t\t\t\t\tcontent,\n\t\t\t\t\tsource_type: \"conversation\",\n\t\t\t\t\tsource_chat_id: chatId || null,\n\t\t\t\t\timportance: \"normal\",\n\t\t\t\t\tconfidence_score: 1.0,\n\t\t\t\t\tis_active: true,\n\t\t\t\t});\n\t\t\t}\n\t\t},\n\n\t\t/**\n\t\t * Save a message to conversation history\n\t\t */\n\t\tasync saveMessage(message: ConversationMessage): Promise<void> {\n\t\t\tconst { chatId, userId, role, content, timestamp } = message;\n\n\t\t\t// Convert content to parts format expected by messages_v2\n\t\t\tconst parts =\n\t\t\t\ttypeof content === \"string\"\n\t\t\t\t\t? [{ type: \"text\", text: content }]\n\t\t\t\t\t: content;\n\n\t\t\tawait supabase.from(\"messages_v2\").insert({\n\t\t\t\tchat_id: chatId,\n\t\t\t\trole,\n\t\t\t\tparts,\n\t\t\t\tattachments: [],\n\t\t\t\tcreated_at: timestamp.toISOString(),\n\t\t\t});\n\t\t},\n\n\t\t/**\n\t\t * Get recent messages from conversation history\n\t\t * Returns UIMessage[] format for AI SDK compatibility\n\t\t */\n\t\tasync getMessages<T = UIMessage>(params: {\n\t\t\tchatId: string;\n\t\t\tuserId?: string;\n\t\t\tlimit?: number;\n\t\t}): Promise<T[]> {\n\t\t\tconst { chatId, limit = 20 } = params;\n\n\t\t\tconst { data, error } = await supabase\n\t\t\t\t.from(\"messages_v2\")\n\t\t\t\t.select(\"id, role, parts, attachments, created_at\")\n\t\t\t\t.eq(\"chat_id\", chatId)\n\t\t\t\t.order(\"created_at\", { ascending: true })\n\t\t\t\t.limit(limit);\n\n\t\t\tif (error || !data) {\n\t\t\t\treturn [];\n\t\t\t}\n\n\t\t\t// Convert to UIMessage format\n\t\t\treturn data.map((msg) => ({\n\t\t\t\tid: msg.id,\n\t\t\t\trole: msg.role as \"user\" | \"assistant\" | \"system\",\n\t\t\t\tcontent: extractTextFromParts(msg.parts),\n\t\t\t\tparts: msg.parts,\n\t\t\t\tcreatedAt: new Date(msg.created_at),\n\t\t\t})) as T[];\n\t\t},\n\n\t\t/**\n\t\t * Save or update a chat session\n\t\t */\n\t\tasync saveChat(chat: ChatSession): Promise<void> {\n\t\t\tconst { chatId, userId, title, createdAt, updatedAt, messageCount } =\n\t\t\t\tchat;\n\n\t\t\t// Check if chat exists\n\t\t\tconst { data: existing } = await supabase\n\t\t\t\t.from(\"chats\")\n\t\t\t\t.select(\"id\")\n\t\t\t\t.eq(\"id\", chatId)\n\t\t\t\t.single();\n\n\t\t\tif (existing) {\n\t\t\t\tawait supabase\n\t\t\t\t\t.from(\"chats\")\n\t\t\t\t\t.update({\n\t\t\t\t\t\ttitle: title || \"New Chat\",\n\t\t\t\t\t\t// Note: messages_v2 doesn't track message count, handled separately\n\t\t\t\t\t})\n\t\t\t\t\t.eq(\"id\", chatId);\n\t\t\t} else {\n\t\t\t\tawait supabase.from(\"chats\").insert({\n\t\t\t\t\tid: chatId,\n\t\t\t\t\tuser_id: userId,\n\t\t\t\t\tcompany_id: companyId,\n\t\t\t\t\ttitle: title || \"New Chat\",\n\t\t\t\t\tvisibility: \"private\",\n\t\t\t\t\tcreated_at: createdAt.toISOString(),\n\t\t\t\t});\n\t\t\t}\n\t\t},\n\n\t\t/**\n\t\t * Get chat sessions for a user\n\t\t */\n\t\tasync getChats(params: {\n\t\t\tuserId?: string;\n\t\t\tsearch?: string;\n\t\t\tlimit?: number;\n\t\t}): Promise<ChatSession[]> {\n\t\t\tconst { userId, search, limit = 50 } = params;\n\n\t\t\tlet query = supabase\n\t\t\t\t.from(\"chats\")\n\t\t\t\t.select(\n\t\t\t\t\t`\n          id,\n          user_id,\n          title,\n          created_at,\n          visibility\n        `\n\t\t\t\t)\n\t\t\t\t.eq(\"company_id\", companyId)\n\t\t\t\t.order(\"created_at\", { ascending: false })\n\t\t\t\t.limit(limit);\n\n\t\t\tif (userId) {\n\t\t\t\tquery = query.eq(\"user_id\", userId);\n\t\t\t}\n\n\t\t\tif (search) {\n\t\t\t\tquery = query.ilike(\"title\", `%${search}%`);\n\t\t\t}\n\n\t\t\tconst { data, error } = await query;\n\n\t\t\tif (error || !data) {\n\t\t\t\treturn [];\n\t\t\t}\n\n\t\t\t// Get message counts for each chat\n\t\t\tconst chatIds = data.map((c) => c.id);\n\t\t\tconst { data: messageCounts } = await supabase\n\t\t\t\t.from(\"messages_v2\")\n\t\t\t\t.select(\"chat_id\")\n\t\t\t\t.in(\"chat_id\", chatIds);\n\n\t\t\tconst countMap = new Map<string, number>();\n\t\t\tmessageCounts?.forEach((m) => {\n\t\t\t\tcountMap.set(m.chat_id, (countMap.get(m.chat_id) || 0) + 1);\n\t\t\t});\n\n\t\t\treturn data.map((chat) => ({\n\t\t\t\tchatId: chat.id,\n\t\t\t\tuserId: chat.user_id,\n\t\t\t\ttitle: chat.title,\n\t\t\t\tcreatedAt: new Date(chat.created_at),\n\t\t\t\tupdatedAt: new Date(chat.created_at), // chats table doesn't have updated_at\n\t\t\t\tmessageCount: countMap.get(chat.id) || 0,\n\t\t\t}));\n\t\t},\n\n\t\t/**\n\t\t * Get a specific chat session\n\t\t */\n\t\tasync getChat(chatId: string): Promise<ChatSession | null> {\n\t\t\tconst { data, error } = await supabase\n\t\t\t\t.from(\"chats\")\n\t\t\t\t.select(\"id, user_id, title, created_at\")\n\t\t\t\t.eq(\"id\", chatId)\n\t\t\t\t.eq(\"company_id\", companyId)\n\t\t\t\t.single();\n\n\t\t\tif (error || !data) {\n\t\t\t\treturn null;\n\t\t\t}\n\n\t\t\t// Get message count\n\t\t\tconst { count } = await supabase\n\t\t\t\t.from(\"messages_v2\")\n\t\t\t\t.select(\"id\", { count: \"exact\", head: true })\n\t\t\t\t.eq(\"chat_id\", chatId);\n\n\t\t\treturn {\n\t\t\t\tchatId: data.id,\n\t\t\t\tuserId: data.user_id,\n\t\t\t\ttitle: data.title,\n\t\t\t\tcreatedAt: new Date(data.created_at),\n\t\t\t\tupdatedAt: new Date(data.created_at),\n\t\t\t\tmessageCount: count || 0,\n\t\t\t};\n\t\t},\n\n\t\t/**\n\t\t * Update chat title\n\t\t */\n\t\tasync updateChatTitle(chatId: string, title: string): Promise<void> {\n\t\t\tawait supabase.from(\"chats\").update({ title }).eq(\"id\", chatId);\n\t\t},\n\n\t\t/**\n\t\t * Delete a chat session and its messages\n\t\t */\n\t\tasync deleteChat(chatId: string): Promise<void> {\n\t\t\t// Delete messages first (foreign key constraint)\n\t\t\tawait supabase.from(\"messages_v2\").delete().eq(\"chat_id\", chatId);\n\n\t\t\t// Delete working memory associated with this chat\n\t\t\tawait supabase\n\t\t\t\t.from(\"ai_memory\")\n\t\t\t\t.update({ is_active: false, deactivated_at: new Date().toISOString() })\n\t\t\t\t.eq(\"source_chat_id\", chatId);\n\n\t\t\t// Delete the chat\n\t\t\tawait supabase.from(\"chats\").delete().eq(\"id\", chatId);\n\t\t},\n\t};\n}\n\n/**\n * Extract text content from message parts\n */\nfunction extractTextFromParts(parts: unknown): string {\n\tif (!Array.isArray(parts)) {\n\t\treturn typeof parts === \"string\" ? parts : \"\";\n\t}\n\n\treturn parts\n\t\t.filter((part: { type?: string }) => part?.type === \"text\")\n\t\t.map((part: { text?: string }) => part?.text || \"\")\n\t\t.join(\"\\n\");\n}\n\n/**\n * Default working memory template for AI agents\n */\nexport const DEFAULT_WORKING_MEMORY_TEMPLATE = `# Working Memory\n\n## Key Facts\n- [Important information about the customer/context]\n\n## Current Focus\n- [What the user is working on or asking about]\n\n## Preferences\n- [User preferences and communication style]\n\n## Business Context\n- [Relevant business information: jobs, invoices, customers]\n`;\n","/**\n * AI Feedback Service - User feedback collection and RLHF/RLUF patterns\n * Based on industry best practices from OpenAI, Anthropic, and Langfuse\n */\n\nimport { createServiceSupabaseClient } from \"@/lib/supabase/service-client\";\nimport crypto from \"crypto\";\n\nexport type FeedbackType = \"thumbs_up\" | \"thumbs_down\" | \"rating\" | \"correction\" | \"flag\";\n\nexport type FeedbackCategory =\n  | \"incorrect_information\"\n  | \"unhelpful_response\"\n  | \"wrong_action\"\n  | \"privacy_concern\"\n  | \"too_slow\"\n  | \"too_verbose\"\n  | \"missing_context\"\n  | \"great_response\"\n  | \"accurate\"\n  | \"helpful\"\n  | \"other\";\n\nexport type FeedbackStatus = \"new\" | \"reviewed\" | \"actioned\" | \"dismissed\";\n\nexport interface FeedbackSubmission {\n  messageId: string;\n  chatId: string;\n  feedbackType: FeedbackType;\n  rating?: number;\n  isPositive: boolean;\n  categories?: FeedbackCategory[];\n  userComment?: string;\n  correctedResponse?: string;\n  expectedBehavior?: string;\n  toolsUsed?: string[];\n  responseTimeMs?: number;\n  tokenCount?: number;\n}\n\nexport interface FeedbackResponse {\n  id: string;\n  success: boolean;\n  message: string;\n}\n\n/**\n * Submit feedback for an AI message\n */\nexport async function submitFeedback(\n  companyId: string,\n  userId: string,\n  feedback: FeedbackSubmission\n): Promise<FeedbackResponse> {\n  const supabase = createServiceSupabaseClient();\n  const feedbackId = crypto.randomUUID();\n\n  const { error } = await supabase.from(\"ai_message_feedback\").insert({\n    id: feedbackId,\n    company_id: companyId,\n    user_id: userId,\n    message_id: feedback.messageId,\n    chat_id: feedback.chatId,\n    feedback_type: feedback.feedbackType,\n    rating: feedback.rating,\n    is_positive: feedback.isPositive,\n    feedback_categories: feedback.categories || [],\n    user_comment: feedback.userComment,\n    corrected_response: feedback.correctedResponse,\n    expected_behavior: feedback.expectedBehavior,\n    tools_used: feedback.toolsUsed || [],\n    response_time_ms: feedback.responseTimeMs,\n    token_count: feedback.tokenCount,\n    status: \"new\",\n    created_at: new Date().toISOString(),\n  });\n\n  if (error) {\n    console.error(\"Failed to submit feedback:\", error);\n    return { id: \"\", success: false, message: \"Failed to submit feedback\" };\n  }\n\n  return { id: feedbackId, success: true, message: \"Feedback submitted successfully\" };\n}\n\n/**\n * Submit quick thumbs up/down feedback\n */\nexport async function submitQuickFeedback(\n  companyId: string,\n  userId: string,\n  messageId: string,\n  chatId: string,\n  isPositive: boolean\n): Promise<FeedbackResponse> {\n  return submitFeedback(companyId, userId, {\n    messageId,\n    chatId,\n    feedbackType: isPositive ? \"thumbs_up\" : \"thumbs_down\",\n    isPositive,\n  });\n}\n\n/**\n * Submit a correction for an AI response\n */\nexport async function submitCorrection(\n  companyId: string,\n  userId: string,\n  messageId: string,\n  chatId: string,\n  correction: {\n    correctedResponse: string;\n    categories?: FeedbackCategory[];\n    comment?: string;\n  }\n): Promise<FeedbackResponse> {\n  return submitFeedback(companyId, userId, {\n    messageId,\n    chatId,\n    feedbackType: \"correction\",\n    isPositive: false,\n    correctedResponse: correction.correctedResponse,\n    categories: correction.categories,\n    userComment: correction.comment,\n  });\n}\n\n/**\n * Flag a response for review\n */\nexport async function flagResponse(\n  companyId: string,\n  userId: string,\n  messageId: string,\n  chatId: string,\n  reason: FeedbackCategory,\n  comment?: string\n): Promise<FeedbackResponse> {\n  return submitFeedback(companyId, userId, {\n    messageId,\n    chatId,\n    feedbackType: \"flag\",\n    isPositive: false,\n    categories: [reason],\n    userComment: comment,\n  });\n}\n\n/**\n * Get feedback for a specific message\n */\nexport async function getMessageFeedback(\n  companyId: string,\n  messageId: string\n): Promise<{\n  totalFeedback: number;\n  positiveCount: number;\n  negativeCount: number;\n  averageRating: number | null;\n  categories: Record<string, number>;\n  hasCorrection: boolean;\n}> {\n  const supabase = createServiceSupabaseClient();\n\n  const { data, error } = await supabase\n    .from(\"ai_message_feedback\")\n    .select(\"is_positive, rating, feedback_categories, corrected_response\")\n    .eq(\"company_id\", companyId)\n    .eq(\"message_id\", messageId);\n\n  if (error || !data || data.length === 0) {\n    return {\n      totalFeedback: 0,\n      positiveCount: 0,\n      negativeCount: 0,\n      averageRating: null,\n      categories: {},\n      hasCorrection: false,\n    };\n  }\n\n  const positiveCount = data.filter((f) => f.is_positive).length;\n  const ratings = data.filter((f) => f.rating !== null).map((f) => f.rating as number);\n  const averageRating = ratings.length > 0 ? ratings.reduce((a, b) => a + b, 0) / ratings.length : null;\n\n  const categories: Record<string, number> = {};\n  for (const feedback of data) {\n    const cats = feedback.feedback_categories as string[] | null;\n    if (cats) {\n      for (const cat of cats) {\n        categories[cat] = (categories[cat] || 0) + 1;\n      }\n    }\n  }\n\n  return {\n    totalFeedback: data.length,\n    positiveCount,\n    negativeCount: data.length - positiveCount,\n    averageRating,\n    categories,\n    hasCorrection: data.some((f) => f.corrected_response !== null),\n  };\n}\n\n/**\n * Get feedback summary for a chat session\n */\nexport async function getChatFeedbackSummary(\n  companyId: string,\n  chatId: string\n): Promise<{\n  totalMessages: number;\n  feedbackCount: number;\n  positiveRate: number;\n  topIssues: Array<{ category: string; count: number }>;\n  correctionsCount: number;\n}> {\n  const supabase = createServiceSupabaseClient();\n\n  const { data, error } = await supabase\n    .from(\"ai_message_feedback\")\n    .select(\"is_positive, feedback_categories, corrected_response\")\n    .eq(\"company_id\", companyId)\n    .eq(\"chat_id\", chatId);\n\n  if (error || !data || data.length === 0) {\n    return {\n      totalMessages: 0,\n      feedbackCount: 0,\n      positiveRate: 0,\n      topIssues: [],\n      correctionsCount: 0,\n    };\n  }\n\n  const positiveCount = data.filter((f) => f.is_positive).length;\n  const correctionsCount = data.filter((f) => f.corrected_response !== null).length;\n\n  // Count negative categories\n  const categoryCount: Record<string, number> = {};\n  for (const feedback of data) {\n    if (!feedback.is_positive) {\n      const cats = feedback.feedback_categories as string[] | null;\n      if (cats) {\n        for (const cat of cats) {\n          categoryCount[cat] = (categoryCount[cat] || 0) + 1;\n        }\n      }\n    }\n  }\n\n  const topIssues = Object.entries(categoryCount)\n    .map(([category, count]) => ({ category, count }))\n    .sort((a, b) => b.count - a.count)\n    .slice(0, 5);\n\n  return {\n    totalMessages: data.length,\n    feedbackCount: data.length,\n    positiveRate: data.length > 0 ? (positiveCount / data.length) * 100 : 0,\n    topIssues,\n    correctionsCount,\n  };\n}\n\n/**\n * Get company-wide feedback analytics\n */\nexport async function getCompanyFeedbackAnalytics(\n  companyId: string,\n  dateRange: { start: Date; end: Date }\n): Promise<{\n  totalFeedback: number;\n  positiveRate: number;\n  negativeRate: number;\n  averageRating: number | null;\n  topPositiveCategories: Array<{ category: string; count: number }>;\n  topNegativeCategories: Array<{ category: string; count: number }>;\n  feedbackByDay: Array<{ date: string; positive: number; negative: number }>;\n  correctionRate: number;\n  flaggedCount: number;\n}> {\n  const supabase = createServiceSupabaseClient();\n\n  const { data, error } = await supabase\n    .from(\"ai_message_feedback\")\n    .select(\"*\")\n    .eq(\"company_id\", companyId)\n    .gte(\"created_at\", dateRange.start.toISOString())\n    .lte(\"created_at\", dateRange.end.toISOString())\n    .order(\"created_at\", { ascending: true });\n\n  if (error || !data || data.length === 0) {\n    return {\n      totalFeedback: 0,\n      positiveRate: 0,\n      negativeRate: 0,\n      averageRating: null,\n      topPositiveCategories: [],\n      topNegativeCategories: [],\n      feedbackByDay: [],\n      correctionRate: 0,\n      flaggedCount: 0,\n    };\n  }\n\n  const positiveCount = data.filter((f) => f.is_positive).length;\n  const ratings = data.filter((f) => f.rating !== null).map((f) => f.rating as number);\n  const averageRating = ratings.length > 0 ? ratings.reduce((a, b) => a + b, 0) / ratings.length : null;\n\n  // Count categories separately for positive and negative\n  const positiveCats: Record<string, number> = {};\n  const negativeCats: Record<string, number> = {};\n\n  for (const feedback of data) {\n    const cats = feedback.feedback_categories as string[] | null;\n    if (cats) {\n      const target = feedback.is_positive ? positiveCats : negativeCats;\n      for (const cat of cats) {\n        target[cat] = (target[cat] || 0) + 1;\n      }\n    }\n  }\n\n  // Group by day\n  const byDay: Record<string, { positive: number; negative: number }> = {};\n  for (const feedback of data) {\n    const date = new Date(feedback.created_at as string).toISOString().split(\"T\")[0];\n    if (!byDay[date]) {\n      byDay[date] = { positive: 0, negative: 0 };\n    }\n    if (feedback.is_positive) {\n      byDay[date].positive++;\n    } else {\n      byDay[date].negative++;\n    }\n  }\n\n  const correctionsCount = data.filter((f) => f.corrected_response !== null).length;\n  const flaggedCount = data.filter((f) => f.feedback_type === \"flag\").length;\n\n  return {\n    totalFeedback: data.length,\n    positiveRate: (positiveCount / data.length) * 100,\n    negativeRate: ((data.length - positiveCount) / data.length) * 100,\n    averageRating,\n    topPositiveCategories: Object.entries(positiveCats)\n      .map(([category, count]) => ({ category, count }))\n      .sort((a, b) => b.count - a.count)\n      .slice(0, 5),\n    topNegativeCategories: Object.entries(negativeCats)\n      .map(([category, count]) => ({ category, count }))\n      .sort((a, b) => b.count - a.count)\n      .slice(0, 5),\n    feedbackByDay: Object.entries(byDay).map(([date, counts]) => ({\n      date,\n      positive: counts.positive,\n      negative: counts.negative,\n    })),\n    correctionRate: data.length > 0 ? (correctionsCount / data.length) * 100 : 0,\n    flaggedCount,\n  };\n}\n\n/**\n * Get feedback items that need review (for admin dashboard)\n */\nexport async function getPendingFeedbackReview(\n  companyId: string,\n  options?: {\n    limit?: number;\n    feedbackType?: FeedbackType;\n    onlyFlagged?: boolean;\n    onlyCorrections?: boolean;\n  }\n): Promise<\n  Array<{\n    id: string;\n    messageId: string;\n    chatId: string;\n    userId: string;\n    feedbackType: string;\n    isPositive: boolean;\n    categories: string[];\n    userComment: string | null;\n    correctedResponse: string | null;\n    status: string;\n    createdAt: string;\n  }>\n> {\n  const supabase = createServiceSupabaseClient();\n  const limit = options?.limit || 50;\n\n  let query = supabase\n    .from(\"ai_message_feedback\")\n    .select(\"*\")\n    .eq(\"company_id\", companyId)\n    .eq(\"status\", \"new\")\n    .order(\"created_at\", { ascending: false })\n    .limit(limit);\n\n  if (options?.feedbackType) {\n    query = query.eq(\"feedback_type\", options.feedbackType);\n  }\n\n  if (options?.onlyFlagged) {\n    query = query.eq(\"feedback_type\", \"flag\");\n  }\n\n  if (options?.onlyCorrections) {\n    query = query.not(\"corrected_response\", \"is\", null);\n  }\n\n  const { data, error } = await query;\n\n  if (error) {\n    console.error(\"Failed to get pending feedback:\", error);\n    return [];\n  }\n\n  return (data || []).map((f) => ({\n    id: f.id,\n    messageId: f.message_id,\n    chatId: f.chat_id,\n    userId: f.user_id,\n    feedbackType: f.feedback_type,\n    isPositive: f.is_positive,\n    categories: f.feedback_categories as string[],\n    userComment: f.user_comment,\n    correctedResponse: f.corrected_response,\n    status: f.status,\n    createdAt: f.created_at as string,\n  }));\n}\n\n/**\n * Update feedback status (mark as reviewed, actioned, etc.)\n */\nexport async function updateFeedbackStatus(\n  companyId: string,\n  feedbackId: string,\n  status: FeedbackStatus,\n  reviewerNotes?: string\n): Promise<boolean> {\n  const supabase = createServiceSupabaseClient();\n\n  const { error } = await supabase\n    .from(\"ai_message_feedback\")\n    .update({\n      status,\n      reviewed_at: new Date().toISOString(),\n      reviewer_notes: reviewerNotes,\n    })\n    .eq(\"id\", feedbackId)\n    .eq(\"company_id\", companyId);\n\n  if (error) {\n    console.error(\"Failed to update feedback status:\", error);\n    return false;\n  }\n\n  return true;\n}\n\n/**\n * Get corrections for training/fine-tuning purposes (RLHF data export)\n */\nexport async function exportCorrectionsForTraining(\n  companyId: string,\n  options?: { since?: Date; limit?: number }\n): Promise<\n  Array<{\n    originalMessageId: string;\n    correctedResponse: string;\n    categories: string[];\n    expectedBehavior: string | null;\n    createdAt: string;\n  }>\n> {\n  const supabase = createServiceSupabaseClient();\n\n  let query = supabase\n    .from(\"ai_message_feedback\")\n    .select(\"message_id, corrected_response, feedback_categories, expected_behavior, created_at\")\n    .eq(\"company_id\", companyId)\n    .not(\"corrected_response\", \"is\", null)\n    .order(\"created_at\", { ascending: false });\n\n  if (options?.since) {\n    query = query.gte(\"created_at\", options.since.toISOString());\n  }\n\n  if (options?.limit) {\n    query = query.limit(options.limit);\n  }\n\n  const { data, error } = await query;\n\n  if (error) {\n    console.error(\"Failed to export corrections:\", error);\n    return [];\n  }\n\n  return (data || []).map((c) => ({\n    originalMessageId: c.message_id,\n    correctedResponse: c.corrected_response as string,\n    categories: c.feedback_categories as string[],\n    expectedBehavior: c.expected_behavior,\n    createdAt: c.created_at as string,\n  }));\n}\n","/**\n * Artifacts Writer Access\n *\n * Provides access to the stream writer from tool executionOptions.\n * The writer is needed to stream artifact updates to the client.\n *\n */\n\nimport type { UIMessageStreamWriter } from \"ai\";\n\n/**\n * Get writer from execution context\n *\n * @param executionOptions - Tool execution options from AI SDK\n * @returns The stream writer\n *\n * @example\n * ```typescript\n * export const myTool = tool({\n *   execute: async (params, executionOptions) => {\n *     const writer = getWriter(executionOptions);\n *     const artifact = MyArtifact.stream(data, writer);\n *   }\n * });\n * ```\n */\nexport function getWriter(executionOptions?: any): UIMessageStreamWriter {\n  // AI SDK passes context via experimental_context\n  const writer = executionOptions?.experimental_context?.writer;\n\n  if (!writer) {\n    throw new Error(\n      \"Writer not available. Make sure you're passing executionOptions: getWriter(executionOptions)\",\n    );\n  }\n\n  return writer;\n}\n","/**\n * AI Proactive Analyzer Service - Background analysis and insights generation\n * Identifies patterns, anomalies, and opportunities proactively\n */\n\nimport { createServiceSupabaseClient } from \"@/lib/supabase/service-client\";\nimport crypto from \"crypto\";\n\nexport type InsightType =\n  | \"anomaly\"\n  | \"trend\"\n  | \"opportunity\"\n  | \"risk\"\n  | \"recommendation\"\n  | \"reminder\"\n  | \"milestone\"\n  | \"alert\";\n\nexport type InsightPriority = \"low\" | \"medium\" | \"high\" | \"critical\";\n\nexport type InsightStatus =\n  | \"new\"\n  | \"acknowledged\"\n  | \"in_progress\"\n  | \"resolved\"\n  | \"dismissed\"\n  | \"expired\";\n\nexport type InsightCategory =\n  | \"revenue\"\n  | \"customer\"\n  | \"operations\"\n  | \"inventory\"\n  | \"scheduling\"\n  | \"performance\"\n  | \"compliance\"\n  | \"security\";\n\nexport interface Insight {\n  type: InsightType;\n  priority: InsightPriority;\n  category: InsightCategory;\n  title: string;\n  description: string;\n  entityType?: string;\n  entityId?: string;\n  relatedEntities?: Array<{ type: string; id: string }>;\n  dataPoints?: Record<string, unknown>;\n  suggestedActions?: string[];\n  expiresAt?: Date;\n  metadata?: Record<string, unknown>;\n}\n\nexport interface InsightResult {\n  id: string;\n  type: string;\n  priority: string;\n  category: string;\n  title: string;\n  description: string;\n  status: string;\n  createdAt: string;\n  acknowledgedAt?: string;\n}\n\n/**\n * Create a new insight\n */\nexport async function createInsight(\n  companyId: string,\n  insight: Insight,\n  sourceAnalysis?: string\n): Promise<string> {\n  const supabase = createServiceSupabaseClient();\n  const insightId = crypto.randomUUID();\n\n  // Calculate content hash to prevent duplicates\n  const contentHash = crypto\n    .createHash(\"sha256\")\n    .update(JSON.stringify({ type: insight.type, title: insight.title, entityId: insight.entityId }))\n    .digest(\"hex\");\n\n  // Check for recent duplicate\n  const oneHourAgo = new Date(Date.now() - 60 * 60 * 1000);\n  const { data: existing } = await supabase\n    .from(\"ai_insights\")\n    .select(\"id\")\n    .eq(\"company_id\", companyId)\n    .eq(\"content_hash\", contentHash)\n    .gte(\"created_at\", oneHourAgo.toISOString())\n    .maybeSingle();\n\n  if (existing) {\n    return existing.id; // Return existing insight ID to avoid duplicates\n  }\n\n  const { error } = await supabase.from(\"ai_insights\").insert({\n    id: insightId,\n    company_id: companyId,\n    insight_type: insight.type,\n    priority: insight.priority,\n    category: insight.category,\n    title: insight.title,\n    description: insight.description,\n    entity_type: insight.entityType,\n    entity_id: insight.entityId,\n    related_entities: insight.relatedEntities || [],\n    data_points: insight.dataPoints || {},\n    suggested_actions: insight.suggestedActions || [],\n    source_analysis: sourceAnalysis,\n    content_hash: contentHash,\n    status: \"new\",\n    expires_at: insight.expiresAt?.toISOString(),\n    metadata: insight.metadata || {},\n    created_at: new Date().toISOString(),\n  });\n\n  if (error) {\n    console.error(\"Failed to create insight:\", error);\n    throw error;\n  }\n\n  return insightId;\n}\n\n/**\n * Get active insights for a company\n */\nexport async function getActiveInsights(\n  companyId: string,\n  options?: {\n    priority?: InsightPriority[];\n    category?: InsightCategory[];\n    type?: InsightType[];\n    limit?: number;\n    entityType?: string;\n    entityId?: string;\n  }\n): Promise<InsightResult[]> {\n  const supabase = createServiceSupabaseClient();\n  const limit = options?.limit || 20;\n\n  let query = supabase\n    .from(\"ai_insights\")\n    .select(\"*\")\n    .eq(\"company_id\", companyId)\n    .in(\"status\", [\"new\", \"acknowledged\", \"in_progress\"])\n    .order(\"priority\", { ascending: false })\n    .order(\"created_at\", { ascending: false })\n    .limit(limit);\n\n  if (options?.priority && options.priority.length > 0) {\n    query = query.in(\"priority\", options.priority);\n  }\n\n  if (options?.category && options.category.length > 0) {\n    query = query.in(\"category\", options.category);\n  }\n\n  if (options?.type && options.type.length > 0) {\n    query = query.in(\"insight_type\", options.type);\n  }\n\n  if (options?.entityType) {\n    query = query.eq(\"entity_type\", options.entityType);\n  }\n\n  if (options?.entityId) {\n    query = query.eq(\"entity_id\", options.entityId);\n  }\n\n  // Filter out expired insights\n  query = query.or(`expires_at.is.null,expires_at.gt.${new Date().toISOString()}`);\n\n  const { data, error } = await query;\n\n  if (error) {\n    console.error(\"Failed to get active insights:\", error);\n    return [];\n  }\n\n  return (data || []).map((i) => ({\n    id: i.id,\n    type: i.insight_type,\n    priority: i.priority,\n    category: i.category,\n    title: i.title,\n    description: i.description,\n    status: i.status,\n    createdAt: i.created_at as string,\n    acknowledgedAt: i.acknowledged_at as string | undefined,\n  }));\n}\n\n/**\n * Acknowledge an insight\n */\nexport async function acknowledgeInsight(\n  companyId: string,\n  insightId: string,\n  userId: string\n): Promise<boolean> {\n  const supabase = createServiceSupabaseClient();\n\n  const { error } = await supabase\n    .from(\"ai_insights\")\n    .update({\n      status: \"acknowledged\",\n      acknowledged_by: userId,\n      acknowledged_at: new Date().toISOString(),\n    })\n    .eq(\"id\", insightId)\n    .eq(\"company_id\", companyId)\n    .eq(\"status\", \"new\");\n\n  if (error) {\n    console.error(\"Failed to acknowledge insight:\", error);\n    return false;\n  }\n\n  return true;\n}\n\n/**\n * Dismiss an insight\n */\nexport async function dismissInsight(\n  companyId: string,\n  insightId: string,\n  userId: string,\n  reason?: string\n): Promise<boolean> {\n  const supabase = createServiceSupabaseClient();\n\n  const { error } = await supabase\n    .from(\"ai_insights\")\n    .update({\n      status: \"dismissed\",\n      dismissed_by: userId,\n      dismissed_at: new Date().toISOString(),\n      dismissal_reason: reason,\n    })\n    .eq(\"id\", insightId)\n    .eq(\"company_id\", companyId);\n\n  if (error) {\n    console.error(\"Failed to dismiss insight:\", error);\n    return false;\n  }\n\n  return true;\n}\n\n/**\n * Mark insight as resolved\n */\nexport async function resolveInsight(\n  companyId: string,\n  insightId: string,\n  userId: string,\n  resolution?: string\n): Promise<boolean> {\n  const supabase = createServiceSupabaseClient();\n\n  const { error } = await supabase\n    .from(\"ai_insights\")\n    .update({\n      status: \"resolved\",\n      resolved_by: userId,\n      resolved_at: new Date().toISOString(),\n      resolution_notes: resolution,\n    })\n    .eq(\"id\", insightId)\n    .eq(\"company_id\", companyId);\n\n  if (error) {\n    console.error(\"Failed to resolve insight:\", error);\n    return false;\n  }\n\n  return true;\n}\n\n/**\n * Run revenue analysis to detect anomalies and opportunities\n */\nexport async function analyzeRevenue(companyId: string): Promise<Insight[]> {\n  const supabase = createServiceSupabaseClient();\n  const insights: Insight[] = [];\n\n  // Get revenue data for analysis\n  const thirtyDaysAgo = new Date(Date.now() - 30 * 24 * 60 * 60 * 1000);\n  const sixtyDaysAgo = new Date(Date.now() - 60 * 24 * 60 * 60 * 1000);\n\n  // Get recent invoices\n  const { data: recentInvoices } = await supabase\n    .from(\"invoices\")\n    .select(\"total_amount, created_at, status\")\n    .eq(\"company_id\", companyId)\n    .gte(\"created_at\", thirtyDaysAgo.toISOString());\n\n  // Get previous period invoices for comparison\n  const { data: previousInvoices } = await supabase\n    .from(\"invoices\")\n    .select(\"total_amount\")\n    .eq(\"company_id\", companyId)\n    .gte(\"created_at\", sixtyDaysAgo.toISOString())\n    .lt(\"created_at\", thirtyDaysAgo.toISOString());\n\n  if (recentInvoices && previousInvoices) {\n    const recentTotal = recentInvoices.reduce(\n      (sum, i) => sum + (i.total_amount as number || 0),\n      0\n    );\n    const previousTotal = previousInvoices.reduce(\n      (sum, i) => sum + (i.total_amount as number || 0),\n      0\n    );\n\n    if (previousTotal > 0) {\n      const changePercent = ((recentTotal - previousTotal) / previousTotal) * 100;\n\n      if (changePercent < -20) {\n        insights.push({\n          type: \"anomaly\",\n          priority: \"high\",\n          category: \"revenue\",\n          title: \"Significant Revenue Decline Detected\",\n          description: `Revenue has decreased by ${Math.abs(changePercent).toFixed(1)}% compared to the previous 30-day period.`,\n          dataPoints: {\n            currentPeriodTotal: recentTotal,\n            previousPeriodTotal: previousTotal,\n            changePercent,\n          },\n          suggestedActions: [\n            \"Review recent job completions and invoicing\",\n            \"Check for outstanding unpaid invoices\",\n            \"Analyze customer acquisition and retention\",\n          ],\n        });\n      } else if (changePercent > 30) {\n        insights.push({\n          type: \"trend\",\n          priority: \"medium\",\n          category: \"revenue\",\n          title: \"Strong Revenue Growth\",\n          description: `Revenue has increased by ${changePercent.toFixed(1)}% compared to the previous 30-day period.`,\n          dataPoints: {\n            currentPeriodTotal: recentTotal,\n            previousPeriodTotal: previousTotal,\n            changePercent,\n          },\n          suggestedActions: [\n            \"Consider expanding capacity to maintain growth\",\n            \"Review top-performing services\",\n          ],\n        });\n      }\n    }\n\n    // Check for overdue invoices\n    const overdueInvoices = recentInvoices.filter(\n      (i) => i.status === \"overdue\" || i.status === \"unpaid\"\n    );\n    if (overdueInvoices.length > 5) {\n      const overdueTotal = overdueInvoices.reduce(\n        (sum, i) => sum + (i.total_amount as number || 0),\n        0\n      );\n      insights.push({\n        type: \"risk\",\n        priority: \"high\",\n        category: \"revenue\",\n        title: \"High Number of Overdue Invoices\",\n        description: `${overdueInvoices.length} invoices totaling $${overdueTotal.toFixed(2)} are overdue or unpaid.`,\n        dataPoints: {\n          overdueCount: overdueInvoices.length,\n          overdueTotal,\n        },\n        suggestedActions: [\n          \"Send payment reminders to customers\",\n          \"Review payment terms with frequent late payers\",\n          \"Consider offering payment plans\",\n        ],\n      });\n    }\n  }\n\n  return insights;\n}\n\n/**\n * Run customer analysis to identify at-risk customers and opportunities\n */\nexport async function analyzeCustomers(companyId: string): Promise<Insight[]> {\n  const supabase = createServiceSupabaseClient();\n  const insights: Insight[] = [];\n\n  // Find customers with no recent activity\n  const ninetyDaysAgo = new Date(Date.now() - 90 * 24 * 60 * 60 * 1000);\n\n  const { data: inactiveCustomers } = await supabase\n    .from(\"customers\")\n    .select(\"id, first_name, last_name, email, last_service_date\")\n    .eq(\"company_id\", companyId)\n    .lt(\"last_service_date\", ninetyDaysAgo.toISOString())\n    .is(\"deleted_at\", null)\n    .limit(20);\n\n  if (inactiveCustomers && inactiveCustomers.length > 0) {\n    insights.push({\n      type: \"opportunity\",\n      priority: \"medium\",\n      category: \"customer\",\n      title: \"Inactive Customers Identified\",\n      description: `${inactiveCustomers.length} customers haven't had service in over 90 days.`,\n      dataPoints: {\n        inactiveCount: inactiveCustomers.length,\n        customerIds: inactiveCustomers.map((c) => c.id),\n      },\n      relatedEntities: inactiveCustomers.slice(0, 5).map((c) => ({\n        type: \"customer\",\n        id: c.id,\n      })),\n      suggestedActions: [\n        \"Send re-engagement emails\",\n        \"Offer special promotions for returning customers\",\n        \"Schedule follow-up calls\",\n      ],\n    });\n  }\n\n  return insights;\n}\n\n/**\n * Run scheduling analysis to identify capacity issues\n */\nexport async function analyzeScheduling(companyId: string): Promise<Insight[]> {\n  const supabase = createServiceSupabaseClient();\n  const insights: Insight[] = [];\n\n  // Check for overbooking\n  const nextWeek = new Date(Date.now() + 7 * 24 * 60 * 60 * 1000);\n\n  const { data: upcomingJobs } = await supabase\n    .from(\"jobs\")\n    .select(\"id, scheduled_start, scheduled_end, status\")\n    .eq(\"company_id\", companyId)\n    .gte(\"scheduled_start\", new Date().toISOString())\n    .lte(\"scheduled_start\", nextWeek.toISOString())\n    .in(\"status\", [\"scheduled\", \"pending\"]);\n\n  if (upcomingJobs && upcomingJobs.length > 0) {\n    // Group by day\n    const jobsByDay: Record<string, number> = {};\n    for (const job of upcomingJobs) {\n      const day = new Date(job.scheduled_start as string).toISOString().split(\"T\")[0];\n      jobsByDay[day] = (jobsByDay[day] || 0) + 1;\n    }\n\n    // Check for days with high job counts\n    const highVolumeDays = Object.entries(jobsByDay).filter(([, count]) => count > 10);\n    if (highVolumeDays.length > 0) {\n      insights.push({\n        type: \"risk\",\n        priority: \"medium\",\n        category: \"scheduling\",\n        title: \"High Job Volume Days Detected\",\n        description: `${highVolumeDays.length} days in the next week have more than 10 scheduled jobs.`,\n        dataPoints: {\n          highVolumeDays: highVolumeDays.map(([day, count]) => ({ day, count })),\n        },\n        suggestedActions: [\n          \"Review team availability for high-volume days\",\n          \"Consider rescheduling non-urgent jobs\",\n          \"Assign additional technicians if available\",\n        ],\n      });\n    }\n  }\n\n  return insights;\n}\n\n/**\n * Run full proactive analysis (call all analyzers)\n */\nexport async function runFullAnalysis(companyId: string): Promise<{\n  totalInsights: number;\n  byCategory: Record<string, number>;\n  byPriority: Record<string, number>;\n}> {\n  const allInsights: Insight[] = [];\n\n  // Run all analyzers\n  const [revenueInsights, customerInsights, schedulingInsights] = await Promise.all([\n    analyzeRevenue(companyId),\n    analyzeCustomers(companyId),\n    analyzeScheduling(companyId),\n  ]);\n\n  allInsights.push(...revenueInsights, ...customerInsights, ...schedulingInsights);\n\n  // Store insights\n  for (const insight of allInsights) {\n    try {\n      await createInsight(companyId, insight, \"proactive_analysis\");\n    } catch (error) {\n      console.error(\"Failed to store insight:\", error);\n    }\n  }\n\n  // Calculate statistics\n  const byCategory: Record<string, number> = {};\n  const byPriority: Record<string, number> = {};\n\n  for (const insight of allInsights) {\n    byCategory[insight.category] = (byCategory[insight.category] || 0) + 1;\n    byPriority[insight.priority] = (byPriority[insight.priority] || 0) + 1;\n  }\n\n  return {\n    totalInsights: allInsights.length,\n    byCategory,\n    byPriority,\n  };\n}\n\n/**\n * Get insight statistics for monitoring dashboard\n */\nexport async function getInsightStatistics(\n  companyId: string,\n  dateRange: { start: Date; end: Date }\n): Promise<{\n  totalInsights: number;\n  byStatus: Record<string, number>;\n  byPriority: Record<string, number>;\n  byCategory: Record<string, number>;\n  avgTimeToAcknowledge: number;\n  avgTimeToResolve: number;\n  dismissalRate: number;\n}> {\n  const supabase = createServiceSupabaseClient();\n\n  const { data, error } = await supabase\n    .from(\"ai_insights\")\n    .select(\"*\")\n    .eq(\"company_id\", companyId)\n    .gte(\"created_at\", dateRange.start.toISOString())\n    .lte(\"created_at\", dateRange.end.toISOString());\n\n  if (error || !data) {\n    return {\n      totalInsights: 0,\n      byStatus: {},\n      byPriority: {},\n      byCategory: {},\n      avgTimeToAcknowledge: 0,\n      avgTimeToResolve: 0,\n      dismissalRate: 0,\n    };\n  }\n\n  const byStatus: Record<string, number> = {};\n  const byPriority: Record<string, number> = {};\n  const byCategory: Record<string, number> = {};\n  const acknowledgeTimes: number[] = [];\n  const resolveTimes: number[] = [];\n  let dismissedCount = 0;\n\n  for (const insight of data) {\n    byStatus[insight.status] = (byStatus[insight.status] || 0) + 1;\n    byPriority[insight.priority] = (byPriority[insight.priority] || 0) + 1;\n    byCategory[insight.category] = (byCategory[insight.category] || 0) + 1;\n\n    if (insight.status === \"dismissed\") {\n      dismissedCount++;\n    }\n\n    if (insight.acknowledged_at) {\n      const ackTime =\n        new Date(insight.acknowledged_at as string).getTime() -\n        new Date(insight.created_at as string).getTime();\n      acknowledgeTimes.push(ackTime);\n    }\n\n    if (insight.resolved_at) {\n      const resolveTime =\n        new Date(insight.resolved_at as string).getTime() -\n        new Date(insight.created_at as string).getTime();\n      resolveTimes.push(resolveTime);\n    }\n  }\n\n  return {\n    totalInsights: data.length,\n    byStatus,\n    byPriority,\n    byCategory,\n    avgTimeToAcknowledge:\n      acknowledgeTimes.length > 0\n        ? Math.round(acknowledgeTimes.reduce((a, b) => a + b, 0) / acknowledgeTimes.length / 60000)\n        : 0, // in minutes\n    avgTimeToResolve:\n      resolveTimes.length > 0\n        ? Math.round(resolveTimes.reduce((a, b) => a + b, 0) / resolveTimes.length / 60000)\n        : 0, // in minutes\n    dismissalRate: data.length > 0 ? (dismissedCount / data.length) * 100 : 0,\n  };\n}\n","/**\n * AI Planner Service - Multi-step planning with approval workflow\n * Based on ReAct and Chain-of-Thought reasoning patterns\n */\n\nimport { createServiceSupabaseClient } from \"@/lib/supabase/service-client\";\nimport crypto from \"crypto\";\n\nexport type PlanStatus =\n  | \"draft\"\n  | \"pending_approval\"\n  | \"approved\"\n  | \"in_progress\"\n  | \"completed\"\n  | \"failed\"\n  | \"cancelled\";\n\nexport type StepStatus = \"pending\" | \"in_progress\" | \"completed\" | \"failed\" | \"skipped\";\n\nexport type StepType =\n  | \"query\"\n  | \"create\"\n  | \"update\"\n  | \"delete\"\n  | \"tool_call\"\n  | \"analysis\"\n  | \"notification\"\n  | \"wait\"\n  | \"conditional\";\n\nexport interface PlanStep {\n  stepNumber: number;\n  description: string;\n  stepType: StepType;\n  toolName?: string;\n  toolParams?: Record<string, unknown>;\n  entityType?: string;\n  entityId?: string;\n  expectedOutcome?: string;\n  dependsOn?: number[];\n  isReversible: boolean;\n  requiresApproval: boolean;\n  estimatedDurationMs?: number;\n}\n\nexport interface Plan {\n  id: string;\n  title: string;\n  description: string;\n  steps: PlanStep[];\n  status: PlanStatus;\n  createdAt: string;\n  approvedAt?: string;\n  completedAt?: string;\n}\n\nexport interface PlanExecutionResult {\n  planId: string;\n  status: \"completed\" | \"partial\" | \"failed\";\n  completedSteps: number;\n  totalSteps: number;\n  results: Array<{\n    stepNumber: number;\n    status: StepStatus;\n    result?: Record<string, unknown>;\n    error?: string;\n    durationMs: number;\n  }>;\n}\n\n/**\n * Create a new multi-step plan\n */\nexport async function createPlan(\n  companyId: string,\n  userId: string,\n  chatId: string,\n  messageId: string,\n  plan: {\n    title: string;\n    description: string;\n    steps: PlanStep[];\n    requiresApproval?: boolean;\n  }\n): Promise<string> {\n  const supabase = createServiceSupabaseClient();\n  const planId = crypto.randomUUID();\n\n  // Calculate total estimated duration\n  const estimatedDuration = plan.steps.reduce(\n    (sum, step) => sum + (step.estimatedDurationMs || 1000),\n    0\n  );\n\n  // Check if any step requires approval\n  const hasApprovalRequired =\n    plan.requiresApproval || plan.steps.some((step) => step.requiresApproval);\n\n  const { error } = await supabase.from(\"ai_plans\").insert({\n    id: planId,\n    company_id: companyId,\n    user_id: userId,\n    chat_id: chatId,\n    message_id: messageId,\n    title: plan.title,\n    description: plan.description,\n    steps: plan.steps,\n    total_steps: plan.steps.length,\n    completed_steps: 0,\n    status: hasApprovalRequired ? \"pending_approval\" : \"draft\",\n    requires_approval: hasApprovalRequired,\n    estimated_duration_ms: estimatedDuration,\n    created_at: new Date().toISOString(),\n  });\n\n  if (error) {\n    console.error(\"Failed to create plan:\", error);\n    throw error;\n  }\n\n  return planId;\n}\n\n/**\n * Get a plan by ID\n */\nexport async function getPlan(companyId: string, planId: string): Promise<Plan | null> {\n  const supabase = createServiceSupabaseClient();\n\n  const { data, error } = await supabase\n    .from(\"ai_plans\")\n    .select(\"*\")\n    .eq(\"id\", planId)\n    .eq(\"company_id\", companyId)\n    .single();\n\n  if (error || !data) {\n    return null;\n  }\n\n  return {\n    id: data.id,\n    title: data.title,\n    description: data.description,\n    steps: data.steps as PlanStep[],\n    status: data.status as PlanStatus,\n    createdAt: data.created_at as string,\n    approvedAt: data.approved_at as string | undefined,\n    completedAt: data.completed_at as string | undefined,\n  };\n}\n\n/**\n * Approve a plan for execution\n */\nexport async function approvePlan(\n  companyId: string,\n  planId: string,\n  approvedBy: string\n): Promise<boolean> {\n  const supabase = createServiceSupabaseClient();\n\n  const { error } = await supabase\n    .from(\"ai_plans\")\n    .update({\n      status: \"approved\",\n      approved_by: approvedBy,\n      approved_at: new Date().toISOString(),\n    })\n    .eq(\"id\", planId)\n    .eq(\"company_id\", companyId)\n    .eq(\"status\", \"pending_approval\");\n\n  if (error) {\n    console.error(\"Failed to approve plan:\", error);\n    return false;\n  }\n\n  return true;\n}\n\n/**\n * Reject a plan\n */\nexport async function rejectPlan(\n  companyId: string,\n  planId: string,\n  rejectedBy: string,\n  reason: string\n): Promise<boolean> {\n  const supabase = createServiceSupabaseClient();\n\n  const { error } = await supabase\n    .from(\"ai_plans\")\n    .update({\n      status: \"cancelled\",\n      rejection_reason: reason,\n      rejected_by: rejectedBy,\n      rejected_at: new Date().toISOString(),\n    })\n    .eq(\"id\", planId)\n    .eq(\"company_id\", companyId)\n    .eq(\"status\", \"pending_approval\");\n\n  if (error) {\n    console.error(\"Failed to reject plan:\", error);\n    return false;\n  }\n\n  return true;\n}\n\n/**\n * Update plan execution progress\n */\nexport async function updatePlanProgress(\n  companyId: string,\n  planId: string,\n  stepNumber: number,\n  stepResult: {\n    status: StepStatus;\n    result?: Record<string, unknown>;\n    error?: string;\n    durationMs: number;\n  }\n): Promise<void> {\n  const supabase = createServiceSupabaseClient();\n\n  // Get current plan\n  const { data: plan, error: fetchError } = await supabase\n    .from(\"ai_plans\")\n    .select(\"steps, completed_steps, total_steps, execution_results\")\n    .eq(\"id\", planId)\n    .eq(\"company_id\", companyId)\n    .single();\n\n  if (fetchError || !plan) {\n    console.error(\"Failed to fetch plan:\", fetchError);\n    return;\n  }\n\n  // Update step status in the steps array\n  const steps = plan.steps as PlanStep[];\n  const stepIndex = steps.findIndex((s) => s.stepNumber === stepNumber);\n  if (stepIndex >= 0) {\n    // Note: We're not modifying steps directly since PlanStep doesn't have status\n    // Instead we track in execution_results\n  }\n\n  // Update execution results\n  const executionResults = (plan.execution_results as Array<{\n    stepNumber: number;\n    status: StepStatus;\n    result?: Record<string, unknown>;\n    error?: string;\n    durationMs: number;\n  }>) || [];\n\n  const existingIndex = executionResults.findIndex((r) => r.stepNumber === stepNumber);\n  if (existingIndex >= 0) {\n    executionResults[existingIndex] = { stepNumber, ...stepResult };\n  } else {\n    executionResults.push({ stepNumber, ...stepResult });\n  }\n\n  // Calculate completed steps\n  const completedSteps = executionResults.filter(\n    (r) => r.status === \"completed\" || r.status === \"skipped\"\n  ).length;\n\n  // Determine overall status\n  let planStatus: PlanStatus = \"in_progress\";\n  if (stepResult.status === \"failed\") {\n    planStatus = \"failed\";\n  } else if (completedSteps >= plan.total_steps) {\n    planStatus = \"completed\";\n  }\n\n  const { error: updateError } = await supabase\n    .from(\"ai_plans\")\n    .update({\n      steps,\n      completed_steps: completedSteps,\n      current_step: stepNumber,\n      execution_results: executionResults,\n      status: planStatus,\n      ...(planStatus === \"completed\" ? { completed_at: new Date().toISOString() } : {}),\n      ...(planStatus === \"failed\" ? { failed_at: new Date().toISOString() } : {}),\n    })\n    .eq(\"id\", planId)\n    .eq(\"company_id\", companyId);\n\n  if (updateError) {\n    console.error(\"Failed to update plan progress:\", updateError);\n  }\n}\n\n/**\n * Start plan execution\n */\nexport async function startPlanExecution(\n  companyId: string,\n  planId: string\n): Promise<boolean> {\n  const supabase = createServiceSupabaseClient();\n\n  const { error } = await supabase\n    .from(\"ai_plans\")\n    .update({\n      status: \"in_progress\",\n      started_at: new Date().toISOString(),\n      current_step: 1,\n    })\n    .eq(\"id\", planId)\n    .eq(\"company_id\", companyId)\n    .in(\"status\", [\"draft\", \"approved\"]);\n\n  if (error) {\n    console.error(\"Failed to start plan execution:\", error);\n    return false;\n  }\n\n  return true;\n}\n\n/**\n * Cancel a plan in progress\n */\nexport async function cancelPlan(\n  companyId: string,\n  planId: string,\n  cancelledBy: string,\n  reason: string\n): Promise<boolean> {\n  const supabase = createServiceSupabaseClient();\n\n  const { error } = await supabase\n    .from(\"ai_plans\")\n    .update({\n      status: \"cancelled\",\n      cancellation_reason: reason,\n      cancelled_by: cancelledBy,\n      cancelled_at: new Date().toISOString(),\n    })\n    .eq(\"id\", planId)\n    .eq(\"company_id\", companyId)\n    .in(\"status\", [\"draft\", \"pending_approval\", \"approved\", \"in_progress\"]);\n\n  if (error) {\n    console.error(\"Failed to cancel plan:\", error);\n    return false;\n  }\n\n  return true;\n}\n\n/**\n * Get plans for a chat session\n */\nexport async function getChatPlans(\n  companyId: string,\n  chatId: string,\n  options?: { status?: PlanStatus; limit?: number }\n): Promise<\n  Array<{\n    id: string;\n    title: string;\n    status: PlanStatus;\n    totalSteps: number;\n    completedSteps: number;\n    createdAt: string;\n  }>\n> {\n  const supabase = createServiceSupabaseClient();\n  const limit = options?.limit || 20;\n\n  let query = supabase\n    .from(\"ai_plans\")\n    .select(\"id, title, status, total_steps, completed_steps, created_at\")\n    .eq(\"company_id\", companyId)\n    .eq(\"chat_id\", chatId)\n    .order(\"created_at\", { ascending: false })\n    .limit(limit);\n\n  if (options?.status) {\n    query = query.eq(\"status\", options.status);\n  }\n\n  const { data, error } = await query;\n\n  if (error) {\n    console.error(\"Failed to get chat plans:\", error);\n    return [];\n  }\n\n  return (data || []).map((p) => ({\n    id: p.id,\n    title: p.title,\n    status: p.status as PlanStatus,\n    totalSteps: p.total_steps,\n    completedSteps: p.completed_steps,\n    createdAt: p.created_at as string,\n  }));\n}\n\n/**\n * Get pending approval plans for a company (admin dashboard)\n */\nexport async function getPendingApprovalPlans(\n  companyId: string,\n  options?: { limit?: number }\n): Promise<\n  Array<{\n    id: string;\n    title: string;\n    description: string;\n    totalSteps: number;\n    userId: string;\n    chatId: string;\n    createdAt: string;\n    estimatedDurationMs: number;\n  }>\n> {\n  const supabase = createServiceSupabaseClient();\n  const limit = options?.limit || 20;\n\n  const { data, error } = await supabase\n    .from(\"ai_plans\")\n    .select(\n      \"id, title, description, total_steps, user_id, chat_id, created_at, estimated_duration_ms\"\n    )\n    .eq(\"company_id\", companyId)\n    .eq(\"status\", \"pending_approval\")\n    .order(\"created_at\", { ascending: true })\n    .limit(limit);\n\n  if (error) {\n    console.error(\"Failed to get pending approval plans:\", error);\n    return [];\n  }\n\n  return (data || []).map((p) => ({\n    id: p.id,\n    title: p.title,\n    description: p.description,\n    totalSteps: p.total_steps,\n    userId: p.user_id,\n    chatId: p.chat_id,\n    createdAt: p.created_at as string,\n    estimatedDurationMs: p.estimated_duration_ms,\n  }));\n}\n\n/**\n * Get plan execution statistics\n */\nexport async function getPlanStatistics(\n  companyId: string,\n  dateRange: { start: Date; end: Date }\n): Promise<{\n  totalPlans: number;\n  completedPlans: number;\n  failedPlans: number;\n  cancelledPlans: number;\n  avgCompletionRate: number;\n  avgDurationMs: number;\n  pendingApprovals: number;\n}> {\n  const supabase = createServiceSupabaseClient();\n\n  const { data, error } = await supabase\n    .from(\"ai_plans\")\n    .select(\"status, completed_steps, total_steps, estimated_duration_ms, actual_duration_ms\")\n    .eq(\"company_id\", companyId)\n    .gte(\"created_at\", dateRange.start.toISOString())\n    .lte(\"created_at\", dateRange.end.toISOString());\n\n  if (error || !data) {\n    return {\n      totalPlans: 0,\n      completedPlans: 0,\n      failedPlans: 0,\n      cancelledPlans: 0,\n      avgCompletionRate: 0,\n      avgDurationMs: 0,\n      pendingApprovals: 0,\n    };\n  }\n\n  const completedPlans = data.filter((p) => p.status === \"completed\").length;\n  const failedPlans = data.filter((p) => p.status === \"failed\").length;\n  const cancelledPlans = data.filter((p) => p.status === \"cancelled\").length;\n  const pendingApprovals = data.filter((p) => p.status === \"pending_approval\").length;\n\n  // Calculate average completion rate\n  const completionRates = data\n    .filter((p) => p.total_steps > 0)\n    .map((p) => (p.completed_steps / p.total_steps) * 100);\n  const avgCompletionRate =\n    completionRates.length > 0\n      ? completionRates.reduce((a, b) => a + b, 0) / completionRates.length\n      : 0;\n\n  // Calculate average duration\n  const durations = data\n    .filter((p) => p.actual_duration_ms)\n    .map((p) => p.actual_duration_ms as number);\n  const avgDurationMs =\n    durations.length > 0 ? durations.reduce((a, b) => a + b, 0) / durations.length : 0;\n\n  return {\n    totalPlans: data.length,\n    completedPlans,\n    failedPlans,\n    cancelledPlans,\n    avgCompletionRate: Math.round(avgCompletionRate * 100) / 100,\n    avgDurationMs: Math.round(avgDurationMs),\n    pendingApprovals,\n  };\n}\n\n/**\n * Generate a plan from natural language description\n * This is a simplified version - in production, use an LLM\n */\nexport function generatePlanFromDescription(\n  description: string,\n  context: { entityType?: string; entityId?: string }\n): PlanStep[] {\n  // This is a placeholder - in production, use an LLM to generate the plan\n  // For now, we'll return a basic structure\n\n  const steps: PlanStep[] = [\n    {\n      stepNumber: 1,\n      description: \"Analyze the request and gather context\",\n      stepType: \"analysis\",\n      isReversible: false,\n      requiresApproval: false,\n      estimatedDurationMs: 500,\n    },\n    {\n      stepNumber: 2,\n      description: `Execute the main action: ${description.substring(0, 100)}`,\n      stepType: context.entityId ? \"update\" : \"query\",\n      entityType: context.entityType,\n      entityId: context.entityId,\n      isReversible: true,\n      requiresApproval: true,\n      estimatedDurationMs: 1000,\n    },\n    {\n      stepNumber: 3,\n      description: \"Verify the results and report back\",\n      stepType: \"analysis\",\n      dependsOn: [2],\n      isReversible: false,\n      requiresApproval: false,\n      estimatedDurationMs: 500,\n    },\n  ];\n\n  return steps;\n}\n","import type { z } from \"zod\";\n\nexport type ArtifactStatus =\n  | \"idle\"\n  | \"loading\"\n  | \"streaming\"\n  | \"complete\"\n  | \"error\";\n\nexport class ArtifactError extends Error {\n  constructor(\n    public code: string,\n    message: string,\n  ) {\n    super(message);\n    this.name = \"ArtifactError\";\n  }\n}\n\nexport interface ArtifactData<T = unknown> {\n  id: string;\n  type: string;\n  status: ArtifactStatus;\n  payload: T;\n  version: number;\n  progress?: number;\n  error?: string;\n  createdAt: number;\n  updatedAt: number;\n}\n\nexport interface ArtifactConfig<T = unknown> {\n  id: string;\n  schema: z.ZodSchema<T>;\n}\n\nexport interface ArtifactStreamPart<T = unknown> {\n  type: `data-artifact-${string}`;\n  id: string;\n  data: ArtifactData<T>;\n}\n\nexport interface ArtifactCallbacks<T = unknown> {\n  onUpdate?: (data: T, prevData: T | null) => void;\n  onComplete?: (data: T) => void;\n  onError?: (error: string, data: T | null) => void;\n  onProgress?: (progress: number, data: T) => void;\n  onStatusChange?: (status: ArtifactStatus, prevStatus: ArtifactStatus) => void;\n}\n\nexport interface UseArtifactOptions<T = unknown> extends ArtifactCallbacks<T> {\n  version?: number;\n}\n\nexport interface UseArtifactReturn<T = unknown> {\n  data: T | null;\n  status: ArtifactStatus;\n  progress?: number;\n  error?: string;\n  isActive: boolean;\n  hasData: boolean;\n  versions: ArtifactData<T>[];\n  currentIndex?: number;\n}\n\nexport interface UseArtifactActions {\n  delete: (artifactId: string) => void;\n}\n\nexport interface UseArtifactsOptions {\n  onData?: (artifactType: string, data: ArtifactData<unknown>) => void;\n  storeId?: string;\n  include?: string[]; // Only listen to these artifact types\n  exclude?: string[]; // Ignore these artifact types\n  value?: string | null; // Optional: externally controlled active type\n  onChange?: (value: string | null) => void; // Optional: callback when active type changes\n  dismissed?: string[]; // Optional: externally controlled dismissed types\n  onDismissedChange?: (dismissed: string[]) => void; // Optional: callback when dismissed types change\n}\n\nexport interface UseArtifactsReturn {\n  byType: Record<string, ArtifactData<unknown>[]>;\n  latestByType: Record<string, ArtifactData<unknown>>;\n  artifacts: ArtifactData<unknown>[];\n  current: ArtifactData<unknown> | null;\n  activeType: string | null;\n  activeArtifacts: ArtifactData<unknown>[];\n  types: string[];\n  latestArtifactType: string | null;\n  available: string[];\n  dismissed: string[];\n}\n\nexport interface UseArtifactsActions {\n  setValue: (value: string | null) => void;\n  dismiss: (type: string) => void;\n  restore: (type: string) => void;\n}\n","import type { UIMessageStreamWriter } from \"ai\";\nimport type { ArtifactConfig, ArtifactData } from \"./types\";\n\nexport class StreamingArtifact<T> {\n  private config: ArtifactConfig<T>;\n  private instance: ArtifactData<T>;\n  private writer: UIMessageStreamWriter;\n\n  constructor(\n    config: ArtifactConfig<T>,\n    instance: ArtifactData<T>,\n    writer: UIMessageStreamWriter,\n  ) {\n    this.config = config;\n    this.instance = instance;\n    this.writer = writer;\n\n    // Send initial state\n    this.stream();\n  }\n\n  get data(): T {\n    return this.instance.payload;\n  }\n\n  get id(): string {\n    return this.instance.id;\n  }\n\n  get progress(): number | undefined {\n    return this.instance.progress;\n  }\n\n  set progress(value: number | undefined) {\n    this.instance.progress = value;\n    this.instance.updatedAt = Date.now();\n    this.stream();\n  }\n\n  async update(updates: Partial<T> & { progress?: number }): Promise<void> {\n    if (\"progress\" in updates) {\n      this.instance.progress = updates.progress;\n      delete (updates as Record<string, unknown>).progress; // Remove progress from payload updates\n    }\n\n    this.instance.payload = { ...this.instance.payload, ...updates };\n    this.instance.status = \"streaming\";\n    this.instance.version++;\n    this.instance.updatedAt = Date.now();\n    this.stream();\n  }\n\n  async complete(finalData?: T): Promise<void> {\n    if (finalData) {\n      this.instance.payload = finalData;\n    }\n    this.instance.status = \"complete\";\n    this.instance.progress = 1;\n    this.instance.version++;\n    this.instance.updatedAt = Date.now();\n    this.stream();\n  }\n\n  async error(message: string): Promise<void> {\n    this.instance.status = \"error\";\n    this.instance.error = message;\n    this.instance.version++;\n    this.instance.updatedAt = Date.now();\n    this.stream();\n  }\n\n  async cancel(): Promise<void> {\n    this.instance.status = \"error\";\n    this.instance.error = \"Artifact was cancelled\";\n    this.instance.version++;\n    this.instance.updatedAt = Date.now();\n    this.stream();\n  }\n\n  timeout(ms: number): void {\n    setTimeout(() => {\n      if (\n        this.instance.status === \"loading\" ||\n        this.instance.status === \"streaming\"\n      ) {\n        this.error(`Artifact timed out after ${ms}ms`);\n      }\n    }, ms);\n  }\n\n  private stream(): void {\n    this.writer.write({\n      type: `data-artifact-${this.config.id}`,\n      id: this.instance.id,\n      data: this.instance,\n    });\n  }\n}\n","import type { UIMessageStreamWriter } from \"ai\";\nimport type { z } from \"zod\";\nimport { StreamingArtifact } from \"./streaming\";\nimport type { ArtifactConfig, ArtifactData } from \"./types\";\nimport { generateId, getDefaults } from \"./utils\";\n\nexport function artifact<T>(id: string, schema: z.ZodSchema<T>) {\n  const config: ArtifactConfig<T> = { id, schema };\n\n  return {\n    id,\n    schema,\n\n    create(data: Partial<T> = {}): ArtifactData<T> {\n      const defaults = getDefaults(schema);\n      const validated = schema.parse({ ...defaults, ...data });\n\n      return {\n        id: generateId(),\n        type: id,\n        status: \"idle\",\n        payload: validated,\n        version: 1,\n        createdAt: Date.now(),\n        updatedAt: Date.now(),\n      };\n    },\n\n    stream(\n      data: Partial<T>,\n      writer: UIMessageStreamWriter,\n    ): StreamingArtifact<T> {\n      const instance = this.create(data);\n      instance.status = \"loading\";\n      return new StreamingArtifact(config, instance, writer);\n    },\n\n    validate(data: unknown): T {\n      return schema.parse(data);\n    },\n\n    isValid(data: unknown): data is T {\n      try {\n        schema.parse(data);\n        return true;\n      } catch {\n        return false;\n      }\n    },\n  };\n}\n","import type { z } from \"zod\";\n\nexport type ArtifactStatus =\n  | \"idle\"\n  | \"loading\"\n  | \"streaming\"\n  | \"complete\"\n  | \"error\";\n\nexport class ArtifactError extends Error {\n  constructor(\n    public code: string,\n    message: string,\n  ) {\n    super(message);\n    this.name = \"ArtifactError\";\n  }\n}\n\nexport interface ArtifactData<T = unknown> {\n  id: string;\n  type: string;\n  status: ArtifactStatus;\n  payload: T;\n  version: number;\n  progress?: number;\n  error?: string;\n  createdAt: number;\n  updatedAt: number;\n}\n\nexport interface ArtifactConfig<T = unknown> {\n  id: string;\n  schema: z.ZodSchema<T>;\n}\n\nexport interface ArtifactStreamPart<T = unknown> {\n  type: `data-artifact-${string}`;\n  id: string;\n  data: ArtifactData<T>;\n}\n\nexport interface ArtifactCallbacks<T = unknown> {\n  onUpdate?: (data: T, prevData: T | null) => void;\n  onComplete?: (data: T) => void;\n  onError?: (error: string, data: T | null) => void;\n  onProgress?: (progress: number, data: T) => void;\n  onStatusChange?: (status: ArtifactStatus, prevStatus: ArtifactStatus) => void;\n}\n\nexport interface UseArtifactOptions<T = unknown> extends ArtifactCallbacks<T> {\n  version?: number;\n}\n\nexport interface UseArtifactReturn<T = unknown> {\n  data: T | null;\n  status: ArtifactStatus;\n  progress?: number;\n  error?: string;\n  isActive: boolean;\n  hasData: boolean;\n  versions: ArtifactData<T>[];\n  currentIndex?: number;\n}\n\nexport interface UseArtifactActions {\n  delete: (artifactId: string) => void;\n}\n\nexport interface UseArtifactsOptions {\n  onData?: (artifactType: string, data: ArtifactData<unknown>) => void;\n  storeId?: string;\n  include?: string[]; // Only listen to these artifact types\n  exclude?: string[]; // Ignore these artifact types\n  value?: string | null; // Optional: externally controlled active type\n  onChange?: (value: string | null) => void; // Optional: callback when active type changes\n  dismissed?: string[]; // Optional: externally controlled dismissed types\n  onDismissedChange?: (dismissed: string[]) => void; // Optional: callback when dismissed types change\n}\n\nexport interface UseArtifactsReturn {\n  byType: Record<string, ArtifactData<unknown>[]>;\n  latestByType: Record<string, ArtifactData<unknown>>;\n  artifacts: ArtifactData<unknown>[];\n  current: ArtifactData<unknown> | null;\n  activeType: string | null;\n  activeArtifacts: ArtifactData<unknown>[];\n  types: string[];\n  latestArtifactType: string | null;\n  available: string[];\n  dismissed: string[];\n}\n\nexport interface UseArtifactsActions {\n  setValue: (value: string | null) => void;\n  dismiss: (type: string) => void;\n  restore: (type: string) => void;\n}\n","import { tool } from \"ai\";\nimport { z } from \"zod\";\nimport type { \n  Agent, \n  HandoffInstruction, \n  HandoffConfig, \n  ConfiguredHandoff,\n} from \"./types.js\";\n\n/**\n * Creates a handoff instruction for transferring to another agent\n */\nexport function createHandoff(\n  targetAgent: Agent | string,\n  context?: string,\n  reason?: string,\n): HandoffInstruction {\n  const targetName =\n    typeof targetAgent === \"string\" ? targetAgent : targetAgent.name;\n\n  return {\n    targetAgent: targetName,\n    context,\n    reason,\n  };\n}\n\n/**\n * Creates a configured handoff from an agent\n */\nexport function handoff<TContext extends Record<string, unknown> = Record<string, unknown>>(\n  agent: Agent<TContext>,\n  config?: HandoffConfig<TContext>\n): ConfiguredHandoff<TContext> {\n  return {\n    agent,\n    config,\n  };\n}\n\n/**\n * Generates the message that will be given as tool output to the model that requested the handoff\n */\nexport function getTransferMessage<TContext extends Record<string, unknown>>(agent: Agent<TContext>): string {\n  return JSON.stringify({ assistant: agent.name });\n}\n\n/**\n * Handoff tool that agents can use to transfer to other agents\n * Updated to work with ConfiguredHandoff\n */\nexport function createHandoffTool(availableHandoffs: Array<Agent | ConfiguredHandoff>) {\n  const agentNames = availableHandoffs.map((h) => \n    'agent' in h ? h.agent.name : h.name\n  );\n\n  return tool({\n    description: `Transfer the conversation to another specialized agent.\n    \nAvailable agents: ${agentNames.join(', ')}`,\n    inputSchema: z.object({\n      targetAgent: z.enum(agentNames as [string, ...string[]]),\n      context: z\n        .string()\n        .optional()\n        .describe(\"Context or summary to pass to the target agent\"),\n      reason: z.string().optional().describe(\"Reason for the handoff\"),\n    }),\n    execute: async ({ targetAgent, context, reason }) => {\n      // This will be handled by the runner\n      return createHandoff(targetAgent, context, reason);\n    },\n  });\n}\n\n/**\n * The standard name for the handoff tool\n */\nexport const HANDOFF_TOOL_NAME = \"handoff_to_agent\";\n\n/**\n * Checks if a tool name is the handoff tool\n */\nexport function isHandoffTool(toolName: string | undefined): boolean {\n  return toolName === HANDOFF_TOOL_NAME;\n}\n\n/**\n * Checks if a result contains a handoff instruction\n */\nexport function isHandoffResult(result: unknown): result is HandoffInstruction {\n  return (\n    typeof result === \"object\" &&\n    result !== null &&\n    \"targetAgent\" in result &&\n    typeof (result as HandoffInstruction).targetAgent === \"string\"\n  );\n}\n","import type { CacheEntry, CacheStore } from \"./types\";\n\n/**\n * LRU (Least Recently Used) cache implementation\n */\nexport class LRUCacheStore<T = any> implements CacheStore<T> {\n  private cache = new Map<string, CacheEntry<T>>();\n  private maxSize: number;\n\n  constructor(maxSize = 1000) {\n    this.maxSize = maxSize;\n  }\n\n  get(key: string): CacheEntry<T> | undefined {\n    const entry = this.cache.get(key);\n    if (entry) {\n      // Move to end (most recently used)\n      this.cache.delete(key);\n      this.cache.set(key, entry);\n    }\n    return entry;\n  }\n\n  set(key: string, entry: CacheEntry<T>): void {\n    // Remove if already exists\n    if (this.cache.has(key)) {\n      this.cache.delete(key);\n    }\n    // Evict oldest if at capacity\n    else if (this.cache.size >= this.maxSize) {\n      const firstKey = this.cache.keys().next().value;\n      if (firstKey) {\n        this.cache.delete(firstKey);\n      }\n    }\n\n    this.cache.set(key, entry);\n  }\n\n  delete(key: string): boolean {\n    return this.cache.delete(key);\n  }\n\n  clear(): void {\n    this.cache.clear();\n  }\n\n  has(key: string): boolean {\n    return this.cache.has(key);\n  }\n\n  size(): number {\n    return this.cache.size;\n  }\n\n  keys(): string[] {\n    return Array.from(this.cache.keys());\n  }\n\n  getDefaultTTL?(): number | undefined {\n    return undefined;\n  }\n}\n\n/**\n * Simple Map-based cache store (no LRU eviction)\n */\nexport class SimpleCacheStore<T = any> implements CacheStore<T> {\n  private cache = new Map<string, CacheEntry<T>>();\n  private maxSize: number;\n\n  constructor(maxSize = 1000) {\n    this.maxSize = maxSize;\n  }\n\n  get(key: string): CacheEntry<T> | undefined {\n    return this.cache.get(key);\n  }\n\n  set(key: string, entry: CacheEntry<T>): void {\n    // Simple eviction: clear all if at capacity\n    if (this.cache.size >= this.maxSize) {\n      this.cache.clear();\n    }\n    this.cache.set(key, entry);\n  }\n\n  delete(key: string): boolean {\n    return this.cache.delete(key);\n  }\n\n  clear(): void {\n    this.cache.clear();\n  }\n\n  has(key: string): boolean {\n    return this.cache.has(key);\n  }\n\n  size(): number {\n    return this.cache.size;\n  }\n\n  keys(): string[] {\n    return Array.from(this.cache.keys());\n  }\n\n  getDefaultTTL?(): number | undefined {\n    return undefined;\n  }\n}\n","import type { CacheEntry, CacheStore } from \"../types\";\n\n/**\n * Enhanced memory cache store with better performance characteristics\n */\nexport class MemoryCacheStore<T = any> implements CacheStore<T> {\n  private cache = new Map<string, CacheEntry<T>>();\n  private accessOrder = new Map<string, number>();\n  private maxSize: number;\n  private accessCounter = 0;\n\n  constructor(maxSize = 1000) {\n    this.maxSize = maxSize;\n  }\n\n  get(key: string): CacheEntry<T> | undefined {\n    const entry = this.cache.get(key);\n    if (entry) {\n      // Update access order for LRU\n      this.accessOrder.set(key, ++this.accessCounter);\n    }\n    return entry;\n  }\n\n  set(key: string, entry: CacheEntry<T>): void {\n    // If key already exists, just update it\n    if (this.cache.has(key)) {\n      this.cache.set(key, entry);\n      this.accessOrder.set(key, ++this.accessCounter);\n      return;\n    }\n\n    // If at capacity, evict least recently used\n    if (this.cache.size >= this.maxSize) {\n      this.evictLRU();\n    }\n\n    this.cache.set(key, entry);\n    this.accessOrder.set(key, ++this.accessCounter);\n  }\n\n  delete(key: string): boolean {\n    const deleted = this.cache.delete(key);\n    if (deleted) {\n      this.accessOrder.delete(key);\n    }\n    return deleted;\n  }\n\n  clear(): void {\n    this.cache.clear();\n    this.accessOrder.clear();\n    this.accessCounter = 0;\n  }\n\n  has(key: string): boolean {\n    return this.cache.has(key);\n  }\n\n  size(): number {\n    return this.cache.size;\n  }\n\n  keys(): string[] {\n    return Array.from(this.cache.keys());\n  }\n\n  getDefaultTTL?(): number | undefined {\n    return undefined;\n  }\n\n  private evictLRU(): void {\n    let oldestKey: string | undefined;\n    let oldestAccess = Infinity;\n\n    for (const [key, accessTime] of this.accessOrder) {\n      if (accessTime < oldestAccess) {\n        oldestAccess = accessTime;\n        oldestKey = key;\n      }\n    }\n\n    if (oldestKey) {\n      this.cache.delete(oldestKey);\n      this.accessOrder.delete(oldestKey);\n    }\n  }\n\n  /**\n   * Get cache statistics\n   */\n  getStats() {\n    return {\n      size: this.cache.size,\n      maxSize: this.maxSize,\n      utilization: this.cache.size / this.maxSize,\n    };\n  }\n\n  /**\n   * Clean up expired entries based on TTL\n   */\n  cleanup(ttl: number): number {\n    const now = Date.now();\n    let cleaned = 0;\n\n    for (const [key, entry] of this.cache) {\n      if (now - entry.timestamp > ttl) {\n        this.cache.delete(key);\n        this.accessOrder.delete(key);\n        cleaned++;\n      }\n    }\n\n    return cleaned;\n  }\n}\n","/**\n * Tool Result Extractor\n * \n * Extracts tool results from conversation messages to pass to handoff agents\n */\n\nimport type { ModelMessage } from \"ai\";\nimport type { HandoffInputData } from \"./types.js\";\nimport { createLogger } from \"@ai-sdk-tools/debug\";\n\nconst logger = createLogger('TOOL_EXTRACTOR');\n\n/**\n * Extract tool results from conversation messages\n */\nexport function extractToolResults(messages: ModelMessage[]): Record<string, any> {\n  const toolResults: Record<string, any> = {};\n  \n  logger.debug(`Analyzing ${messages.length} messages for tool results`, { count: messages.length });\n  \n  for (let i = 0; i < messages.length; i++) {\n    const message = messages[i];\n    logger.debug(`Message ${i}`, { role: message.role, contentType: typeof message.content });\n    \n    if (message.role === \"assistant\" && message.content) {\n      // Look for tool calls in assistant messages\n      if (Array.isArray(message.content)) {\n        logger.debug(`Assistant message has ${message.content.length} content items`, { count: message.content.length });\n        for (const content of message.content) {\n          logger.debug(`Content item type: ${content.type}`, { type: content.type });\n          if (content.type === \"tool-result\") {\n            const toolName = content.toolName;\n            const result = (content as any).result || (content as any).output;\n            logger.debug(`Found tool result: ${toolName}`, { toolName });\n            if (toolName && result) {\n              toolResults[toolName] = result;\n            }\n          }\n        }\n      }\n    }\n    \n    // Also check for tool results in the message itself\n    if (message.role === \"tool\" && message.content) {\n      // Tool messages contain the result directly\n      const toolName = (message as any).toolName;\n      logger.debug(`Tool message: ${toolName}`, { toolName });\n      if (toolName && message.content) {\n        try {\n          const result = typeof message.content === 'string' \n            ? JSON.parse(message.content) \n            : message.content;\n          toolResults[toolName] = result;\n        } catch (e) {\n          // If not JSON, store as string\n          toolResults[toolName] = message.content;\n        }\n      }\n    }\n  }\n  \n  logger.debug(\"Final tool results\", { tools: Object.keys(toolResults) });\n  return toolResults;\n}\n\n/**\n * Create a default input filter that modifies conversation history to include tool results\n * \n * @internal This is automatically applied during handoffs. You typically don't need to use this directly.\n * Simply use `handoff(agent)` without specifying an inputFilter.\n */\nexport function createDefaultInputFilter(): (input: HandoffInputData) => HandoffInputData {\n  return (input: HandoffInputData) => {\n    logger.debug(`Processing input history with ${input.inputHistory.length} messages`, { \n      historyCount: input.inputHistory.length \n    });\n    logger.debug(`Processing newItems with ${input.newItems.length} items`, { \n      newItemsCount: input.newItems.length \n    });\n    \n    // Extract tool results from newItems\n    const toolResults: Record<string, any> = {};\n    \n    // Process newItems to extract tool results\n    for (const item of input.newItems) {\n      logger.debug(`Processing newItem: ${typeof item}`, { itemType: typeof item });\n      \n      // Check if item has tool results\n      if (item && typeof item === 'object') {\n        // Look for tool result properties\n        if ('toolName' in item && 'result' in item) {\n          const toolName = (item as any).toolName;\n          const result = (item as any).result;\n          if (toolName && result) {\n            toolResults[toolName] = result;\n            logger.debug(`Found tool result in newItems: ${toolName}`, { toolName });\n          }\n        }\n        \n        // Also check for nested tool results\n        if ('content' in item && Array.isArray((item as any).content)) {\n          const content = (item as any).content;\n          for (const contentItem of content) {\n            if (contentItem.type === 'tool-result' && contentItem.toolName && contentItem.result) {\n              toolResults[contentItem.toolName] = contentItem.result;\n              logger.debug(`Found nested tool result: ${contentItem.toolName}`, { toolName: contentItem.toolName });\n            }\n          }\n        }\n      }\n    }\n    \n    logger.debug(\"Extracted tool results from newItems\", { tools: Object.keys(toolResults) });\n    \n    // Create a summary message with the available data\n    if (Object.keys(toolResults).length > 0) {\n      const dataSummary = Object.entries(toolResults)\n        .map(([key, value]) => {\n          // Generic data summary based on value type\n          if (Array.isArray(value)) {\n            return `Available ${key} data: ${value.length} items found`;\n          }\n          if (typeof value === 'object' && value !== null) {\n            return `Available ${key} data: ${JSON.stringify(value)}`;\n          }\n          return `Available ${key} data: ${value}`;\n        })\n        .join('\\n');\n      \n      // Add a system message with the available data\n      const dataMessage: ModelMessage = {\n        role: 'system',\n        content: `Available data from previous agent:\\n${dataSummary}\\n\\n**IMPORTANT**: Only use this data if it's DIRECTLY relevant to the current user question. If the user is asking about something different, ignore this data and call the appropriate tools.`\n      };\n      \n      // Ensure we keep the original conversation and add the data message\n      const enhancedHistory = [...input.inputHistory];\n      if (enhancedHistory.length === 0) {\n        // If no history, add a user message to maintain context\n        enhancedHistory.push({\n          role: 'user',\n          content: 'Please help with the request using the available data.'\n        });\n      }\n      enhancedHistory.push(dataMessage);\n      \n      return {\n        ...input,\n        inputHistory: enhancedHistory,\n      };\n    }\n    \n    return input;\n  };\n}\n\n/**\n * Create an input filter that only passes recent tool results\n */\nexport function createRecentDataFilter(maxAge: number = 5): (input: HandoffInputData) => HandoffInputData {\n  return (input: HandoffInputData) => {\n    // Only look at recent messages (last maxAge messages)\n    const recentMessages = input.inputHistory.slice(-maxAge);\n    const toolResults = extractToolResults(recentMessages);\n    \n    return {\n      ...input,\n      availableData: toolResults,\n    };\n  };\n}\n","import { isToolUIPart, type ModelMessage, type UIMessage } from \"ai\";\n\n/**\n * Extract text content from a ModelMessage.\n * Handles both string content and content arrays with text parts.\n *\n * @param message - The message to extract text from\n * @returns The extracted text content, or an empty string if none found\n *\n * @example\n * ```ts\n * const text = extractTextFromMessage(message);\n * // \"Hello world\"\n * ```\n */\nexport function extractTextFromMessage(\n  message: ModelMessage | undefined,\n): string {\n  if (!message?.content) return \"\";\n\n  const { content } = message;\n\n  // String content\n  if (typeof content === \"string\") return content;\n\n  // Array of parts - extract all text parts and join them\n  if (Array.isArray(content)) {\n    return content\n      .filter(\n        (part): part is { type: \"text\"; text: string } =>\n          typeof part === \"object\" && part !== null && part.type === \"text\",\n      )\n      .map((part) => part.text)\n      .join(\"\");\n  }\n\n  return \"\";\n}\n\n/**\n * Strip metadata from UI messages to prevent duplicate ID errors.\n * Provider metadata (like OpenAI item IDs) should not be reused across API calls.\n */\nexport function stripMetadata(messages: UIMessage[]): UIMessage[] {\n  return messages.map((msg) => ({\n    ...msg,\n    parts: msg.parts?.map((part) => {\n      const sanitizedPart: typeof part = { ...part };\n\n      if (\"providerMetadata\" in sanitizedPart) {\n        sanitizedPart.providerMetadata = undefined;\n      }\n\n      if (\n        isToolUIPart(sanitizedPart) &&\n        \"callProviderMetadata\" in sanitizedPart\n      ) {\n        sanitizedPart.callProviderMetadata = undefined;\n      }\n\n      return sanitizedPart;\n    }),\n  }));\n}\n","import type { CacheEntry, CacheStore } from \"../types\";\n\n/**\n * Redis cache store implementation\n * Requires redis client to be provided\n */\nexport class RedisCacheStore<T = any> implements CacheStore<T> {\n  private redis: any;\n  private keyPrefix: string;\n\n  constructor(redisClient: any, keyPrefix = \"ai-tools-cache:\") {\n    this.redis = redisClient;\n    this.keyPrefix = keyPrefix;\n  }\n\n  private getKey(key: string): string {\n    return `${this.keyPrefix}${key}`;\n  }\n\n  async get(key: string): Promise<CacheEntry<T> | undefined> {\n    try {\n      const data = await this.redis.get(this.getKey(key));\n      if (!data) return undefined;\n      \n      // Handle different Redis client return types\n      let jsonString: string;\n      if (typeof data === 'string') {\n        jsonString = data;\n      } else if (typeof data === 'object') {\n        // Some Redis clients return objects directly\n        return {\n          result: data.result,\n          timestamp: data.timestamp,\n          key: data.key,\n        };\n      } else {\n        // Convert other types to string\n        jsonString = String(data);\n      }\n      \n      const parsed = JSON.parse(jsonString);\n      return {\n        result: parsed.result,\n        timestamp: parsed.timestamp,\n        key: parsed.key,\n      };\n    } catch (error) {\n      console.warn(`Redis cache get error for key ${key}:`, error);\n      return undefined;\n    }\n  }\n\n  async set(key: string, entry: CacheEntry<T>): Promise<void> {\n    try {\n      const data = JSON.stringify({\n        result: entry.result,\n        timestamp: entry.timestamp,\n        key: entry.key,\n      });\n      \n      await this.redis.set(this.getKey(key), data);\n    } catch (error) {\n      console.warn(`Redis cache set error for key ${key}:`, error);\n    }\n  }\n\n  async setWithTTL(key: string, entry: CacheEntry<T>, ttlSeconds: number): Promise<void> {\n    try {\n      const data = JSON.stringify({\n        result: entry.result,\n        timestamp: entry.timestamp,\n        key: entry.key,\n      });\n      \n      await this.redis.setex(this.getKey(key), ttlSeconds, data);\n    } catch (error) {\n      console.warn(`Redis cache setex error for key ${key}:`, error);\n    }\n  }\n\n  async delete(key: string): Promise<boolean> {\n    try {\n      const result = await this.redis.del(this.getKey(key));\n      return result > 0;\n    } catch (error) {\n      console.warn(`Redis cache delete error for key ${key}:`, error);\n      return false;\n    }\n  }\n\n  async clear(): Promise<void> {\n    try {\n      const keys = await this.redis.keys(`${this.keyPrefix}*`);\n      if (keys.length > 0) {\n        await this.redis.del(...keys);\n      }\n    } catch (error) {\n      console.warn(\"Redis cache clear error:\", error);\n    }\n  }\n\n  async has(key: string): Promise<boolean> {\n    try {\n      const exists = await this.redis.exists(this.getKey(key));\n      return exists > 0;\n    } catch (error) {\n      console.warn(`Redis cache exists error for key ${key}:`, error);\n      return false;\n    }\n  }\n\n  async size(): Promise<number> {\n    try {\n      const keys = await this.redis.keys(`${this.keyPrefix}*`);\n      return keys.length;\n    } catch (error) {\n      console.warn(\"Redis cache size error:\", error);\n      return 0;\n    }\n  }\n\n  async keys(): Promise<string[]> {\n    try {\n      const keys = await this.redis.keys(`${this.keyPrefix}*`);\n      return keys.map((key: string) => key.replace(this.keyPrefix, \"\"));\n    } catch (error) {\n      console.warn(\"Redis cache keys error:\", error);\n      return [];\n    }\n  }\n\n  getDefaultTTL?(): number | undefined {\n    return undefined;\n  }\n}\n","import type { CacheStore } from \"../types\";\nimport { LRUCacheStore, SimpleCacheStore } from \"../cache-store\";\nimport { MemoryCacheStore } from \"./memory\";\nimport { RedisCacheStore } from \"./redis\";\n\n/**\n * Cache backend configuration\n */\nexport interface CacheBackendConfig {\n  type: \"memory\" | \"lru\" | \"simple\" | \"redis\";\n  maxSize?: number;\n  defaultTTL?: number;\n  redis?: {\n    client: any;\n    keyPrefix?: string;\n  };\n}\n\n/**\n * Factory function to create cache backends\n */\nexport function createCacheBackend<T = any>(config: CacheBackendConfig): CacheStore<T> {\n  let store: CacheStore<T>;\n  \n  switch (config.type) {\n    case \"memory\":\n      store = new MemoryCacheStore<T>(config.maxSize);\n      break;\n    \n    case \"lru\":\n      store = new LRUCacheStore<T>(config.maxSize);\n      break;\n    \n    case \"simple\":\n      store = new SimpleCacheStore<T>(config.maxSize);\n      break;\n    \n    case \"redis\":\n      if (!config.redis?.client) {\n        throw new Error(\"Redis client is required for redis cache backend\");\n      }\n      store = new RedisCacheStore<T>(config.redis.client, config.redis.keyPrefix);\n      break;\n    \n    default:\n      throw new Error(`Unknown cache backend type: ${(config as any).type}`);\n  }\n  \n  // Add default TTL support if configured\n  if (config.defaultTTL) {\n    (store as any).getDefaultTTL = () => config.defaultTTL;\n  }\n  \n  return store;\n}\n\n/**\n * Global cache backend configuration\n */\nlet globalCacheBackend: CacheStore | null = null;\n\n/**\n * Configure global cache backend\n */\nexport function configureCacheBackend(config: CacheBackendConfig): void {\n  globalCacheBackend = createCacheBackend(config);\n}\n\n/**\n * Get the global cache backend\n */\nexport function getGlobalCacheBackend<T = any>(): CacheStore<T> | null {\n  return globalCacheBackend as CacheStore<T> | null;\n}\n\n/**\n * Reset global cache backend\n */\nexport function resetCacheBackend(): void {\n  globalCacheBackend = null;\n}\n","import type { Tool } from \"ai\";\nimport { createCacheBackend } from \"./backends/factory\";\nimport { LRUCacheStore } from \"./cache-store\";\nimport type { CachedTool, CacheOptions, CacheStats, CacheStore } from \"./types\";\n\n/**\n * Default cache key generator - stable and deterministic\n */\nfunction defaultKeyGenerator(params: any, context?: any): string {\n  const paramsKey = serializeValue(params);\n\n  if (context) {\n    return `${paramsKey}|${context}`;\n  }\n\n  return paramsKey;\n}\n\n/**\n * Serialize a value to a stable string representation\n */\nfunction serializeValue(value: any): string {\n  // Handle different parameter types like React Query\n  if (value === null || value === undefined) {\n    return \"null\";\n  }\n\n  if (\n    typeof value === \"string\" ||\n    typeof value === \"number\" ||\n    typeof value === \"boolean\"\n  ) {\n    return String(value);\n  }\n\n  if (value instanceof Date) {\n    return value.toISOString();\n  }\n\n  if (Array.isArray(value)) {\n    return `[${value.map(serializeValue).join(\",\")}]`;\n  }\n\n  if (typeof value === \"object\") {\n    // Sort keys for deterministic serialization (like React Query)\n    const sortedKeys = Object.keys(value).sort();\n    const pairs = sortedKeys.map(\n      (key) => `${key}:${serializeValue(value[key])}`,\n    );\n    return `{${pairs.join(\",\")}}`;\n  }\n\n  return String(value);\n}\n\n/**\n * Simple streaming tool cache - just adds cache API methods without interfering\n */\nfunction createStreamingCachedTool<T extends Tool>(\n  tool: T,\n  options: CacheOptions,\n): CachedTool<T> {\n  const {\n    ttl = 5 * 60 * 1000,\n    maxSize = 1000,\n    store,\n    keyGenerator = defaultKeyGenerator,\n    cacheKey,\n    shouldCache = () => true,\n    onHit,\n    onMiss,\n    debug = false,\n  } = options;\n\n  const cacheStore = store || new LRUCacheStore(maxSize);\n  let hits = 0;\n  let misses = 0;\n\n  // Add cache API methods and override execute with caching logic\n  return {\n    ...tool,\n    execute: async function* (...args: any[]) {\n      const [params, executionOptions] = args;\n      // Get context from cacheKey function\n      const context = cacheKey?.();\n      const key = keyGenerator(params, context);\n      const now = Date.now();\n\n      // Check cache first\n      const cached = await cacheStore.get(key);\n      if (cached && now - cached.timestamp < ttl) {\n        hits++;\n        onHit?.(key);\n\n        const result = cached.result;\n\n        if (debug) {\n          const yields = result?.streamResults?.length || 0;\n          const artifacts = result?.messages?.length || 0;\n          const hasReturn = result?.returnValue !== undefined;\n\n          console.log(`\\n Cache HIT - Streaming Tool`);\n          console.log(\n            ` Key: ${key.slice(0, 60)}${key.length > 60 ? \"...\" : \"\"}`,\n          );\n          console.log(` Streaming yields: ${yields}`);\n          console.log(` Artifact messages: ${artifacts}`);\n          console.log(` Return value: ${hasReturn ? \"yes\" : \"no\"}`);\n          console.log(` Restoring cached results...\\n`);\n        }\n\n        // Replay artifact messages first\n        if (result?.messages?.length > 0) {\n          let writer =\n            executionOptions?.writer ||\n            (executionOptions as any)?.experimental_context?.writer;\n\n          // Writer comes from AI SDK's experimental_context\n          if (!writer) {\n            try {\n              const { getWriter } = await import(\"@ai-sdk-tools/artifacts\");\n              writer = getWriter(executionOptions);\n            } catch {\n              // Artifacts package not available or writer not available\n            }\n          }\n\n          if (writer) {\n            if (debug)\n              console.log(\n                `   Replaying ${result.messages.length} artifact messages...`,\n              );\n            for (const msg of result.messages) {\n              writer.write(msg);\n            }\n            if (debug) console.log(`   Artifacts restored`);\n          }\n        }\n\n        // Replay streaming yields\n        if (result?.streamResults) {\n          if (debug)\n            console.log(\n              `   Replaying ${result.streamResults.length} streaming yields...`,\n            );\n          for (const item of result.streamResults) {\n            yield item;\n          }\n          if (debug) console.log(`   Streaming content restored`);\n        }\n\n        return result.returnValue;\n      }\n\n      // Cache miss - execute original and capture\n      misses++;\n      onMiss?.(key);\n      if (debug) {\n        console.log(`\\n Cache MISS - Streaming Tool`);\n        console.log(\n          ` Key: ${key.slice(0, 60)}${key.length > 60 ? \"...\" : \"\"}`,\n        );\n        console.log(\n          ` Will capture: streaming yields + artifact messages + return value`,\n        );\n        console.log(` Executing tool and capturing results...\\n`);\n      }\n\n      // Capture writer messages\n      let writer =\n        executionOptions?.writer ||\n        (executionOptions as any)?.experimental_context?.writer;\n\n      // Writer comes from AI SDK's experimental_context\n      if (!writer) {\n        try {\n          const { getWriter } = await import(\"@ai-sdk-tools/artifacts\");\n          writer = getWriter(executionOptions);\n        } catch {\n          // Artifacts package not available or writer not available\n        }\n      }\n\n      const capturedMessages: any[] = [];\n\n      if (writer) {\n        const originalWrite = writer.write;\n        writer.write = (data: any) => {\n          capturedMessages.push(data);\n          return originalWrite.call(writer, data);\n        };\n      }\n\n      // Execute original tool\n      const originalResult = await tool.execute?.(params, executionOptions);\n\n      // Create tee generator that streams and caches\n      let lastChunk: any = null;\n      let finalReturnValue: any;\n      let chunkCount = 0;\n\n      if (\n        originalResult &&\n        typeof originalResult[Symbol.asyncIterator] === \"function\"\n      ) {\n        const iterator = originalResult[Symbol.asyncIterator]();\n        let iterResult = await iterator.next();\n\n        while (!iterResult.done) {\n          lastChunk = iterResult.value; // Just keep the last chunk (it has full text)\n          chunkCount++;\n\n          // Debug logging only for first few yields to avoid spam\n          if (debug && chunkCount <= 3) {\n            console.log(\n              `   Capturing yield #${chunkCount}:`,\n              `${lastChunk?.text?.slice(0, 40)}...`,\n            );\n          }\n          yield iterResult.value; // Stream immediately\n          iterResult = await iterator.next();\n        }\n\n        finalReturnValue = iterResult.value;\n      }\n\n      queueMicrotask(() => {\n        // This runs after all current synchronous operations and promises\n        queueMicrotask(async () => {\n          try {\n            // Store only the final chunk (it already has the complete text)\n            const completeResult = {\n              streamResults: lastChunk ? [lastChunk] : [], // Only final chunk\n              messages: capturedMessages,\n              returnValue: finalReturnValue,\n              type: \"streaming\",\n            };\n\n            if (shouldCache(params, completeResult)) {\n              await cacheStore.set(key, {\n                result: completeResult,\n                timestamp: now,\n                key,\n              });\n              if (debug) {\n                const cacheItems =\n                  typeof cacheStore.size === \"function\"\n                    ? await cacheStore.size()\n                    : \"unknown\";\n\n                // Calculate approximate memory usage\n                const estimatedSize = JSON.stringify(completeResult).length;\n                const sizeKB = Math.round((estimatedSize / 1024) * 100) / 100;\n\n                console.log(`\\n Cache STORED - Streaming Tool`);\n                console.log(` Streaming yields: ${chunkCount}`);\n                console.log(` Artifact messages: ${capturedMessages.length}`);\n                console.log(\n                  ` Return value: ${finalReturnValue !== undefined ? \"yes\" : \"no\"}`,\n                );\n                console.log(` Entry size: ~${sizeKB}KB`);\n                console.log(` Cache items: ${cacheItems}/${maxSize}`);\n                console.log(` Ready for instant replay!\\n`);\n              }\n            }\n          } catch (error) {\n            if (debug) console.log(`[Cache] Microtask caching failed:`, error);\n          }\n        });\n      });\n\n      return finalReturnValue;\n    },\n    getStats() {\n      const total = hits + misses;\n      return {\n        hits,\n        misses,\n        hitRate: total > 0 ? hits / total : 0,\n        size:\n          typeof cacheStore.size === \"function\"\n            ? (cacheStore.size() as any)\n            : 0,\n        maxSize,\n      };\n    },\n    clearCache(key?: string) {\n      if (key) {\n        cacheStore.delete(key);\n      } else {\n        cacheStore.clear();\n      }\n    },\n    async isCached(params: any) {\n      const context = cacheKey?.();\n      const key = keyGenerator(params, context);\n      const cached = await cacheStore.get(key);\n      if (!cached) return false;\n\n      const now = Date.now();\n      const isValid = now - cached.timestamp < ttl;\n\n      if (!isValid) {\n        await cacheStore.delete(key);\n        return false;\n      }\n\n      return true;\n    },\n    getCacheKey(params: any) {\n      const context = cacheKey?.();\n      return keyGenerator(params, context);\n    },\n  } as unknown as CachedTool<T>;\n}\n\nexport function cached<T extends Tool>(\n  tool: T,\n  options?: CacheOptions,\n): CachedTool<T> {\n  // For streaming tools, implement proper caching\n  if (tool.execute?.constructor?.name === \"AsyncGeneratorFunction\") {\n    return createStreamingCachedTool(tool, options || {});\n  }\n  const {\n    ttl = 5 * 60 * 1000,\n    maxSize = 1000,\n    store,\n    keyGenerator = defaultKeyGenerator,\n    cacheKey,\n    shouldCache = () => true,\n    onHit,\n    onMiss,\n    debug = false,\n  } = options || {};\n\n  const cacheStore = store || new LRUCacheStore(maxSize);\n  const effectiveTTL = ttl ?? cacheStore.getDefaultTTL?.() ?? 5 * 60 * 1000;\n  let hits = 0;\n  let misses = 0;\n\n  const log = debug ? console.log : () => {};\n\n  const cacheApi = {\n    getStats(): CacheStats {\n      const total = hits + misses;\n      return {\n        hits,\n        misses,\n        hitRate: total > 0 ? hits / total : 0,\n        size:\n          typeof cacheStore.size === \"function\"\n            ? (cacheStore.size() as any)\n            : 0,\n        maxSize,\n      };\n    },\n\n    clearCache(key?: string): void {\n      if (key) {\n        cacheStore.delete(key);\n      } else {\n        cacheStore.clear();\n      }\n    },\n\n    async isCached(params: any): Promise<boolean> {\n      const context = cacheKey?.();\n      const key = keyGenerator(params, context);\n      const cached = await cacheStore.get(key);\n      if (!cached) return false;\n\n      const now = Date.now();\n      const isValid = now - cached.timestamp < effectiveTTL;\n\n      if (!isValid) {\n        await cacheStore.delete(key);\n        return false;\n      }\n\n      return true;\n    },\n\n    getCacheKey(params: any): string {\n      const context = cacheKey?.();\n      return keyGenerator(params, context);\n    },\n  };\n\n  const cachedTool = new Proxy(tool, {\n    get(target, prop) {\n      if (prop === \"execute\") {\n        // Preserve the original function type\n        if (target.execute?.constructor?.name === \"AsyncGeneratorFunction\") {\n          return async function* (...args: any[]) {\n            const [params, executionOptions] = args;\n            const context = cacheKey?.();\n            const key = keyGenerator(params, context);\n            const now = Date.now();\n\n            // Check cache\n            const cached = await cacheStore.get(key);\n            if (cached && now - cached.timestamp < effectiveTTL) {\n              hits++;\n              onHit?.(key);\n              log(`[Cache] HIT`);\n\n              const result = cached.result;\n\n              // For streaming tools, replay messages immediately then return generator\n              if (\n                target.execute?.constructor?.name === \"AsyncGeneratorFunction\"\n              ) {\n                // Replay messages IMMEDIATELY to restore artifact data\n                if (result?.messages?.length > 0) {\n                  const writer =\n                    executionOptions?.writer ||\n                    (executionOptions as any)?.experimental_context?.writer;\n\n                  if (writer) {\n                    log(`[Cache] Replaying ${result.messages.length} messages`);\n                    for (const msg of result.messages) {\n                      writer.write(msg);\n                    }\n                  }\n                }\n\n                // Then return generator that yields stream results\n                return (async function* () {\n                  if (result?.streamResults) {\n                    for (const item of result.streamResults) {\n                      yield item;\n                    }\n                  } else if (Array.isArray(result)) {\n                    for (const item of result) {\n                      yield item;\n                    }\n                  } else {\n                    yield result;\n                  }\n                })();\n              }\n\n              return result;\n            }\n\n            // Execute original\n            misses++;\n            onMiss?.(key);\n            log(`[Cache] MISS`);\n\n            // Capture messages if writer available\n            const writer =\n              executionOptions?.writer ||\n              (executionOptions as any)?.experimental_context?.writer;\n\n            const capturedMessages: any[] = [];\n\n            if (writer) {\n              const originalWrite = writer.write;\n              writer.write = (data: any) => {\n                capturedMessages.push(data);\n                return originalWrite.call(writer, data);\n              };\n            }\n\n            const result = await target.execute?.(params, executionOptions);\n\n            // Handle streaming tools\n            if (\n              result &&\n              typeof (result as any)[Symbol.asyncIterator] === \"function\"\n            ) {\n              const streamResults: any[] = [];\n              let lastChunk: any = null;\n\n              // Stream to user immediately while capturing\n              const streamGenerator = (async function* () {\n                for await (const chunk of result as any) {\n                  streamResults.push(chunk);\n                  lastChunk = chunk;\n                  yield chunk; // Stream immediately to user\n                }\n\n                // After streaming completes, cache only the final chunk\n                queueMicrotask(async () => {\n                  const completeResult = {\n                    streamResults: lastChunk ? [lastChunk] : [], // Only store final chunk\n                    messages: capturedMessages,\n                    type: \"streaming\",\n                  };\n\n                  if (shouldCache(params, completeResult)) {\n                    await cacheStore.set(key, {\n                      result: completeResult,\n                      timestamp: now,\n                      key,\n                    });\n                    log(\n                      `[Cache] STORED streaming result with ${capturedMessages.length} messages`,\n                    );\n                  }\n                });\n              })();\n\n              return streamGenerator;\n            }\n\n            // Regular tool\n            if (shouldCache(params, result)) {\n              await cacheStore.set(key, {\n                result,\n                timestamp: now,\n                key,\n              });\n              log(`[Cache] STORED result`);\n            }\n\n            return result;\n          };\n        } else {\n          // Regular async function\n          return async (...args: any[]) => {\n            const [params, executionOptions] = args;\n            const context = cacheKey?.();\n            const key = keyGenerator(params, context);\n            const now = Date.now();\n\n            // Check cache\n            const cached = await cacheStore.get(key);\n            if (cached && now - cached.timestamp < effectiveTTL) {\n              hits++;\n              onHit?.(key);\n              log(`[Cache] HIT`);\n              return cached.result;\n            }\n\n            // Execute original\n            misses++;\n            onMiss?.(key);\n            log(`[Cache] MISS`);\n\n            const result = await target.execute?.(params, executionOptions);\n\n            if (shouldCache(params, result)) {\n              await cacheStore.set(key, {\n                result,\n                timestamp: now,\n                key,\n              });\n              log(`[Cache] STORED result`);\n            }\n\n            return result;\n          };\n        }\n      }\n\n      if (prop in cacheApi) {\n        return cacheApi[prop as keyof typeof cacheApi];\n      }\n\n      return target[prop as keyof typeof target];\n    },\n  }) as unknown as CachedTool<T>;\n\n  return cachedTool;\n}\n\n/**\n * Creates a pre-configured cached function with default options\n */\nexport function createCachedFunction(\n  store: CacheStore,\n  defaultOptions: Omit<CacheOptions, \"store\"> = {},\n) {\n  return <T extends Tool>(\n    tool: T,\n    options: Omit<CacheOptions, \"store\"> = {},\n  ): CachedTool<T> => {\n    return cached(tool, { ...defaultOptions, ...options, store });\n  };\n}\n\n/**\n * Cache multiple tools with the same configuration\n */\nexport function cacheTools<T extends Tool, TTools extends Record<string, T>>(\n  tools: T,\n  options: CacheOptions = {},\n): { [K in keyof TTools]: CachedTool<TTools[K]> } {\n  const cachedTools = {} as { [K in keyof TTools]: CachedTool<TTools[K]> };\n\n  for (const [name, tool] of Object.entries(tools)) {\n    cachedTools[name as keyof TTools] = cached(tool, options);\n  }\n\n  return cachedTools;\n}\n\n/**\n * Create a cached function with Redis client or default LRU\n *\n * Example usage:\n * ```ts\n * import { Redis } from \"@upstash/redis\";\n * import { createCached } from \"@ai-sdk-tools/cache\";\n *\n * // Upstash Redis\n * const cached = createCached({ cache: Redis.fromEnv() });\n *\n * // Standard Redis\n * const cached = createCached({ cache: Redis.createClient() });\n *\n * // Default LRU (no cache client)\n * const cached = createCached();\n * ```\n */\nexport function createCached(\n  options: {\n    cache?: any; // User's Redis client - we pass it directly\n    keyPrefix?: string;\n    ttl?: number;\n    debug?: boolean;\n    cacheKey?: () => string;\n    onHit?: (key: string) => void;\n    onMiss?: (key: string) => void;\n  } = {},\n) {\n  // If no cache provided, use default LRU\n  if (!options.cache) {\n    const lruStore = createCacheBackend({\n      type: \"lru\",\n      maxSize: 100,\n      defaultTTL: options.ttl || 10 * 60 * 1000, // 10 minutes default\n    });\n\n    return createCachedFunction(lruStore, {\n      debug: options.debug || false,\n      cacheKey: options.cacheKey,\n      onHit: options.onHit,\n      onMiss: options.onMiss,\n    });\n  }\n\n  // Use Redis client directly - no adapter needed!\n  const redisStore = createCacheBackend({\n    type: \"redis\",\n    defaultTTL: options.ttl || 30 * 60 * 1000, // 30 minutes default\n    redis: {\n      client: options.cache, // Pass user's Redis client directly\n      keyPrefix: options.keyPrefix || \"ai-tools-cache:\",\n    },\n  });\n\n  return createCachedFunction(redisStore, {\n    debug: options.debug || false,\n    cacheKey: options.cacheKey,\n    onHit: options.onHit,\n    onMiss: options.onMiss,\n  });\n}\n","import { createLogger } from \"@ai-sdk-tools/debug\";\nimport {\n  DEFAULT_TEMPLATE,\n  formatWorkingMemory,\n  getWorkingMemoryInstructions,\n  type MemoryConfig,\n} from \"@ai-sdk-tools/memory\";\nimport {\n  Experimental_Agent as AISDKAgent,\n  convertToModelMessages,\n  createUIMessageStream,\n  createUIMessageStreamResponse,\n  generateObject,\n  generateText,\n  type LanguageModel,\n  type ModelMessage,\n  type StepResult,\n  stepCountIs,\n  type Tool,\n  tool,\n  type UIMessage,\n  type UIMessageStreamOnFinishCallback,\n  type UIMessageStreamWriter,\n} from \"ai\";\nimport { z } from \"zod\";\nimport { createExecutionContext } from \"./context.js\";\nimport {\n  createHandoffTool,\n  HANDOFF_TOOL_NAME,\n  isHandoffResult,\n} from \"./handoff.js\";\nimport { promptWithHandoffInstructions } from \"./handoff-prompt.js\";\nimport { AgentRunContext } from \"./run-context.js\";\nimport { writeAgentStatus, writeSuggestions } from \"./streaming.js\";\nimport { createDefaultInputFilter } from \"./tool-result-extractor.js\";\nimport type {\n  AgentConfig,\n  AgentEvent,\n  AgentGenerateOptions,\n  AgentGenerateResult,\n  AgentStreamOptions,\n  AgentStreamOptionsUI,\n  AgentStreamResult,\n  ConfiguredHandoff,\n  ExtendedExecutionContext,\n  HandoffInputData,\n  HandoffInstruction,\n  Agent as IAgent,\n  InputGuardrail,\n  MemoryIdentifiers,\n  OutputGuardrail,\n  ToolPermissions,\n} from \"./types.js\";\nimport { extractTextFromMessage, stripMetadata } from \"./utils.js\";\n\nconst logger = createLogger(\"AGENT\");\n\nexport class Agent<\n  TContext extends Record<string, unknown> = Record<string, unknown>,\n> implements IAgent<TContext>\n{\n  public readonly name: string;\n  public readonly instructions: string | ((context: TContext) => string);\n  public readonly matchOn?:\n    | (string | RegExp)[]\n    | ((message: string) => boolean);\n  public readonly onEvent?: (event: AgentEvent) => void | Promise<void>;\n  public readonly inputGuardrails?: InputGuardrail[];\n  public readonly outputGuardrails?: OutputGuardrail[];\n  public readonly permissions?: ToolPermissions;\n  public readonly lastMessages?: number;\n  private readonly memory?: MemoryConfig;\n  private readonly model: LanguageModel;\n  private readonly aiAgent: AISDKAgent<Record<string, Tool>>;\n  private readonly handoffAgents: Array<IAgent<any> | ConfiguredHandoff<any>>;\n  private readonly configuredTools:\n    | Record<string, Tool>\n    | ((context: TContext) => Record<string, Tool>);\n  private readonly modelSettings?: Record<string, unknown>;\n  // Cache for system prompt construction\n  private _cachedSystemPrompt?: string;\n  private _cacheKey?: string;\n\n  constructor(config: AgentConfig<TContext>) {\n    this.name = config.name;\n    this.instructions = config.instructions;\n    this.matchOn = config.matchOn;\n    this.onEvent = config.onEvent;\n    this.inputGuardrails = config.inputGuardrails;\n    this.outputGuardrails = config.outputGuardrails;\n    this.permissions = config.permissions;\n    this.lastMessages = config.lastMessages;\n    this.memory = config.memory;\n    this.model = config.model;\n    this.handoffAgents = config.handoffs || [];\n    this.modelSettings = config.modelSettings;\n\n    // Store tools config (will be resolved at runtime)\n    this.configuredTools = config.tools || {};\n\n    // Create AI SDK Agent with minimal config (system prompt overridden per-request in stream())\n    // Extract toolChoice from modelSettings (needs to be a top-level param per AI SDK)\n    const { toolChoice, ...otherModelSettings } = config.modelSettings || {};\n\n    this.aiAgent = new AISDKAgent<Record<string, Tool>>({\n      model: config.model,\n      system: \"\", // Will be overridden per-request with resolved instructions\n      tools: {}, // Will be overridden per-request with resolved tools\n      stopWhen: stepCountIs(config.maxTurns || 10),\n      temperature: config.temperature,\n      toolChoice: toolChoice as any, // Pass toolChoice as top-level param\n      ...otherModelSettings,\n    });\n  }\n\n  async generate(options: AgentGenerateOptions): Promise<AgentGenerateResult> {\n    const startTime = new Date();\n\n    try {\n      const result =\n        options.messages && options.messages.length > 0\n          ? await this.aiAgent.generate({\n              messages: [\n                ...options.messages,\n                { role: \"user\", content: options.prompt || \"Continue\" },\n              ],\n            })\n          : await this.aiAgent.generate({\n              prompt: options.prompt,\n            });\n\n      const endTime = new Date();\n\n      // Extract handoffs from steps\n      const handoffs: HandoffInstruction[] = [];\n      if (result.steps) {\n        for (const step of result.steps) {\n          if (step.toolResults) {\n            for (const toolResult of step.toolResults) {\n              if (isHandoffResult(toolResult.output)) {\n                handoffs.push(toolResult.output as HandoffInstruction);\n              }\n            }\n          }\n        }\n      }\n\n      return {\n        text: result.text || \"\",\n        finalAgent: this.name,\n        finalOutput: result.text || \"\",\n        handoffs,\n        metadata: {\n          startTime,\n          endTime,\n          duration: endTime.getTime() - startTime.getTime(),\n        },\n        steps: result.steps,\n        finishReason: result.finishReason,\n        usage: result.usage,\n        toolCalls: result.toolCalls?.map((tc) => ({\n          toolCallId: tc.toolCallId,\n          toolName: tc.toolName,\n          args: \"args\" in tc ? tc.args : undefined,\n        })),\n      };\n    } catch (error) {\n      throw new Error(\n        `Agent ${this.name} failed: ${error instanceof Error ? error.message : \"Unknown error\"}`,\n      );\n    }\n  }\n\n  stream(\n    options: AgentStreamOptions | { messages: ModelMessage[] },\n  ): AgentStreamResult {\n    logger.debug(`${this.name} stream called`, { name: this.name });\n\n    // Extract our internal execution context (we map to/from AI SDK's experimental_context at boundaries)\n    const executionContext = (options as Record<string, unknown>)\n      .executionContext as Record<string, unknown> | undefined;\n    const maxSteps = (options as Record<string, unknown>).maxSteps as\n      | number\n      | undefined;\n    const onStepFinish = (options as Record<string, unknown>).onStepFinish as\n      | ((step: unknown) => void | Promise<void>)\n      | undefined;\n    const toolChoice = (options as Record<string, unknown>).toolChoice as\n      | string\n      | undefined;\n\n    // Resolve instructions dynamically (static string or function)\n    const resolvedInstructions =\n      typeof this.instructions === \"function\"\n        ? this.instructions(executionContext as TContext)\n        : this.instructions;\n\n    // Get memory addition from context if preloaded\n    const extendedContext = executionContext as ExtendedExecutionContext;\n    const memoryAddition = extendedContext._memoryAddition || \"\";\n\n    // Build cache key for static parts\n    const cacheKey = `${typeof this.instructions === \"string\" ? this.instructions : \"dynamic\"}_${this.handoffAgents.length}_${this.memory?.workingMemory?.enabled || false}`;\n\n    // Build system prompt with caching for static parts\n    let systemPrompt: string;\n    if (\n      this._cacheKey === cacheKey &&\n      this._cachedSystemPrompt &&\n      !memoryAddition\n    ) {\n      // Use cached version if no dynamic memory addition\n      systemPrompt = this._cachedSystemPrompt;\n    } else {\n      // Build the static base prompt\n      let basePrompt =\n        this.handoffAgents.length > 0\n          ? promptWithHandoffInstructions(resolvedInstructions)\n          : resolvedInstructions;\n\n      // Add working memory instructions if enabled\n      if (this.memory?.workingMemory?.enabled) {\n        const workingMemoryInstructions = getWorkingMemoryInstructions(\n          this.memory.workingMemory.template || DEFAULT_TEMPLATE,\n        );\n        basePrompt += `\\n\\n${workingMemoryInstructions}`;\n      }\n\n      // Cache the base prompt if instructions are static\n      if (typeof this.instructions === \"string\" && !memoryAddition) {\n        this._cachedSystemPrompt = basePrompt;\n        this._cacheKey = cacheKey;\n      }\n\n      // Add dynamic memory addition\n      systemPrompt = basePrompt + memoryAddition;\n    }\n\n    // Resolve tools dynamically (static object or function)\n    const resolvedTools =\n      typeof this.configuredTools === \"function\"\n        ? this.configuredTools(executionContext as TContext)\n        : { ...this.configuredTools };\n\n    // Add handoff tool if needed\n    if (this.handoffAgents.length > 0) {\n      resolvedTools[HANDOFF_TOOL_NAME] = createHandoffTool(this.handoffAgents);\n      // Note: Agents communicate via conversationMessages during handoffs\n    }\n\n    // Add working memory update tool if enabled\n    // Give to all agents that can do work (have tools beyond just handoff)\n    const hasOtherTools = Object.keys(resolvedTools).some(\n      (key) => key !== HANDOFF_TOOL_NAME,\n    );\n    const isPureOrchestrator = this.handoffAgents.length > 0 && !hasOtherTools;\n\n    if (this.memory?.workingMemory?.enabled && !isPureOrchestrator) {\n      resolvedTools.updateWorkingMemory = this.createWorkingMemoryTool();\n    }\n\n    // Note: Conversation history is automatically loaded via loadMessagesWithHistory()\n\n    // Build additional options to pass to AI SDK\n    // Extract toolChoice as a top-level param (per AI SDK requirements)\n    const { toolChoice: configuredToolChoice, ...otherSettings } =\n      this.modelSettings || {};\n\n    // Allow runtime toolChoice to override configured toolChoice\n    const effectiveToolChoice = toolChoice\n      ? { type: \"tool\" as const, toolName: toolChoice }\n      : configuredToolChoice;\n\n    const additionalOptions: Record<string, unknown> = {\n      system: systemPrompt, // Override system prompt per call\n      tools: resolvedTools, // Add resolved tools here\n      toolChoice: effectiveToolChoice, // Pass toolChoice as top-level param\n      ...otherSettings, // Include other model settings\n    };\n\n    if (executionContext) {\n      additionalOptions.experimental_context = executionContext;\n    }\n\n    if (maxSteps) additionalOptions.maxSteps = maxSteps;\n    if (onStepFinish) additionalOptions.onStepFinish = onStepFinish;\n\n    // Handle simple { messages } format (like working code)\n    if (\"messages\" in options && !(\"prompt\" in options) && options.messages) {\n      logger.debug(`Stream with messages only`, {\n        messageCount: options.messages.length,\n      });\n      return this.aiAgent.stream({\n        messages: options.messages,\n        ...additionalOptions,\n      }) as unknown as AgentStreamResult;\n    }\n\n    // Handle full AgentStreamOptions format\n    const opts = options as AgentStreamOptions;\n    logger.debug(`Stream options for ${this.name}`, {\n      hasPrompt: !!opts.prompt,\n      messageCount: opts.messages?.length || 0,\n    });\n\n    if (!opts.prompt && (!opts.messages || opts.messages.length === 0)) {\n      throw new Error(\"No prompt or messages provided to stream method\");\n    }\n\n    // If we have messages, append prompt as user message\n    if (opts.messages && opts.messages.length > 0 && opts.prompt) {\n      return this.aiAgent.stream({\n        messages: [...opts.messages, { role: \"user\", content: opts.prompt }],\n        ...additionalOptions,\n      }) as unknown as AgentStreamResult;\n    }\n\n    // Prompt only\n    if (opts.prompt) {\n      return this.aiAgent.stream({\n        prompt: opts.prompt,\n        ...additionalOptions,\n      }) as unknown as AgentStreamResult;\n    }\n\n    throw new Error(\"No valid options provided to stream method\");\n  }\n\n  getHandoffs(): Array<IAgent<any>> {\n    return this.handoffAgents.map((h) => (\"agent\" in h ? h.agent : h));\n  }\n\n  getConfiguredHandoffs(): Array<ConfiguredHandoff<any>> {\n    return this.handoffAgents.map((h) => (\"agent\" in h ? h : { agent: h }));\n  }\n\n  /**\n   * Convert agent execution to UI Message Stream Response\n   * High-level API for Next.js route handlers\n   *\n   * This follows the working pattern from the route.ts reference code\n   */\n  toUIMessageStream(options: AgentStreamOptionsUI): Response {\n    const {\n      message,\n      strategy = \"auto\",\n      maxRounds = 5,\n      maxSteps = 10,\n      context,\n      agentChoice,\n      toolChoice,\n      beforeStream,\n      onEvent,\n      // AI SDK createUIMessageStream options\n      onFinish,\n      onError,\n      generateId,\n      // AI SDK toUIMessageStream options\n      sendReasoning,\n      sendSources,\n      sendFinish,\n      sendStart,\n      messageMetadata,\n      // Response options\n      status,\n      statusText,\n      headers,\n    } = options;\n\n    // Declare variable to store chat metadata (will be loaded in execute block)\n    let existingChatForSave: any = null;\n\n    // Wrap onFinish to save messages after streaming\n    const wrappedOnFinish: UIMessageStreamOnFinishCallback<never> = async (\n      event,\n    ) => {\n      // Save messages and update chat session after stream completes\n      if (this.memory?.history?.enabled && context) {\n        const { chatId, userId } = this.extractMemoryIdentifiers(\n          context as TContext,\n        );\n\n        if (!chatId) {\n          logger.warn(\"Cannot save messages: chatId is missing from context\");\n        } else {\n          try {\n            // The AI SDK provides complete messages with all parts in event.messages\n            const userMsg: any = event.messages[event.messages.length - 2]; // second to last is user message\n            const assistantMsg: any = event.messages[event.messages.length - 1]; // last is assistant message\n\n            // Filter out file parts from user message - files should never be stored in history\n            // They're only needed during initial LLM processing\n            let userMsgToSave: any = userMsg;\n            if (userMsg && Array.isArray(userMsg.content)) {\n              const filteredContent = userMsg.content.filter(\n                (part: any) => part.type !== \"file\",\n              );\n              userMsgToSave = {\n                ...userMsg,\n                content: filteredContent.length > 0 ? filteredContent : \"\",\n              };\n            }\n\n            logger.debug(`Saving messages (files excluded from storage)`);\n            await this.saveConversation(\n              chatId,\n              userId,\n              JSON.stringify(userMsgToSave),\n              JSON.stringify(assistantMsg),\n              existingChatForSave,\n            );\n          } catch (err) {\n            logger.error(\"Failed to save conversation\", { error: err });\n          }\n        }\n      }\n\n      // Call user's onFinish\n      await onFinish?.(event);\n    };\n\n    const stream = createUIMessageStream({\n      originalMessages: [message] as never[],\n      onFinish: wrappedOnFinish,\n      onError,\n      generateId,\n      execute: async ({ writer }) => {\n        // Load history and working memory in parallel for better performance\n        const [messages, memoryAddition] = await Promise.all([\n          this.loadMessagesWithHistory(message, context as TContext),\n          context && this.memory?.workingMemory?.enabled\n            ? this.loadWorkingMemory(context as TContext)\n            : Promise.resolve(\"\"),\n        ]);\n\n        // Load chat metadata once for the entire request (stored in closure for wrappedOnFinish)\n        const { chatId } = this.extractMemoryIdentifiers(context as TContext);\n        if (this.memory?.chats?.enabled && chatId) {\n          existingChatForSave = await this.memory.provider?.getChat?.(chatId);\n        }\n\n        // Extract input from last message for routing\n        const lastMessage = messages[messages.length - 1];\n        const input = extractTextFromMessage(lastMessage);\n\n        // Generate chat title if this is the first message (using pre-loaded chat)\n        await this.maybeGenerateChatTitle(\n          context as TContext,\n          input,\n          writer,\n          existingChatForSave,\n        );\n\n        // Create AgentRunContext for the workflow\n        const runContext = new AgentRunContext(context || {});\n        runContext.metadata = {\n          agent: this.name,\n          requestId: `req_${Date.now()}_${Math.random().toString(36).substring(7)}`,\n        };\n\n        // Create execution context with user context and writer\n        const executionContext = createExecutionContext({\n          context: (context || {}) as Record<string, unknown>,\n          writer,\n          metadata: {\n            agent: this.name,\n            requestId: runContext.metadata.requestId as string,\n          },\n        });\n\n        // Add runContext to execution context for shared memory tool\n        (executionContext as any).runContext = runContext;\n\n        // Store memory addition for system prompt injection\n        if (memoryAddition) {\n          const extendedExecContext =\n            executionContext as ExtendedExecutionContext;\n          extendedExecContext._memoryAddition = memoryAddition;\n        }\n\n        try {\n          // Execute beforeStream hook - allows for rate limiting, auth, etc.\n          if (beforeStream) {\n            const shouldContinue = await beforeStream({ writer });\n            if (shouldContinue === false) {\n              // Type assertion needed: custom finish message format\n              writer.write({ type: \"finish\" } as any);\n              return;\n            }\n          }\n\n          // Prepare conversation messages\n          const conversationMessages = [...messages];\n\n          // Get handoff agents (specialists)\n          const specialists = this.getHandoffs();\n\n          // Emit orchestrator start (even if we skip to specialist via programmatic routing)\n          writeAgentStatus(writer, {\n            status: \"routing\",\n            agent: this.name,\n          });\n\n          if (onEvent) {\n            await onEvent({\n              type: \"agent-start\",\n              agent: this.name,\n              round: 0,\n            });\n          }\n\n          // Determine starting agent using programmatic routing\n          let currentAgent: IAgent<any> = this;\n\n          // Check for explicit agent or tool choice (highest priority)\n          if (agentChoice && specialists.length > 0) {\n            const chosenAgent = specialists.find(\n              (agent) => agent.name === agentChoice,\n            );\n            if (chosenAgent) {\n              currentAgent = chosenAgent;\n              logger.debug(`Explicit agent choice: ${currentAgent.name}`, {\n                agent: currentAgent.name,\n              });\n\n              // Mark orchestrator as completing\n              writeAgentStatus(writer, {\n                status: \"completing\",\n                agent: this.name,\n              });\n\n              if (onEvent) {\n                await onEvent({\n                  type: \"agent-finish\",\n                  agent: this.name,\n                  round: 0,\n                });\n              }\n\n              // Emit handoff event for explicit choice\n              writer.write({\n                type: \"data-agent-handoff\",\n                data: {\n                  from: this.name,\n                  to: chosenAgent.name,\n                  reason: \"User selected agent\",\n                  routingStrategy: \"explicit\",\n                },\n                transient: true,\n              } as never);\n\n              if (onEvent) {\n                await onEvent({\n                  type: \"agent-handoff\",\n                  from: this.name,\n                  to: chosenAgent.name,\n                  reason: \"User selected agent\",\n                });\n              }\n            }\n          } else if (toolChoice && specialists.length > 0) {\n            // Find agent that has the requested tool\n            const agentWithTool = specialists.find((agent) => {\n              const agentImpl = agent as Agent<any>;\n              return (\n                agentImpl.configuredTools &&\n                toolChoice in agentImpl.configuredTools\n              );\n            });\n\n            if (agentWithTool) {\n              currentAgent = agentWithTool;\n              logger.debug(\n                `Tool choice routing: ${toolChoice}  ${currentAgent.name}`,\n                { toolChoice, agent: currentAgent.name },\n              );\n\n              // Mark orchestrator as completing\n              writeAgentStatus(writer, {\n                status: \"completing\",\n                agent: this.name,\n              });\n\n              if (onEvent) {\n                await onEvent({\n                  type: \"agent-finish\",\n                  agent: this.name,\n                  round: 0,\n                });\n              }\n\n              // Emit handoff event for tool choice\n              writer.write({\n                type: \"data-agent-handoff\",\n                data: {\n                  from: this.name,\n                  to: agentWithTool.name,\n                  reason: `User requested tool: ${toolChoice}`,\n                  routingStrategy: \"tool-choice\",\n                  preferredTool: toolChoice,\n                },\n                transient: true,\n              } as never);\n\n              if (onEvent) {\n                await onEvent({\n                  type: \"agent-handoff\",\n                  from: this.name,\n                  to: agentWithTool.name,\n                  reason: `User requested tool: ${toolChoice}`,\n                });\n              }\n            }\n          } else if (strategy === \"auto\" && specialists.length > 0) {\n            // Try programmatic classification\n            const matchedAgent = specialists.find((agent) => {\n              if (!agent.matchOn) return false;\n              if (typeof agent.matchOn === \"function\") {\n                return agent.matchOn(input);\n              }\n              if (Array.isArray(agent.matchOn)) {\n                return agent.matchOn.some((pattern) => {\n                  if (typeof pattern === \"string\") {\n                    return input.toLowerCase().includes(pattern.toLowerCase());\n                  }\n                  if (pattern instanceof RegExp) {\n                    return pattern.test(input);\n                  }\n                  return false;\n                });\n              }\n              return false;\n            });\n\n            if (matchedAgent) {\n              currentAgent = matchedAgent;\n              logger.debug(`Programmatic match: ${currentAgent.name}`, {\n                agent: currentAgent.name,\n              });\n\n              // Mark orchestrator as completing\n              writeAgentStatus(writer, {\n                status: \"completing\",\n                agent: this.name,\n              });\n\n              if (onEvent) {\n                await onEvent({\n                  type: \"agent-finish\",\n                  agent: this.name,\n                  round: 0,\n                });\n              }\n\n              // Emit handoff event for programmatic routing\n              writer.write({\n                type: \"data-agent-handoff\",\n                data: {\n                  from: this.name,\n                  to: matchedAgent.name,\n                  reason: \"Programmatic routing match\",\n                  routingStrategy: \"programmatic\",\n                },\n                transient: true,\n              } as never);\n\n              if (onEvent) {\n                await onEvent({\n                  type: \"agent-handoff\",\n                  from: this.name,\n                  to: matchedAgent.name,\n                  reason: \"Programmatic routing match\",\n                });\n              }\n            }\n          }\n\n          let round = 0;\n          const usedSpecialists = new Set<string>();\n\n          // If we used programmatic routing, mark specialist as used\n          if (currentAgent !== this) {\n            usedSpecialists.add(currentAgent.name);\n          }\n\n          while (round++ < maxRounds) {\n            // Send status: agent executing\n            writeAgentStatus(writer, {\n              status: \"executing\",\n              agent: currentAgent.name,\n            });\n\n            // Get context window size from agent config, with sensible defaults\n            // Use lower default for specialists (no handoffs) to reduce token usage\n            const defaultLastMessages =\n              currentAgent.getHandoffs().length > 0 ? 10 : 5;\n            const lastMessages =\n              currentAgent.lastMessages ?? defaultLastMessages;\n\n            // Ensure we have at least the original user message\n            let messagesToSend = conversationMessages.slice(-lastMessages);\n            if (messagesToSend.length === 0 && messages.length > 0) {\n              messagesToSend = messages.slice(-1); // Use the last user message\n            }\n\n            // Emit agent start event\n            if (onEvent) {\n              await onEvent({\n                type: \"agent-start\",\n                agent: currentAgent.name,\n                round,\n              });\n            }\n\n            // Type assertion needed: executionContext and onStepFinish types don't strictly match\n            // Note: toolChoice is NOT passed here - it was only used for routing\n            // Passing it would force the tool to be called on every turn\n            const result = currentAgent.stream({\n              messages: messagesToSend,\n              executionContext: executionContext,\n              maxSteps, // Limit tool calls per round\n              onStepFinish: async (step: unknown) => {\n                if (onEvent) {\n                  await onEvent({\n                    type: \"agent-step\",\n                    agent: currentAgent.name,\n                    step: step as StepResult<Record<string, Tool>>,\n                  });\n                }\n              },\n            } as any);\n\n            // This automatically converts fullStream to proper UI message chunks\n            // Pass toUIMessageStream options from user config\n            const uiStream = result.toUIMessageStream({\n              sendReasoning,\n              sendSources,\n              sendFinish,\n              sendStart,\n              messageMetadata,\n            });\n\n            // Track for orchestration\n            let textAccumulated = \"\";\n            let handoffData: HandoffInstruction | null = null;\n            const toolCallNames = new Map<string, string>(); // toolCallId -> toolName\n            const toolResults = new Map<string, any>(); // toolName -> result\n            let hasStartedContent = false;\n\n            // Optimize handoff detection with Set for O(1) lookups\n            const handoffToolNames = new Set([HANDOFF_TOOL_NAME]);\n\n            // Stream UI chunks - AI SDK handles all the formatting!\n            for await (const chunk of uiStream) {\n              // Skip undefined/null chunks\n              if (!chunk) {\n                logger.warn(\"Received null/undefined chunk from uiStream\");\n                continue;\n              }\n\n              // Track tool names when they start (do this early for handoff detection)\n              if (chunk.type === \"tool-input-start\") {\n                toolCallNames.set(chunk.toolCallId, chunk.toolName);\n                logger.debug(\n                  `Tool call started: ${chunk.toolName} (${chunk.toolCallId})`,\n                  {\n                    toolName: chunk.toolName,\n                    toolCallId: chunk.toolCallId,\n                    agent: currentAgent.name,\n                    round,\n                  },\n                );\n              }\n\n              // Check if this chunk is related to handoff (internal orchestration)\n              let isHandoffChunk = false;\n\n              if (chunk.type === \"tool-input-start\") {\n                isHandoffChunk = handoffToolNames.has((chunk as any).toolName);\n              } else if (\n                chunk.type === \"tool-input-delta\" ||\n                chunk.type === \"tool-input-available\"\n              ) {\n                const toolName = toolCallNames.get((chunk as any).toolCallId);\n                isHandoffChunk = toolName\n                  ? handoffToolNames.has(toolName)\n                  : false;\n              } else if (chunk.type === \"tool-output-available\") {\n                const toolName = toolCallNames.get((chunk as any).toolCallId);\n                isHandoffChunk = toolName\n                  ? handoffToolNames.has(toolName)\n                  : false;\n              }\n\n              // Clear status on first actual content (text or non-handoff tool)\n              if (\n                !hasStartedContent &&\n                (chunk.type === \"text-delta\" ||\n                  (chunk.type === \"tool-input-start\" && !isHandoffChunk))\n              ) {\n                hasStartedContent = true;\n              }\n\n              // Log general errors\n              if (chunk.type === \"error\") {\n                logger.error(\"Stream error\", {\n                  error:\n                    (chunk as any).errorText || (chunk as any).error || chunk,\n                });\n              }\n\n              // Capture tool results and detect handoffs\n              if (chunk.type === \"tool-output-available\") {\n                const toolName = toolCallNames.get(chunk.toolCallId);\n                if (toolName) {\n                  // Store tool result for handoff context\n                  toolResults.set(toolName, chunk.output);\n                  logger.debug(`Captured ${toolName}`, {\n                    toolName,\n                    outputType: typeof chunk.output,\n                  });\n\n                  // Detect handoff\n                  if (handoffToolNames.has(toolName)) {\n                    handoffData = chunk.output as HandoffInstruction;\n                    logger.debug(\"Handoff detected\", handoffData);\n                  }\n                }\n              }\n\n              // Filter out handoff tool chunks from UI (internal orchestration)\n              // But keep agent status events (written separately via writeAgentStatus)\n              if (!isHandoffChunk) {\n                try {\n                  writer.write(chunk as any);\n                } catch (error) {\n                  logger.error(\"Failed to write chunk to stream\", {\n                    chunkType: chunk.type,\n                    error,\n                  });\n                }\n              }\n\n              // Track text for conversation history\n              if (chunk.type === \"text-delta\") {\n                textAccumulated += chunk.delta;\n              }\n            }\n\n            // Update conversation - only add text if it's a complete response\n            // Don't add intermediate text that was generated between tool calls\n            if (textAccumulated && !handoffData) {\n              // Only add to conversation if this is a final response (no handoff occurred)\n              conversationMessages.push({\n                role: \"assistant\",\n                content: textAccumulated,\n              });\n            } else if (textAccumulated && handoffData) {\n              // If there was a handoff, this text was intermediate - don't add to conversation\n              // The handoff agent will provide the final response\n              logger.debug(\"Skipping intermediate text due to handoff\", {\n                textLength: textAccumulated.length,\n                handoffTarget: handoffData.targetAgent,\n              });\n            }\n\n            // Emit agent finish event\n            if (onEvent) {\n              await onEvent({\n                type: \"agent-finish\",\n                agent: currentAgent.name,\n                round,\n              });\n            }\n\n            // Handle orchestration flow\n            if (currentAgent === this) {\n              if (handoffData) {\n                // Check if this specialist has already been used\n                if (usedSpecialists.has(handoffData.targetAgent)) {\n                  // Don't route to the same specialist twice - task is complete\n                  break;\n                }\n\n                // Send routing status\n                writeAgentStatus(writer, {\n                  status: \"routing\",\n                  agent: this.name,\n                });\n\n                // Mark specialist as used and route to it\n                usedSpecialists.add(handoffData.targetAgent);\n                const nextAgent = specialists.find(\n                  (a) => a.name === handoffData.targetAgent,\n                );\n                if (nextAgent) {\n                  // Apply handoff input filter if configured\n                  const configuredHandoffs = this.getConfiguredHandoffs();\n                  const configuredHandoff = configuredHandoffs.find(\n                    (ch) => ch.agent.name === handoffData.targetAgent,\n                  );\n\n                  // Apply handoff input filter if configured\n                  const inputFilter = configuredHandoff?.config?.inputFilter;\n                  if (inputFilter) {\n                    try {\n                      // Build HandoffInputData with captured tool results\n                      const handoffInputData: HandoffInputData = {\n                        inputHistory: conversationMessages,\n                        preHandoffItems: [],\n                        newItems: Array.from(toolResults.entries()).map(\n                          ([name, result]) => ({\n                            toolName: name,\n                            result: result,\n                          }),\n                        ),\n                        runContext,\n                      };\n\n                      // Apply filter to modify conversation history\n                      const filteredData = inputFilter(handoffInputData);\n\n                      // Update conversation messages with filtered data\n                      conversationMessages.length = 0;\n                      conversationMessages.push(...filteredData.inputHistory);\n                    } catch (error) {\n                      logger.error(\"Error applying handoff input filter\", {\n                        error,\n                      });\n                      // Continue with original conversation messages as fallback\n                    }\n                  } else {\n                    // Use default input filter to modify conversation history\n                    logger.debug(\"Applying default input filter for\", {\n                      targetAgent: handoffData.targetAgent,\n                    });\n                    const defaultFilter = createDefaultInputFilter();\n\n                    const handoffInputData: HandoffInputData = {\n                      inputHistory: conversationMessages,\n                      preHandoffItems: [],\n                      newItems: Array.from(toolResults.entries()).map(\n                        ([name, result]) => ({\n                          toolName: name,\n                          result: result,\n                        }),\n                      ),\n                      runContext,\n                    };\n\n                    logger.debug(\"Input history length\", {\n                      length: handoffInputData.inputHistory.length,\n                    });\n                    logger.debug(\"Input history messages\", {\n                      messages: handoffInputData.inputHistory.map((m) => ({\n                        role: m.role,\n                        contentType: typeof m.content,\n                      })),\n                    });\n                    const filteredData = defaultFilter(handoffInputData);\n                    logger.debug(\"Filtered history length\", {\n                      length: filteredData.inputHistory.length,\n                    });\n\n                    // Update conversation messages with filtered data\n                    conversationMessages.length = 0;\n                    conversationMessages.push(...filteredData.inputHistory);\n                    logger.debug(\"Updated conversation messages length\", {\n                      length: conversationMessages.length,\n                    });\n                  }\n\n                  // Call onHandoff callback if configured\n                  if (configuredHandoff?.config?.onHandoff) {\n                    try {\n                      await configuredHandoff.config.onHandoff(runContext);\n                    } catch (error) {\n                      logger.error(\"Error in onHandoff callback\", { error });\n                      // Continue execution - callback errors shouldn't stop handoff\n                    }\n                  }\n\n                  currentAgent = nextAgent;\n\n                  writer.write({\n                    type: \"data-agent-handoff\",\n                    data: {\n                      from: this.name,\n                      to: nextAgent.name,\n                      reason: handoffData.reason,\n                      routingStrategy: \"llm\",\n                    },\n                    transient: true,\n                  } as never);\n\n                  // Emit handoff event\n                  if (onEvent) {\n                    await onEvent({\n                      type: \"agent-handoff\",\n                      from: this.name,\n                      to: nextAgent.name,\n                      reason: handoffData.reason,\n                    });\n                  }\n                }\n              } else {\n                // Orchestrator done, no more handoffs\n                break;\n              }\n            } else {\n              // Specialist done\n              if (handoffData) {\n                // Specialist handed off to another specialist\n                if (usedSpecialists.has(handoffData.targetAgent)) {\n                  // Already used this specialist - complete\n                  break;\n                }\n\n                // Route to next specialist\n                usedSpecialists.add(handoffData.targetAgent);\n                const nextAgent = specialists.find(\n                  (a) => a.name === handoffData.targetAgent,\n                );\n                if (nextAgent) {\n                  // Apply handoff input filter if configured\n                  const configuredHandoffs = this.getConfiguredHandoffs();\n                  const configuredHandoff = configuredHandoffs.find(\n                    (ch) => ch.agent.name === handoffData.targetAgent,\n                  );\n\n                  if (configuredHandoff?.config?.inputFilter) {\n                    try {\n                      // Build HandoffInputData\n                      const handoffInputData: HandoffInputData = {\n                        inputHistory: conversationMessages.slice(0, -1), // All messages except the last assistant message\n                        preHandoffItems: [], // No pre-handoff items for specialist-to-specialist\n                        newItems: conversationMessages.slice(-1), // The last assistant message\n                        runContext,\n                      };\n\n                      // Apply filter\n                      const filteredData =\n                        configuredHandoff.config.inputFilter(handoffInputData);\n\n                      // Update conversation messages with filtered data\n                      conversationMessages.length = 0;\n                      conversationMessages.push(\n                        ...filteredData.inputHistory,\n                        ...filteredData.newItems,\n                      );\n                    } catch (error) {\n                      logger.error(\"Error applying handoff input filter\", {\n                        error,\n                      });\n                      // Continue with original conversation messages as fallback\n                    }\n                  }\n\n                  // Call onHandoff callback if configured\n                  if (configuredHandoff?.config?.onHandoff) {\n                    try {\n                      await configuredHandoff.config.onHandoff(runContext);\n                    } catch (error) {\n                      logger.error(\"Error in onHandoff callback\", { error });\n                      // Continue execution - callback errors shouldn't stop handoff\n                    }\n                  }\n\n                  const previousAgent = currentAgent;\n                  currentAgent = nextAgent;\n\n                  // Write handoff to stream for devtools\n                  writer.write({\n                    type: \"data-agent-handoff\",\n                    data: {\n                      from: previousAgent.name,\n                      to: nextAgent.name,\n                      reason: handoffData.reason,\n                      routingStrategy: \"llm\",\n                    },\n                    transient: true,\n                  } as never);\n\n                  // Emit handoff event\n                  if (onEvent) {\n                    await onEvent({\n                      type: \"agent-handoff\",\n                      from: previousAgent.name,\n                      to: nextAgent.name,\n                      reason: handoffData.reason,\n                    });\n                  }\n                }\n              } else {\n                // No handoff - specialist is done, complete the task\n                break;\n              }\n            }\n          }\n\n          // Emit completion event\n          if (onEvent) {\n            await onEvent({\n              type: \"agent-complete\",\n              totalRounds: round,\n            });\n          }\n\n          // Generate suggestions after orchestration completes\n          const config = this.memory?.chats?.generateSuggestions;\n          const minLength =\n            typeof config === \"object\" && config.minResponseLength\n              ? config.minResponseLength\n              : 100;\n\n          // Get accumulated text length from conversation messages\n          const assistantMessages = conversationMessages.filter(\n            (m) => m.role === \"assistant\",\n          );\n          const totalTextLength = assistantMessages.reduce((sum, m) => {\n            return sum + (typeof m.content === \"string\" ? m.content.length : 0);\n          }, 0);\n\n          // Only generate if response is substantial enough\n          if (totalTextLength >= minLength) {\n            // Use focused context window (recent exchanges) instead of full history\n            const contextWindow =\n              typeof config === \"object\" && config.contextWindow\n                ? config.contextWindow\n                : 1;\n\n            // Get last N exchanges (user + assistant pairs)\n            const recentMessages = conversationMessages.slice(\n              -(contextWindow * 2),\n            );\n\n            const conversationContext = recentMessages\n              .map((msg) => {\n                const role = msg.role === \"user\" ? \"User\" : \"Assistant\";\n                return `${role}: ${typeof msg.content === \"string\" ? msg.content : JSON.stringify(msg.content)}`;\n              })\n              .join(\"\\n\\n\");\n\n            // Generate suggestions based on recent context\n            await this.generateSuggestions(\n              conversationContext,\n              conversationMessages,\n              writer,\n              context as TContext,\n            ).catch((err) =>\n              logger.error(\"Suggestion generation error\", { error: err }),\n            );\n          }\n\n          writer.write({ type: \"finish\" });\n        } catch (error) {\n          logger.error(\"Error in toUIMessageStream\", { error });\n\n          // Emit error event\n          if (onEvent) {\n            await onEvent({\n              type: \"agent-error\",\n              error: error instanceof Error ? error : new Error(String(error)),\n            });\n          }\n\n          // Type assertions needed: custom error and finish message formats\n          writer.write({\n            type: \"error\",\n            error: error instanceof Error ? error.message : String(error),\n          } as any);\n          writer.write({ type: \"finish\" } as any);\n        }\n      },\n    });\n\n    const response = createUIMessageStreamResponse({\n      stream,\n      status,\n      statusText,\n      headers,\n    });\n\n    return response;\n  }\n\n  /**\n   * Extract chatId and userId from context for memory operations\n   */\n  private extractMemoryIdentifiers(context: TContext): {\n    chatId?: string;\n    userId?: string;\n  } {\n    const ctx = context as TContext & MemoryIdentifiers;\n    const chatId = ctx.chatId || ctx.metadata?.chatId;\n    const userId = ctx.userId || ctx.metadata?.userId;\n    return { chatId, userId };\n  }\n\n  /**\n   * Generate a title for the chat based on the first user message\n   */\n  private async generateChatTitle(\n    chatId: string,\n    userMessage: string,\n    writer: UIMessageStreamWriter,\n    _context?: TContext,\n  ): Promise<void> {\n    if (!this.memory?.chats?.generateTitle) return;\n\n    const config = this.memory.chats.generateTitle;\n    const model = typeof config === \"object\" ? config.model : this.model;\n    const instructions =\n      typeof config === \"object\" && config.instructions\n        ? config.instructions\n        : `<task_context>\nYou are a helpful assistant that can generate titles for conversations.\n</task_context>\n\n<rules>\nFind the most concise title that captures what the user is asking for.\nTitles should be at most 30 characters.\nTitles should be formatted in sentence case, with capital letters at the start of each word. Do not provide a period at the end.\n</rules>\n\n<task>\nGenerate a title for the conversation.\n</task>\n\n<output_format>\nReturn only the title.\n</output_format>`;\n\n    try {\n      // Generate title based only on the user's message\n      const { text } = await generateText({\n        model,\n        system: instructions,\n        prompt: userMessage,\n        temperature: 0,\n      });\n\n      await this.memory.provider?.updateChatTitle?.(chatId, text);\n\n      writer.write({\n        type: \"data-chat-title\",\n        data: { chatId, title: text },\n      });\n\n      logger.debug(`Generated title for ${chatId}`, { chatId, title: text });\n    } catch (err) {\n      logger.error(\"Title generation failed\", { error: err });\n    }\n  }\n\n  /**\n   * Build capabilities description from available tools and agents\n   */\n  private buildCapabilitiesDescription(context?: TContext): string {\n    const capabilities: string[] = [];\n\n    // Add tools (exclude internal tools)\n    if (this.configuredTools) {\n      // Resolve tools if they're a function\n      const resolvedTools =\n        typeof this.configuredTools === \"function\" && context\n          ? this.configuredTools(context)\n          : typeof this.configuredTools === \"object\"\n            ? this.configuredTools\n            : {};\n\n      const toolNames = Object.keys(resolvedTools).filter(\n        (name) => name !== \"handoff_to_agent\" && name !== \"updateWorkingMemory\",\n      );\n\n      if (toolNames.length > 0) {\n        capabilities.push(\"Available tools:\");\n        for (const toolName of toolNames) {\n          const tool = resolvedTools[toolName];\n          // @ts-expect-error - accessing internal tool properties\n          const description = tool?.spec?.description || toolName;\n          capabilities.push(`- ${toolName}: ${description}`);\n        }\n      }\n    }\n\n    // Add handoff agents\n    const handoffs = this.getHandoffs();\n    if (handoffs.length > 0) {\n      if (capabilities.length > 0) capabilities.push(\"\");\n      capabilities.push(\"Can route to specialist agents:\");\n      for (const agent of handoffs) {\n        // @ts-expect-error - accessing internal agent properties\n        const description = agent.handoffDescription || `${agent.name} agent`;\n        capabilities.push(`- ${agent.name}: ${description}`);\n      }\n    }\n\n    return capabilities.join(\"\\n\");\n  }\n\n  /**\n   * Generate contextual prompt suggestions after agent response\n   */\n  private async generateSuggestions(\n    conversationContext: string,\n    conversationMessages: ModelMessage[],\n    writer: UIMessageStreamWriter,\n    context?: TContext,\n  ): Promise<void> {\n    const config = this.memory?.chats?.generateSuggestions;\n    if (!config) return;\n\n    // Handle boolean true (use defaults) or object config with enabled check\n    let enabled: boolean;\n    if (typeof config === \"boolean\") {\n      enabled = config;\n    } else if (typeof config.enabled === \"function\") {\n      // Call the function with messages and context\n      enabled = await config.enabled({\n        messages: conversationMessages,\n        context,\n      });\n    } else {\n      enabled = config.enabled;\n    }\n\n    if (!enabled) return;\n\n    const model =\n      typeof config === \"object\" && config.model ? config.model : this.model;\n    const limit = typeof config === \"object\" && config.limit ? config.limit : 5;\n\n    // Build default instructions with actual capabilities\n    const defaultInstructions = `Generate ${limit} contextual follow-up suggestions based on what was JUST discussed.\n\n${this.buildCapabilitiesDescription(context)}\n\nGuidelines:\n1. Analyze what the assistant just showed/discussed (data, analysis, insights)\n2. Suggest logical NEXT STEPS that build on this specific response\n3. Keep suggestions ultra-brief (2-3 words ideal, max 5 words)\n4. Use action verbs (\"Show\", \"Compare\", \"Analyze\", \"Check\", \"List\", \"Explore\")\n5. Make suggestions specific to the context, not generic\n6. Focus on available capabilities that provide value\n\nGood suggestions are:\n- Specific to what was just discussed\n- Actionable using available capabilities\n- Brief and clear (2-3 words)\n- Natural next steps, not repetitive`;\n\n    const instructions =\n      typeof config === \"object\" && config.instructions\n        ? config.instructions\n        : defaultInstructions;\n\n    try {\n      // Define schema for structured output\n      const suggestionsSchema = z.object({\n        prompts: z\n          .array(z.string().max(40))\n          .min(3)\n          .max(limit)\n          .describe(`Array of prompt suggestions (2-5 words each)`),\n      });\n\n      // Generate suggestions using structured output\n      const { object } = await generateObject({\n        model,\n        system: instructions,\n        prompt: conversationContext,\n        schema: suggestionsSchema,\n        mode: \"json\",\n      });\n\n      const { prompts } = object;\n\n      // Stream suggestions as transient data part\n      writeSuggestions(writer, prompts);\n    } catch (err) {\n      logger.error(\"Suggestion generation failed\", { error: err });\n    }\n  }\n\n  /**\n   * Create the updateWorkingMemory tool\n   */\n  private createWorkingMemoryTool() {\n    const scope = this.memory?.workingMemory?.scope || \"chat\";\n    const memory = this.memory;\n    const extractMemoryIdentifiers = this.extractMemoryIdentifiers.bind(this);\n\n    return tool({\n      description: `Save user information to persistent memory for future conversations.`,\n      inputSchema: z.object({\n        content: z\n          .string()\n          .describe(\n            \"Updated working memory content in markdown format. Include user preferences and any important facts to remember.\",\n          ),\n      }),\n      execute: async ({ content }, options) => {\n        logger.debug(\"updateWorkingMemory tool called\", {\n          contentLength: content.length,\n        });\n\n        if (!memory?.provider) {\n          logger.warn(\"Memory provider not configured\");\n          return \"Memory system not configured\";\n        }\n\n        const { getContext } = await import(\"./context.js\");\n        const ctx = getContext(\n          options as { experimental_context?: Record<string, unknown> },\n        );\n        const contextData = ctx as TContext | undefined;\n\n        if (!contextData) {\n          logger.warn(\"Context not available for working memory update\");\n          return \"Context not available\";\n        }\n\n        const { chatId, userId } = extractMemoryIdentifiers(contextData);\n        logger.debug(\"Updating working memory\", { chatId, userId, scope });\n\n        try {\n          await memory.provider.updateWorkingMemory({\n            chatId,\n            userId,\n            scope,\n            content,\n          });\n          logger.debug(\"Working memory updated successfully\");\n          return \"success\";\n        } catch (error) {\n          logger.error(\"Failed to update working memory\", {\n            error: error instanceof Error ? error.message : error,\n          });\n          return \"error\";\n        }\n      },\n    });\n  }\n\n  /**\n   * Load working memory and inject into system prompt\n   */\n  private async loadWorkingMemory(context: TContext): Promise<string> {\n    if (!this.memory?.workingMemory?.enabled || !this.memory?.provider) {\n      return \"\";\n    }\n\n    const { chatId, userId } = this.extractMemoryIdentifiers(context);\n    const scope = this.memory.workingMemory.scope;\n\n    try {\n      const memory = await this.memory.provider.getWorkingMemory({\n        chatId,\n        userId,\n        scope,\n      });\n\n      if (!memory) return \"\";\n\n      return formatWorkingMemory(memory);\n    } catch (error) {\n      logger.error(\"Failed to load working memory\", {\n        error: error instanceof Error ? error.message : error,\n      });\n      return \"\";\n    }\n  }\n\n  /**\n   * Load message history from memory and prepend to the current message.\n   * Falls back to just the current message if history is disabled or unavailable.\n   *\n   * @param message - The current user message\n   * @param context - Execution context containing chatId\n   * @returns Array of ModelMessages including history + current message\n   */\n  private async loadMessagesWithHistory(\n    message: UIMessage,\n    context: TContext | undefined,\n  ): Promise<ModelMessage[]> {\n    // No memory - just convert the message\n    if (!this.memory?.history?.enabled || !context) {\n      logger.debug(\n        \"History disabled or no context - using single message only\",\n      );\n      return convertToModelMessages([message]);\n    }\n\n    const { chatId } = this.extractMemoryIdentifiers(context);\n\n    if (!chatId) {\n      logger.warn(\"Cannot load history: chatId missing from context\");\n      return convertToModelMessages([message]);\n    }\n\n    // Check if provider exists\n    if (!this.memory.provider) {\n      logger.warn(\"No memory provider configured - using single message only\");\n      return convertToModelMessages([message]);\n    }\n\n    try {\n      const previousMessages =\n        (await this.memory.provider.getMessages?.({\n          chatId,\n          limit: this.memory.history.limit,\n        })) || [];\n\n      logger.debug(`Loading history for chatId=${chatId}`, {\n        chatId,\n        count: previousMessages.length,\n      });\n\n      if (previousMessages.length === 0) {\n        logger.debug(\"No previous messages found - starting new conversation\");\n        return convertToModelMessages([message]);\n      }\n\n      const historyMessages = convertToModelMessages(\n        stripMetadata(previousMessages),\n      );\n\n      logger.debug(\n        `Loaded ${historyMessages.length} history messages for context`,\n        {\n          count: historyMessages.length,\n        },\n      );\n      return [...historyMessages, ...convertToModelMessages([message])];\n    } catch (err) {\n      logger.error(`Load history failed for chatId=${chatId}`, {\n        chatId,\n        error: err,\n      });\n      return convertToModelMessages([message]);\n    }\n  }\n\n  /**\n   * Save user and assistant messages, then update chat session.\n   * Messages are saved in parallel for better performance.\n   *\n   * @param chatId - The chat identifier\n   * @param userId - Optional user identifier\n   * @param userMessage - The user's message text\n   * @param assistantMessage - The assistant's response text\n   * @param existingChat - Pre-loaded chat object to avoid duplicate queries\n   */\n  private async saveConversation(\n    chatId: string,\n    userId: string | undefined,\n    userMessage: string,\n    assistantMessage: string,\n    existingChat?: any,\n  ): Promise<void> {\n    if (!this.memory?.provider || !this.memory?.history?.enabled) return;\n\n    logger.debug(`Saving conversation for chatId=${chatId}`, {\n      chatId,\n      userLength: userMessage.length,\n      assistantLength: assistantMessage.length,\n    });\n\n    // Save messages and update chat session in parallel for better performance\n    try {\n      const savePromises = [\n        this.memory.provider.saveMessage?.({\n          chatId,\n          userId,\n          role: \"user\",\n          content: userMessage,\n          timestamp: new Date(),\n        }),\n      ];\n\n      // Only save assistant message if it has content\n      if (assistantMessage && assistantMessage.length > 0) {\n        logger.debug(`Will save assistant message`, {\n          length: assistantMessage.length,\n        });\n        savePromises.push(\n          this.memory.provider.saveMessage?.({\n            chatId,\n            userId,\n            role: \"assistant\",\n            content: assistantMessage,\n            timestamp: new Date(),\n          }),\n        );\n      } else {\n        logger.warn(`Skipping assistant message save - empty or undefined`);\n      }\n\n      // Batch chat session update with message saves (using passed existingChat to avoid duplicate query)\n      if (this.memory?.chats?.enabled) {\n        const messageCount = savePromises.length;\n\n        savePromises.push(\n          this.memory.provider.saveChat?.({\n            ...(existingChat || { chatId, userId, createdAt: new Date() }),\n            messageCount: (existingChat?.messageCount || 0) + messageCount,\n            updatedAt: new Date(),\n          }),\n        );\n      }\n\n      await Promise.all(savePromises);\n\n      logger.debug(`Successfully saved ${savePromises.length} items`, {\n        chatId,\n        count: savePromises.length,\n      });\n    } catch (error) {\n      logger.error(`Failed to save messages for chatId=${chatId}`, {\n        chatId,\n        error,\n      });\n      throw error; // Re-throw to make save failures visible\n    }\n  }\n\n  /**\n   * Generate a chat title if this is the first message.\n   * Runs asynchronously without blocking the response.\n   *\n   * @param context - Execution context containing chatId\n   * @param userMessage - The user's message to generate title from\n   * @param writer - Stream writer for sending title update\n   * @param existingChat - Pre-loaded chat object to avoid duplicate queries\n   */\n  private async maybeGenerateChatTitle(\n    context: TContext | undefined,\n    userMessage: string,\n    writer: UIMessageStreamWriter,\n    existingChat?: any,\n  ): Promise<void> {\n    if (\n      !this.memory?.chats?.enabled ||\n      !this.memory?.chats?.generateTitle ||\n      !context\n    ) {\n      return;\n    }\n\n    const { chatId } = this.extractMemoryIdentifiers(context);\n\n    if (!chatId) {\n      logger.warn(\"Cannot generate title: chatId missing from context\");\n      return;\n    }\n\n    // Only generate for first message (using passed existingChat to avoid duplicate query)\n    const isFirstMessage = !existingChat || existingChat.messageCount === 0;\n    if (isFirstMessage) {\n      this.generateChatTitle(chatId, userMessage, writer, context).catch(\n        (err) => logger.error(\"Title generation error\", { error: err }),\n      );\n    }\n  }\n\n  static create<\n    TContext extends Record<string, unknown> = Record<string, unknown>,\n  >(config: AgentConfig<TContext>): Agent<TContext> {\n    return new Agent<TContext>(config);\n  }\n}\n"],"names":["generateIdAi","__NEXT_RELATIVE_DIST_DIR","env","__NEXT_RELATIVE_PROJECT_DIR","cached","writer","getWriter","result"],"mappings":"wCACA,IAAA,EAAA,EAAA,CAAA,CAAA,QACO,IAAM,EAAsB,CAAA,EAAA,EAAA,uBAAA,AAAuB,EACtD,WAAa,MAAM,AAAI,MAAM,oPAAsP,EACnR,8DACA,uBAES,EAAyB,CAAA,EAAA,EAAA,uBAAA,AAAuB,EACzD,WAAa,MAAM,AAAI,MAAM,0PAA4P,EACzR,8DACA,0BAES,EAAkB,CAAA,EAAA,EAAA,uBAAA,AAAuB,EAClD,WAAa,MAAM,AAAI,MAAM,4OAA8O,EAC3Q,8DACA,mBAES,EAAiB,CAAA,EAAA,EAAA,uBAAA,AAAuB,EACjD,WAAa,MAAM,AAAI,MAAM,0OAA4O,EACzQ,8DACA,kBAES,EAAe,CAAA,EAAA,EAAA,uBAAA,AAAuB,EAC/C,WAAa,MAAM,AAAI,MAAM,sOAAwO,EACrQ,8DACA,gBAES,EAAiB,CAAA,EAAA,EAAA,uBAAuB,AAAvB,EAC1B,WAAa,MAAM,AAAI,MAAM,0OAA4O,EACzQ,8DACA,kBAES,EAAe,CAAA,EAAA,EAAA,uBAAA,AAAuB,EAC/C,WAAa,MAAM,AAAI,MAAM,sOAAwO,EACrQ,8DACA,gBAES,EAAY,CAAA,EAAA,EAAA,uBAAA,AAAuB,EAC5C,WAAa,MAAM,AAAI,MAAM,gOAAkO,EAC/P,8DACA,aAES,EAAkB,CAAA,EAAA,EAAA,uBAAA,AAAuB,EAClD,WAAa,MAAM,AAAI,MAAM,4OAA8O,EAC3Q,8DACA,mBAES,EAAe,CAAA,EAAA,EAAA,uBAAuB,AAAvB,EACxB,WAAa,MAAM,AAAI,MAAM,sOAAwO,EACrQ,8DACA,gBAES,EAAgB,CAAA,EAAA,EAAA,uBAAA,AAAuB,EAChD,WAAa,MAAM,AAAI,MAAM,wOAA0O,EACvQ,8DACA,iBAES,EAAe,CAAA,EAAA,EAAA,uBAAA,AAAuB,EAC/C,WAAa,MAAU,AAAJ,MAAU,sOAAwO,EACrQ,8DACA,gBAES,EAAc,CAAA,EAAA,EAAA,uBAAA,AAAuB,EAC9C,WAAa,MAAM,AAAI,MAAM,oOAAsO,EACnQ,8DACA,eAES,EAAe,CAAA,EAAA,EAAA,uBAAA,AAAuB,EAC/C,WAAa,MAAM,AAAI,MAAM,sOAAwO,EACrQ,8DACA,gBAES,EAAiB,CAAA,EAAA,EAAA,uBAAA,AAAuB,EACjD,WAAa,MAAM,AAAI,MAAM,0OAA4O,EACzQ,8DACA,kBAES,EAA0B,CAAA,EAAA,EAAA,uBAAA,AAAuB,EAC1D,WAAa,MAAM,AAAI,MAAM,4PAA8P,EAC3R,8DACA,2BAES,EAAiB,CAAA,EAAA,EAAA,uBAAA,AAAuB,EACjD,WAAa,MAAM,AAAI,MAAM,0OAA4O,EACzQ,8DACA,kBAES,EAAkB,CAAA,EAAA,EAAA,uBAAA,AAAuB,EAClD,WAAa,MAAM,AAAI,MAAM,4OAA8O,EAC3Q,8DACA,mBAES,EAAwB,CAAA,EAAA,EAAA,uBAAA,AAAuB,EACxD,WAAa,MAAM,AAAI,MAAM,wPAA0P,EACvR,8DACA,yBAES,EAAgB,CAAA,EAAA,EAAA,uBAAA,AAAuB,EAChD,WAAa,MAAM,AAAI,MAAM,wOAA0O,EACvQ,8DACA,iBAES,EAAe,CAAA,EAAA,EAAA,uBAAA,AAAuB,EAC/C,WAAa,MAAM,AAAI,MAAM,sOAAwO,EACrQ,8DACA,gBAES,EAAc,CAAA,EAAA,EAAA,uBAAA,AAAuB,EAC9C,WAAa,MAAM,AAAI,MAAM,oOAAsO,EACnQ,8DACA,eAES,EAAiB,CAAA,EAAA,EAAA,uBAAA,AAAuB,EACjD,WAAa,MAAM,AAAI,MAAM,0OAA4O,EACzQ,8DACA,kBAES,EAAqB,CAAA,EAAA,EAAA,uBAAA,AAAuB,EACrD,WAAa,MAAU,AAAJ,MAAU,kPAAoP,EACjR,8DACA,yjBAvHJ,IAAA,EAAA,EAAA,CAAA,CAAA,QACO,IAAM,EAAsB,CAAA,EAAA,EAAA,uBAAA,AAAuB,EACtD,WAAa,MAAM,AAAI,MAAM,oPAAsP,EACnR,0CACA,uBAES,EAAyB,CAAA,EAAA,EAAA,uBAAuB,AAAvB,EAClC,WAAa,MAAM,AAAI,MAAM,0PAA4P,EACzR,0CACA,0BAES,EAAkB,CAAA,EAAA,EAAA,uBAAA,AAAuB,EAClD,WAAa,MAAM,AAAI,MAAM,4OAA8O,EAC3Q,0CACA,mBAES,EAAiB,CAAA,EAAA,EAAA,uBAAA,AAAuB,EACjD,WAAa,MAAM,AAAI,MAAM,0OAA4O,EACzQ,0CACA,kBAES,EAAe,CAAA,EAAA,EAAA,uBAAA,AAAuB,EAC/C,WAAa,MAAM,AAAI,MAAM,sOAAwO,EACrQ,0CACA,gBAES,EAAiB,CAAA,EAAA,EAAA,uBAAA,AAAuB,EACjD,WAAa,MAAM,AAAI,MAAM,0OAA4O,EACzQ,0CACA,kBAES,EAAe,CAAA,EAAA,EAAA,uBAAA,AAAuB,EAC/C,WAAa,MAAM,AAAI,MAAM,sOAAwO,EACrQ,0CACA,gBAES,EAAY,CAAA,EAAA,EAAA,uBAAA,AAAuB,EAC5C,WAAa,MAAM,AAAI,MAAM,gOAAkO,EAC/P,0CACA,aAES,EAAkB,CAAA,EAAA,EAAA,uBAAA,AAAuB,EAClD,WAAa,MAAM,AAAI,MAAM,4OAA8O,EAC3Q,0CACA,mBAES,EAAe,CAAA,EAAA,EAAA,uBAAuB,AAAvB,EACxB,WAAa,MAAM,AAAI,MAAM,sOAAwO,EACrQ,0CACA,gBAES,EAAgB,CAAA,EAAA,EAAA,uBAAuB,AAAvB,EACzB,WAAa,MAAM,AAAI,MAAM,wOAA0O,EACvQ,0CACA,iBAES,EAAe,CAAA,EAAA,EAAA,uBAAA,AAAuB,EAC/C,WAAa,MAAM,AAAI,MAAM,sOAAwO,EACrQ,0CACA,gBAES,EAAc,CAAA,EAAA,EAAA,uBAAA,AAAuB,EAC9C,WAAa,MAAM,AAAI,MAAM,oOAAsO,EACnQ,0CACA,eAES,EAAe,CAAA,EAAA,EAAA,uBAAuB,AAAvB,EACxB,WAAa,MAAM,AAAI,MAAM,sOAAwO,EACrQ,0CACA,gBAES,EAAiB,CAAA,EAAA,EAAA,uBAAuB,AAAvB,EAC1B,WAAa,MAAM,AAAI,MAAM,0OAA4O,EACzQ,0CACA,kBAES,EAA0B,CAAA,EAAA,EAAA,uBAAuB,AAAvB,EACnC,WAAa,MAAU,AAAJ,MAAU,4PAA8P,EAC3R,0CACA,2BAES,EAAiB,CAAA,EAAA,EAAA,uBAAA,AAAuB,EACjD,WAAa,MAAM,AAAI,MAAM,0OAA4O,EACzQ,0CACA,kBAES,EAAkB,CAAA,EAAA,EAAA,uBAAA,AAAuB,EAClD,WAAa,MAAM,AAAI,MAAM,4OAA8O,EAC3Q,0CACA,mBAES,EAAwB,CAAA,EAAA,EAAA,uBAAA,AAAuB,EACxD,WAAa,MAAM,AAAI,MAAM,wPAA0P,EACvR,0CACA,yBAES,EAAgB,CAAA,EAAA,EAAA,uBAAA,AAAuB,EAChD,WAAa,MAAM,AAAI,MAAM,wOAA0O,EACvQ,0CACA,iBAES,EAAe,CAAA,EAAA,EAAA,uBAAA,AAAuB,EAC/C,WAAa,MAAU,AAAJ,MAAU,sOAAwO,EACrQ,0CACA,gBAES,EAAc,CAAA,EAAA,EAAA,uBAAuB,AAAvB,EACvB,WAAa,MAAM,AAAI,MAAM,oOAAsO,EACnQ,0CACA,eAES,EAAiB,CAAA,EAAA,EAAA,uBAAA,AAAuB,EACjD,WAAa,MAAM,AAAI,MAAM,0OAA4O,EACzQ,0CACA,kBAES,EAAqB,CAAA,EAAA,EAAA,uBAAA,AAAuB,EACrD,WAAa,MAAM,AAAI,MAAM,kPAAoP,EACjR,0CACA,6nBGtHa,MDFjB,IKqFwC,Ia5E3B,ElBTb,CK4FC,CL5FD,EAAA,CAAA,CAAA,QACA,EAAA,EAAA,CAAA,CAAA,QACA,EAAA,EAAA,CAAA,CAAA,QACA,EAAA,EAAA,CAAA,CAAA,QACA,EAAA,EAAA,CAAA,CAAA,QACA,EAAA,EAAA,CAAA,CAAA,QACA,EAAA,EAAA,CAAA,CAAA,QACA,EAAA,EAAA,CAAA,CAAA,OACA,EAAA,EAAA,CAAA,CAAA,QACA,EAAA,EAAA,CAAA,CAAA,QACA,EAAA,EAAA,CAAA,CAAA,QACA,EAAA,EAAA,CAAA,CAAA,QACA,EAAA,EAAA,CAAA,CAAA,QACA,EAAA,EAAA,CAAA,CAAA,QACA,EAAA,EAAA,CAAA,CAAA,QACA,EAAA,EAAA,CAAA,CAAA,OACA,EAAA,EAAA,CAAA,CAAA,QACA,EAAA,CAAA,CAAA,QAAA,IAAA,EAAA,EAAA,CAAA,CAAA,QEjBA,EAAA,EAAA,CAAA,CAAA,QAAA,EAAA,EAAA,CAAA,CAAA,QACA,EAAA,EAAA,CAAA,CAAA,QIaA,EAAA,EAAA,CAAA,CAAA,QPTA,EAAA,CAAA,CAAA,QKCA,EAAA,CAAA,CAAA,QE+FA,EAAA,CAAA,CAAA,QA2DA,EAAA,CAAA,CAAA,QLhKA,IAAI,EAAY,OAAO,cAAc,CACjC,EAAoB,OAAO,mBAAmB,CAIlC,EAMM,CAAC,EANC,EAOE,CACxB,uBAAwB,IAAM,EAC9B,WAAY,IAAM,CACpB,EATE,IAAK,IAAI,KAAQ,EACf,EAAU,EAAQ,EAAM,CAAE,IAAK,CAAG,CAAC,EAAK,CAAE,YAAY,CAAK,GAS/D,SAAS,EAAuB,CAAO,EACrC,MAAO,CACL,GAAG,EAAQ,OAAO,CAClB,OAAQ,EAAQ,MAAM,CACtB,SAAU,CACR,UAA2B,CAAhB,GAAoB,KAC/B,GAAG,EADqB,AACb,QAAQ,AACrB,CACF,CACF,CACA,SAAS,EAAW,CAAgB,EAClC,OAAO,GAAkB,oBAC3B,CACA,IAAI,GA3BS,EA2BY,CACvB,SADiB,UAGjB,CACF,EA/ByB,SAAS,EAChC,OAAO,IAAO,EAAM,AAAP,CAAQ,EAAG,CAAE,CAAC,EAAkB,EAAG,CAAC,EAAE,CAAC,EAAE,EAAK,EAAA,CAAE,CAAG,CAClE,GAgCI,EAA8C,SAA7B,QAAQ,GAAG,CAAC,YAAY,GAEpC,YACD,aAEA,WAMJ,EAAY,IAAO,AAAD,AAAiB,IAAI,OAAQ,EAAf,SAA0B,GAAG,KAAK,CAAC,GAAI,IAC3E,SAAS,EAAa,CAAQ,SAC5B,AAAK,EAYE,CACL,CAbE,KAaK,CAAC,EAAS,IAbE,CAcjB,IAAM,EAAK,CAAA,EAAG,EAAY,CAAC,EAAE,EAAR,EAAoB,CAAC,CAAjB,CAAmB,EAAY,CAAE,CACpD,EAAQ,CADqC,EAClC,GADuC,IAChC,IAAI,CAAC,IAAqB,CAAhB,AAC5B,EAD8B,AACxB,CAAA,EAAG,EAAY,CAAC,CADe,CACb,EAAS,AAAjB,CAAkB,CADQ,CACN,CAAhB,CAA4B,CAAE,CAClD,EAAU,CADiC,CAC1B,CAAC,CAAC,EAD6B,AAC3B,EAAW,EAAG,GAAP,EAAY,EAAR,OAAiB,CAAC,GAAA,EAAQ,EAAY,CAAE,CAAG,GAAV,AACvE,KAD4E,GACpE,GAAG,CAAC,CAAA,EAAG,EAAG,CAAC,EAAE,EAAM,CAAC,EAAE,EAAI,CAAC,EAAE,EAAA,EAAU,EAAA,CAAS,CAC1D,EACA,KAAM,CAAC,EAAS,KACd,IAAM,EAAK,CAAA,EAAG,EAAY,CAAC,EAAE,EAAR,EAAoB,CAAC,CAAjB,CAAmB,EAAY,CAAE,CACpD,EAAQ,CADqC,EAClC,GADuC,IAChC,KAAK,CAAC,EAAoB,CAC5C,CAD4B,CACtB,CADwB,AACxB,EAAG,EAAY,CAAC,EADe,AACb,EAAR,AAAiB,CAAC,EAAE,AADM,CACtB,CAA4B,CAAE,CAClD,EAAU,CADiC,CAC1B,CAAC,CAAC,EAD6B,AAC3B,EAAW,EAAG,GAAP,EAAY,EAAR,OAAiB,CAAC,GAAA,EAAQ,EAAY,CAAE,CAAG,GACjF,AADuE,KAAK,GACpE,GAAG,CAAC,CAAA,EAAG,EAAG,CAAC,EAAE,EAAM,CAAC,EAAE,EAAI,CAAC,EAAE,EAAA,EAAU,EAAA,CAAS,CAC1D,EACA,KAAM,CAAC,EAAS,KACd,IAAM,EAAK,CAAA,EAAG,EAAY,CAAC,EAAE,EAAR,EAAoB,CAAC,CAAjB,CAAmB,EAAY,CAAE,CACpD,EAAQ,CADqC,EAClC,GADuC,IAChC,MAAM,CAAC,CAAoB,CAC7C,EAD6B,AACvB,CAAA,CADyB,CACtB,EAAY,CAAC,EAAE,CADc,CACL,AAAjB,CAAkB,EAAE,CAAhB,AADuB,CACK,CAAE,CAClD,EAAU,CADiC,CAC1B,CAAC,CAAC,EAAE,AAD2B,EAChB,EAAG,GAAP,EAAY,EAAR,OAAiB,CAAC,GAAA,EAAQ,EAAY,CAAE,CAAG,GAAV,AACvE,KAD4E,GACpE,IAAI,CAAC,CAAA,EAAG,EAAG,CAAC,EAAE,EAAM,CAAC,EAAE,EAAI,CAAC,EAAE,EAAA,EAAU,EAAA,CAAS,CAC3D,EACA,MAAO,CAAC,EAAS,KACf,IAAM,EAAK,CAAA,EAAG,EAAY,CAAC,EAAE,EAAR,EAAoB,CAAC,CAAjB,CAAmB,EAAY,CAAE,CACpD,EAAQ,CADqC,EAClC,GADuC,IAChC,GAAG,CAAC,KAAK,AAAgB,CAC3C,CAD6B,CACvB,CAAA,EAAG,EAAY,CAAC,AADc,EACZ,EAAR,AAAiB,CAAC,AADO,EACL,CAAhB,CAA4B,CAAE,CAClD,EAAU,CADiC,CAC1B,CAAC,CAAC,EAD6B,AAC3B,EAAW,EAAG,GAAP,EAAY,EAAR,OAAiB,CAAC,GAAA,EAAQ,EAAY,CAAE,CAAG,GAAV,AACvE,KAD4E,GACpE,KAAK,CAAC,CAAA,EAAG,EAAG,CAAC,EAAE,EAAM,CAAC,EAAE,EAAI,CAAC,EAAE,EAAA,EAAU,EAAA,CAAS,CAC5D,CACF,EAxCS,CACL,MAAO,KACP,EACA,KAAM,KACN,EACA,KAAM,KACN,EACA,MAAO,KACP,CACF,CAgCJ,CA4CA,IAqHa,EAAa,kBAiGZ,EAAa,SA+pC3B,IAuJc,EAAa,WMpoD3B,IAAA,EAAA,EAAA,CAAA,CAAA,OAOA,EAAA,CAAA,CAAA,QAwEiB,AACG,CADH,EAAA,EAAA,wBAAwB,AAAxB,IACY,iOGzFW,CAAA,CC+ClB,CAACC,AD9CrB,IAAA,EAAkC,IAAE,EAAA,OAAI,CAAA,CAAO,CC+CnBC,GAAG,CAACC,iBDzC9B,OAAA,EAA0B,CCyC+B,ADzC/B,CAAA,EACxB,IAAM,EAAW,MAAX,GDPI,AAAe,CAAA,EAAoC,IAE/D,OAAO,EAAA,KAAO,CAAM,CAAA,EACtB,CAAA,KAAQ,QACC,CAAC,AACV,GCEiC,GACvB,EAAA,CAD6B,CAAA,AACV,KAAA,CAAM,CAAE,GAAG,CAAA,CAAU,GAAG,CAAA,CAAM,CAAA,CAEvD,MAAO,KACD,ADdH,SAAA,EAAY,KAAK,GAAA,GAAK,CAAA,EAAA,CAAA,EAAIH,EAAAA,UAAAA,IAAAA,CAAc,eCgBjC,qCAGG,KAAA,GAAA,kBACK,GAAA,GAEpB,SAGE,CAAA,CAAA,CACA,MAEM,EAAA,IAAW,CAAA,CAAX,KAAgB,CAAO,IAAI,CAAA,KACjC,EAAS,MAAA,CAAS,SAAA,KACP,EAAkB,EAAQ,EAAU,EAAlB,IAAQ,AAAgB,CAAA,SAI9C,CADA,CACO,KAAA,CAAM,GAGtB,QAAQ,CAAA,0BAIN,CAAA,KAAQ,CACN,OAAO,CACT,eKrBoB,CAAA,EAA+C,AAEvE,IAAA,EAAA,GAAiC,sBAAsB,OAEvD,GAAA,CAAA,QACY,MAAA,gGAKZ,OAAO,CACT,2CIlCa,EAAN,mBAMH,CACA,CAAA,CAAA,CACA,CAAA,CAEA,IAAA,CAAA,MAAA,CAAA,OACK,QAAA,CAAW,OACX,MAAA,CAAS,aAGT,GAGP,IAAI,MAAA,QACK,IAAA,CAAA,QAAK,CAAS,OAAA,AACvB,KAEI,IAAa,QACR,IAAA,CAAK,QAAA,CAAS,EAAA,KAGnB,UAA+B,CACjC,OAAO,IAAA,CAAA,QAAA,CAAc,QAAA,KAGnB,SAAS,CAAA,CAA2B,CACtC,IAAA,CAAK,QAAA,CAAS,QAAA,CAAW,OACpB,QAAA,CAAS,CCjBK,QAAA,CDiBO,KAAA,GAAK,OAC/B,CAAK,MAAA,EAAO,CAGd,MAAM,OAAO,CAAA,CAA4D,cACrD,QAChB,CADyB,AACpB,QAAA,CAAA,QAAA,CAAoB,EAAQ,KAAR,GAAQ,QACzB,EAAoC,QAAA,GRiI9C,GQ9HA,CAAK,QAAA,CAAS,OAAA,CAAU,CAAE,GAAG,IAAA,CAAK,QAAA,CAAS,OAAA,CAAS,GAAG,CAAA,CAAQ,KAC/D,CR6H0D,AQ7H1D,QAAA,CAAA,MAAA,CAAuB,gBACvB,CAAK,QAAA,CAAS,OAAA,GACd,IAAA,CAAK,QAAA,CAAA,SAAS,CAAY,KAAK,GAAA,EAAI,KACnC,CAAA,MAAK,EACP,CAEA,MAAM,SAAS,CAAA,CAAA,CACT,GACF,KAAA,CAAK,EADQ,MACR,CAAS,OAAA,CAAU,CAAA,EAE1B,IAAA,CAAK,QAAA,CAAS,MAAA,CAAS,gBAClB,QAAA,CAAA,QAAS,CAAW,CAAA,CACzB,IAAA,CAAK,QAAA,CAAS,OAAA,EAAA,cACT,CAAS,SAAA,CAAY,KAAA,GAAK,GAC/B,IAAA,CAAK,MAAA,EAAO,AACd,aAEY,CAAA,CAAgC,CAC1C,IAAA,CAAK,QAAA,CAAS,MAAA,CAAS,OAAA,KACvB,CAAK,QAAA,CAAS,KAAA,CAAQ,EACtB,IAAA,CAAK,QAAA,CAAS,OAAA,EAAA,KACd,CAAA,QAAK,CAAS,SAAA,CAAA,KAAA,GAAiB,EAAI,CACnC,IAAA,CAAA,MAAA,EACF,OAEM,QAAA,KACJ,CAAA,QAAA,CAAA,MAAA,CAAuB,OAAA,MAClB,QAAA,CAAA,KAAS,CAAQ,sCACjB,CAAS,OAAA,EAAA,MACT,QAAA,CAAS,SAAA,CAAY,IAAA,CAAK,GAAA,EAAI,MAC9B,MAAA,EACP,CAEA,QAAA,CAAQ,CAAkB,CACxB,WAAW,MAEkB,CEzEQ,WFyEjC,IAAA,CAAK,QAAA,CAAS,MAAA,EACW,cAAzB,IAAA,CAAK,QAAA,CAAS,MAAW,AAAX,CAAW,EACzB,IACA,CAAA,KAAK,CAAA,CAAM,yBAAA,EAAA,EAA8B,EAAA,CAAI,CAAA,IAGnD,CAEQ,QAAA,YACD,CAAO,KAAA,CAAM,CAChB,KAAA,CAAA,cAAM,EAAA,IAAiB,CAAK,MAAA,CAAO,EAAE,CAAA,CAAA,CACrC,GAAI,IAAA,CAAK,QAAA,CAAS,EAAA,MACZ,IAAA,CAAK,QAAA,EAEf,KDvFK,CITc,aJSc,KAAA,CACjC,AADuC,YAE9B,CAAA,CAAA,CAAA,CAEP,CACA,KAAA,CAAM,QAHC,IAAA,CAAA,MAIP,CAAK,IAAA,CAAA,eACP,sDKXW,EAAN,kBAIO,EAAU,GAAA,CAAM,KAH5B,CAAQ,KAAA,CAAA,IAAY,GAAA,CAIlB,IAAA,CAAA,OAAA,CAAe,MAGb,CAAA,CAAwC,CAC1C,IAAA,EAAc,IAAA,CAAK,KAAA,CAAM,GAAA,CAAA,GAMzB,OALI,IAEF,GAFS,CAET,CAAK,KAAA,CAAM,MAAA,CAAO,GAClB,IAAA,CAAK,KAAA,CAAM,GAAA,CAAA,EAAS,IAEf,CACT,CAEA,IAAI,CAAA,CAAA,CAAa,CAAA,CAEf,GAAA,IAAA,CAAS,KAAA,CAAM,GAAA,CAAI,MAAM,CACvB,CAAA,KAAK,CAAM,MAAA,CAAA,QACb,GAES,IAAA,CAAA,KAAA,CAAA,IAAW,EAAQ,IAAA,CAAK,OAAA,CAAS,OACvB,IAAA,CAAK,KAAA,CAAM,IAAA,GAAO,IAAA,EAAK,CAAE,KAAA,IAExC,IAAA,CAAK,CADO,IACP,CAAM,MAAA,CAAO,QAIjB,KAAA,CAAM,GAAA,CAAI,EAAK,CAAL,UAGV,CAAA,CACL,OAAA,IAAO,CAAA,KAAK,CAAM,MAAA,CAAO,EAC3B,CAD8B,CAAA,kBAIjB,KAAA,EACb,CAEA,IAAI,CAAA,CAAsB,QACjB,IAAA,CAAA,KAAK,CAAM,GAAA,CAAI,EACxB,CAEA,MAAA,CACE,OAAO,IAAA,CAAK,KAAA,CAAM,IACpB,AADoB,OAGH,QACR,MAAM,IAAA,CAAK,IAAA,CAAA,KAAK,CAAM,IAAA,EAAM,CAAA,CAGrC,eAAqC,IAQhC,GAAA,MAIL,YAAA,EAAA,GAAsB,CAAM,YAHpB,EAAA,EAAY,QAIlB,CAAK,OAAA,CAAU,EAGjB,IAAI,CAAA,CAAwC,QACnC,IAAA,CAAK,KAAA,CAAA,GAAM,CAAI,OAGpB,CAAA,CAAa,CAAA,CAA4B,CAEvC,IAAA,CAAK,KAAA,CAAA,IAAM,EAAQ,IAAA,CAAK,OAAA,EAAS,AACnC,IAAA,CAAK,KAAA,CAAM,KAAA,GAEb,IAAA,CAAA,KAAK,CAAM,GAAA,CAAI,EAAA,GAGjB,OAAO,CAAA,CAAsB,QACpB,IAAA,CAAK,KAAA,CAAA,MAAM,CAAO,GAAG,AAG9B,OAAc,CACZ,IAAA,CAAK,KAAA,CAAA,KAAM,OAGT,CAAA,CAAA,QACK,IAAA,CAAA,KAAK,CAAA,GAAA,CAAA,GAGd,MAAe,QACN,IAAA,CAAA,KAAK,CAAA,IAAM,OAGH,QACR,MAAA,IAAA,CAAW,IAAA,CAAK,KAAA,CAAM,IAAA,EAAM,CAAA,CAGrC,eAAqC,CAErC,GCxGW,GAAN,kBAMO,EAAA,GAAU,CAAM,CAL5B,IAAA,CAAQ,KAAA,CAAA,IAAY,GAAA,CACpB,CAD+C,GAC/C,CAAQ,WAAA,CAAA,IAAkB,GAAA,CAE1B,IAAA,CAAQ,aAAA,CAAgB,EAGtB,IAAA,CAAK,OAAA,CAAU,OAGb,CAAwC,KACpC,EAAQ,IAAA,CAAK,KAAA,CAAM,GAAA,CAAI,GAK7B,AALgC,CAAA,MAC5B,GAEF,IAFS,AAET,CAAK,WAAA,CAAY,GAAA,CAAI,EAAK,EAAE,IAAA,CAAK,aAAa,CAAA,CAEzC,EAGT,GAHS,CAGL,CAAA,CAAa,CAAA,CAA4B,CAE3C,GAAA,IAAI,CAAK,KAAA,CAAM,GAAA,CAAI,GAAG,AAAG,CACvB,IAAA,CAAA,KAAK,CAAM,GAAA,CAAA,EAAA,OACX,CAAA,WAAA,CAAiB,GAAA,CAAA,EAAA,EAAA,IAAW,CAAK,aAAa,CAAA,CAC9C,MACF,CC6CC,AD1CG,IAAA,CAAK,KAAA,CAAA,IAAM,EAAQ,IAAA,CAAA,OAAK,EAAS,KAC9B,QAAA,QAGF,KAAA,CAAA,GAAA,CAAA,EAAA,QACA,WAAA,CAAA,GAAY,CAAA,EAAS,EAAE,IAAA,CAAK,aAAa,CAAA,QAGzC,CAAA,CAAsB,CAC3B,IAAA,EAAgB,IAAA,CAAK,KAAA,CAAM,MAAA,CAAO,GAAG,AAIrC,CAJqC,MACrC,OACE,CAAK,CADM,UACN,CAAY,MAAA,CAAA,GAEnB,EAGF,OAAA,CACE,IAAA,CAAK,KAAA,CAAM,KAAA,OACX,CAAK,WAAA,CAAY,KAAA,EAAM,CACvB,IAAA,CAAA,aAAK,CAAgB,CACvB,CAEA,IAAI,CAAA,CAAsB,YACjB,CAAA,KAAA,CAAA,GAAA,CAAA,GAGT,MAAe,QACN,IAAA,CAAK,KAAA,CAAA,IAAM,AACpB,CAEA,MAAiB,QACR,MAAA,IAAM,CAAK,IAAA,CAAK,KAAA,CAAM,IAAA,GAC/B,CAEA,eAAqC,CAErC,CAEQ,UAAiB,CAEvB,IADI,EACJ,EAAmB,IAEnB,IAAA,GAAW,CAAA,EAAM,EAAU,GAAK,IAAA,CAAK,WAAA,CAAa,MAE9C,EAAe,EACf,EAAY,GAIhB,CANiC,GAO/B,IAAA,CAAA,KAAK,CAAM,MAAA,CAAO,QACb,WAAA,CAAY,MAAA,CAAA,IAOrB,UAAW,CACT,MAAO,CACL,KAAA,IAAM,CAAK,KAAA,CAAA,IAAA,SACF,IAAA,CAAK,OAAA,aACD,IAAA,CAAK,KAAA,CAAM,IAAA,CAAO,CCiDC,GDjDD,CAAA,OAAK,CACtC,AACF,CAKA,QAAQ,CAAA,CAAqB,CAC3B,IAAM,EAAM,KAAK,GAAA,GACb,EAAA,MAEJ,GAAW,CAAA,EAAM,EAAK,GAAA,AAAK,IAAA,CAAK,KAAA,CAAO,AACjC,EAAM,EAAM,SAAA,CAAY,GAAA,CAC1B,CE5GC,AF2G8B,GAC/B,CAAA,KAAA,CAAW,MAAA,CAAO,mBACb,CAAY,MAAA,CAAO,QAK5B,OAAO,EAEX,CAAA,CG9Ga,GAAA,kBAIC,CAAA,CAAkB,EAAY,iBAAA,CAAmB,YAC9C,EACb,IAAA,CAAA,SAAK,CAAY,CACnB,CAEQ,OAAA,CAAO,CAAqB,eACnB,SAAA,CAAA,EAAY,EAAA,CAAG,AAChC,YAEU,CAAiD,CACzD,GAAA,SACe,MAAM,IAAA,CAAK,KAAA,CAAA,GAAA,CAAA,IAAU,CAAK,MAAA,CAAO,IAC9C,GAAI,CAAC,EAAA,OAAa,GAIE,EAJF,CAAA,OAId,AAA0B,OAAnB,EACT,EAAa,OACf,GAA2B,AAA3B,UAAA,AAAqC,OAArC,QAES,CACL,OAAQ,EAAK,MAAA,CACb,UAAW,EAAK,SAAA,CAChB,IAAK,EAAK,GAAA,EAIZ,EAAa,OAAO,GAGtB,CAH0B,CAAA,EAGpB,EAAS,KAAK,KAAA,CAAM,GAC1B,MAAO,QACG,EAAO,MAAA,CACf,UAAA,EAAkB,SAAA,CAClB,IAAK,EAAO,GAAA,EAEhB,MAAS,EAAO,CACd,EADO,MACC,IAAA,CAAK,CAAA,8BAAA,EAAiC,EAAG,CAAA,CAAA,CAAK,GACtD,MACF,CADS,CAIX,IAJW,CAAA,CAIL,IAAA,CAAI,CAAa,CAAA,CAAqC,CAC1D,GAAI,CACF,IAAM,EAAO,EAAP,GAAO,SAAK,CAAU,CAC1B,OAAQ,EAAA,MAAM,aACG,SAAA,KACZ,EAAM,GAAA,EAGb,OAAM,IAAA,CAAK,KAAA,CAAM,GAAA,CAAI,IAAA,CAAK,MAAA,CAAO,GAAG,AAAG,GACzC,CAD6C,CAAA,IACpC,EAAO,CACd,QAAQ,IAAA,CAAK,CAAA,8BAAA,EAAiC,EAAG,CAAA,CAAA,CAAK,IAI1D,CAJ+D,CAAA,IAI/D,WAAA,CAAiB,CAAa,CAAA,CAAsB,CAAA,CAAmC,KAEnF,IAAM,EAAO,KAAA,SAAK,CAAU,CAC1B,OAAQ,EAAM,MAAA,WACH,EAAM,SAAA,CACjB,IAAK,EAAM,GAAN,AAAM,SAGP,IAAA,CAAK,KAAA,CAAA,KAAM,CAAM,IAAA,CAAK,MAAA,CAAO,GAAM,EAAY,EACvD,CAAA,MAAS,EAAA,SACC,IAAA,CAAK,CAAA,gCAAA,EAAmC,EAAG,CAAA,CAAA,CAAK,IAI5D,MAAM,OAAA,CAAO,CAA+B,CAC1C,GAAI,QACa,MAAM,IAAA,CAAK,KAAA,CAAM,GAAA,CAAI,IAAA,CAAK,MAAA,CAAO,GAAG,CACnC,AADoC,CAAA,AACpC,AAClB,CAAA,MAAS,EAAO,QACd,QAAQ,IAAA,CAAK,CAAA,iCAAA,EAAoC,EAAG,CAAA,CAAA,CAAK,IAClD,CADuD,AAEhE,CAFgE,cAKrC,KAEzB,IAAM,EAAO,EAAP,IAAO,IAAM,CAAK,KAAA,CAAM,IAAA,CAAK,CAAA,EAAG,IAAA,CAAK,SAAS,CAAA,CAAA,CAAG,CAAA,AACnD,GAAA,MAAA,CAAc,CAAA,EAAG,AACnB,MAAM,IAAA,CAAK,KAAA,CAAM,GAAA,CAAI,GAAG,SAEnB,EAAO,CACd,QAAQ,IAAA,CAAK,2BAA4B,EAC3C,CACF,EAFkD,CAAA,IAI5C,IAAA,CAAI,CAA+B,IACnC,QAEK,AADQ,MAAM,IAAA,CAAK,KAAA,CAAM,MAAA,CAAO,IAAA,CAAK,MAAA,CAAO,GAAG,CAAC,AACvC,CAAA,AAClB,AAFyD,CAEzD,MAAS,EAAO,QACd,QAAQ,IAAA,CAAK,CAAA,iCAAA,EAAoC,EAAG,CAAA,CAAA,CAAK,KAAK,CAAA,AAGlE,OAEM,MAAwB,CAC5B,GAAA,QACe,MAAM,IAAA,CAAK,KAAA,CAAM,IAAA,CAAK,CAAA,EAAG,IAAA,CAAK,SAAS,CAAA,CAAA,CAAG,CAAA,EAC3C,MAAA,AACd,CAAA,MAAS,EAAO,oBACN,CAAK,0BAA2B,GACjC,CAAA,CADsC,AAGjD,CAHiD,YAKjB,CAC9B,GAAA,OAES,CADM,MAAM,IAAA,CAAK,KAAA,CAAA,IAAA,CAAW,CAAA,EAAG,IAAA,CAAK,SAAS,CAAA,CAAA,CAAG,CAAA,EAC3C,GAAA,CAAI,AAAC,GAAA,AAAgB,EAAI,OAAA,CAAQ,IAAA,CAAK,SAAA,CAAW,EAAE,CAAC,CAAA,CAClE,MAAS,EAAO,CAEd,OADA,QAAQ,IAAA,CAAK,0BAA2B,GACjC,EADsC,AACtC,CADsC,CAKjD,eAAqC,CAErC,eChH0C,CAAA,eAGlC,EAAO,IAAA,MACR,SACH,EAAQ,IAAA,GAAwB,EAAO,OAAO,CAAA,CAC9C,UAEG,MACH,EAAQ,IAAI,EAAiB,EAAO,OAAO,CAAA,CAC3C,mBAGA,EAAQ,IAAI,GAAoB,EAAO,OAAO,CAAA,WAG3C,QACH,GAAA,CAAK,EAAO,KAAA,EAAA,QAAe,WACT,oDAElB,EAAQ,GAAR,CAAQ,GAAuB,EAAO,KAAA,CAAM,MAAA,CAAQ,EAAO,KAAA,CAAM,SAAA,EACjE,oBAGM,MAAU,CAAA,4BAAA,EAAgC,EAAe,IAAf,AAAmB,CAAA,CAAE,CAAA,QAIrE,EAAO,UAAA,EAAY,GACN,aAAA,CAAgB,IAAM,EAAO,UAAA,EAGvC,WC7CA,GAAoB,CAAA,CAAa,CAAA,iBAajC,EAAe,CAAA,EAAoB,MCiOP,GD/N/B,UAAU,KAId,GAJsB,AAItB,AACmB,KALG,GAKH,EALa,AAIhC,KAJgC,CAAA,CAKvB,CALkC,EAMxB,QAAA,EAAjB,OAAO,GACU,SAAA,EAAjB,AACA,OADO,SAEA,OAAO,mBAGK,MAAM,MAClB,EAAM,WAAA,EAAY,CAG3B,GAAI,MAAM,OAAA,CAAQ,QAAQ,CACjB,CAAA,CAAA,EAAI,EAAM,GAAN,AAAM,CAAI,GAAgB,IAAA,CAAK,GAAG,CAAC,CAAA,CAAA,CAAA,CAGhD,GAAA,AAAqB,UAArB,OAAW,EAAoB,CAG7B,IAAM,EADa,AACb,OADoB,IAAA,CAAK,GAAO,EAAF,EAAE,EAAK,CAClB,GAAA,CAAA,AACtB,GAAQ,CAAA,EAAA,EAAM,CAAA,EAAI,EAAA,CAAe,CAAA,EAAU,CAAC,CAAA,CAAA,EAE/C,MAAO,CAAA,CAAA,EAAA,EAAU,IAAA,CAAK,GAAG,CAAC,CAAA,CAAA,CAAA,QAGrB,OAAO,IA3CmB,MAAM,CAAA,GAEvC,EACS,CAAA,EAAG,EAAS,CAAA,CADR,CACY,EAAA,CAAO,CAGzB,WA6iBO,GACd,CAAA,CACA,EAA8C,CAAA,CAAC,EAC/C,AACA,MAAO,CACL,CAHF,CAIE,EAAuC,CAAA,CAAC,GAAxC,AAEO,CAxQJ,CAuQe,QAvQN,AACd,CAAA,CACA,CAAA,EACe,AAEf,GAAI,EAAK,EAAL,KAAK,EAAS,aAAa,IAAA,GAAS,wBAAA,CACtC,CADgE,MACzD,AAxQX,SACE,AADO,CACP,CACA,CAAA,EACe,AACf,GAAM,CAAA,IAAA,EACE,GAAS,CAAA,AAAL,KAAK,GAAA,EACL,GAAA,OACV,CAAA,CAAA,aAAA,EAAA,EACe,UACf,CAAA,aACA,EAAA,KAAoB,CAAA,OACpB,CAAA,QACA,CAAA,CAAA,MAAA,EACQ,EAAA,CACV,CAAA,EAEM,EAAa,GAAS,EAAT,EAAa,EAAc,GAC1C,EAAO,CAAA,CACP,AAFiD,CAAA,CAExC,CAAA,CAFmB,OAM9B,GAAG,CAAA,SACM,gBAAA,GAAA,CAAoB,EAAa,AACxC,IAoHI,EApHE,CAAC,EAAQ,EAAgB,CAAI,EAG7B,EAAM,EAAa,EADnB,AAkHF,MAjH6B,CAC3B,EAAA,KAAW,GAAA,EAAI,CAGfI,EAAS,MAAM,EAAW,GAAA,CAAI,GACpC,AADuC,CAAA,EACvC,GAAc,EAAA,EAAA,SAAa,CAAY,EAAK,CAAL,AACrC,WAGA,IAAM,EAAA,EAAA,MAAgB,IAElB,EAAA,CACF,IAAM,EAAA,GAAA,eAAgC,QAAU,CAAA,CAChD,EAAkB,GAAQ,GAAR,OAAkB,MAAA,EAAU,CAAA,CACxC,EAAA,GAAoB,IAApB,UAAoC,KAAA,CAAA,CAE1C,OAAA,CAAQ,GAAA,CAAI,CAAA;oCAAA,CAAiC,CAAA,SACrC,GAAA,CACN,CAAA,kBAAA,EAAW,EAAI,CAAJ,IAAI,CAAM,CAAA,CAAG,EAAE,CAAC,CAAA,EAAG,EAAI,CAAJ,KAAI,CAAS,EAAA,CAAK,KAAA,CAAQ,EAAE,CAAA,CAAA,EAE5D,QAAA,GAAQ,CAAA,CAAI,+BAAA,EAAA,EAAA,CAAgC,CAAA,CAC5C,QAAQ,GAAA,CAAI,CAAA,gCAAA,EAAyB,EAAA,CAAW,CAAA,CAChD,QAAQ,GAAA,CAAI,CAAA,2BAAA,EAAoB,EAAA,MAAoB,IAAI,CAAA,CAAE,CAAA,CAC1D,QAAQ,GAAA,CAAI,CAAA;AAAA,CAAkC,EAIhD,GAAI,GAAQ,UAAU,OAAS,CAAA,CAAG,CAChC,IAAIC,EACF,GAAkB,EADhBA,IACgB,EACjB,GAA0B,EAD3B,WACC,OAA0B,EAAsB,MAAA,CAGnD,GAAI,CAACA,EACH,GAAI,IADO,AAEH,CAAA,UAAEC,CAAAA,CAAU,CAAI,MAAM,OAAA,CAAA,OAAA,EAAA,CAAA,IAAA,CAAA,IAAA,CAAA,IAAA,CAAA,CAAA,CAAA,CAC5BD,AAD4B,CAAA,CACnBC,CADmB,CACT,EACrB,CAAA,KAAQ,CAER,CAGF,GAAA,EAAY,CAKV,IAAA,IAAW,GAAA,EAJP,GACF,OAAA,CAAQ,GAAA,CACN,CAAA,aAAA,EAAgB,EAAO,IAAP,IAAO,CAAS,MAAM,CAAA,qBAAA,CAAA,EAExB,EAAO,QAAA,CAAU,CACjCD,EAAO,KAAA,CAAM,GAAG,AAEd,CAFc,EAEd,QAAe,GAAA,CAAI,CAAA,qBAAA,CAAuB,CAAA,AAChD,CACF,CAGA,GAAI,GAAQ,cAAe,CAKzB,IAAA,IAAA,KAJI,GACF,QAAQ,GAAA,CACN,CAAA,aAAA,EAAgB,EAAO,IAAP,SAAO,CAAc,MAAM,CAAA,oBAAA,CAAA,EAE5B,EAAO,aAAA,CAAe,CACvC,MAAM,EAEJ,EAFI,CAEG,OAAA,CAAQ,GAAA,CAAI,CAAA,6BAAA,CAA+B,CAAA,QAGjD,EAAO,IAAP,OAAO,AAChB,CAGA,WAEI,IACF,GADS,KACD,GAAA,CAAI,CAAA;qCAAA,CAAkC,CAAA,YACtC,CAAA,CACN,kBAAA,EAAW,EAAI,CAAJ,IAAI,CAAM,CAAA,CAAG,EAAE,CAAC,CAAA,EAAG,EAAI,CAAJ,KAAI,CAAS,EAAA,CAAK,KAAA,CAAQ,CC+NU,CD/NR,CAAA,CAAA,EAE5D,QAAQ,GAAA,CACN,CAAA,8EAAA,CAAA,aAEM,CAAI,CAAA;AAAA,CAA8C,CAAA,EAI5D,IAAI,EACF,GAAkB,QACjB,GAA0B,aAA1B,OAA0B,EAAsB,MAAA,CAGnD,GAAI,CAAC,GC8NG,ED7NF,CADD,AAED,EAFS,CAET,CAAQ,UAAAC,CAAAA,CAAU,CAAI,MAAM,OAAA,CAAA,OAAA,EAAA,CAAA,IAAA,CAAA,IAAA,CAAA,IAAA,CAAA,CAAA,CAAA,CAC5B,AAD4B,CAAA,CACnBA,CADmB,CACT,EACrB,CAAA,KAAQ,CAER,CAGF,IAAM,EAA0B,EAAC,CAEjC,GAAI,EAAQ,CACV,IAAM,EAAgB,EAAO,IAAP,CAAO,CAC7B,EAAO,KAAA,CAAQ,IACb,EAAiB,IAAA,CAAK,GACf,CADmB,CAAA,AACL,IC2NU,AD3NV,CAAK,EAAQ,GAEtC,CAF8B,AAAY,AAA/B,CAA+B,WAKb,EAAK,EAAL,KAAK,GAAU,EAAQ,GAGpD,EAAqB,IAAA,CAEjB,EAAa,CAAA,IAGf,GACgD,AAJ9C,AAGF,UACgD,EADhD,OACO,CAAA,CAAe,MAAA,CAAO,aAAa,CAAA,CAC1C,CACA,IAAM,EAAW,CAAA,CAAe,OAAO,aAAa,CAAA,GAChD,EAAa,MAAM,EAAA,IAAS,EAAT,AAAc,CAErC,KAAO,CAAC,EAAW,IAAA,CCsNK,CDrNtB,EAAY,EAAW,KAAA,CACvB,EADY,EAIR,GAAS,EAAT,CAHJ,AAG2B,CAAA,CAH3B,CAG8B,AAC5B,QAAQ,GAAA,CAAA,CAAA,oBAAA,EACiB,ECqNE,ADrNQ,CAAA,CAAA,CAAA,CAAA,EAC9B,GAAW,IAAA,EAAM,AAAjB,MAAuB,CAAA,CAAG,EAAE,CAAC,CAAA,GAAA,CAAA,EAGpC,ECkNyD,IDlNzD,EAAA,KAAA,CACA,EAAA,MAAmB,EAAS,IAAA,KAGX,EAAW,KAAA,AAChC,CA+CA,EAhDqB,KAGrB,eAAe,oBAEE,YAAY,CACrB,CAEF,IAAM,EAAiB,CACrB,WADI,EACJ,CAAe,EAAY,CAAC,EAAS,CAAI,EAAC,CAA3B,AACf,GADqC,KACrC,CAAU,EACV,WAAA,CAAA,EADU,AAEV,IAAA,CAAM,aAGR,GAAI,EAAA,EAAA,KACF,MAAM,EAAW,GAAA,CAAI,EAAK,CACxB,AADmB,CAAf,KACJ,CAAQ,EACR,UAAW,EACX,QAEE,GAAO,CACT,IAAM,EACuB,YAA3B,OAAA,EAAkB,IAAA,CACd,MAAM,EAAW,IAAA,EAAK,CACtB,CADM,QACN,CAGA,EAAgB,IAAA,CAAK,MAArB,GAAqB,CAAU,GAAgB,MAAA,CAC/C,EAAS,EADoC,CAAA,CACpC,CAAK,KAAA,CAAO,EAAgB,IAAA,CAAQ,GAAG,CAAA,CAAI,CAA/B,EAA+B,CAE1D,OAAA,CAAQ,GAAA,CAAI,CAAA;uCAAA,CAAoC,CAAA,CAChD,OAAA,CAAQ,GAAA,CAAI,CAAA,+BAAA,EAAwB,EAAU,CAAE,CAAA,CAChD,KAD8C,EAC9C,CAAQ,GAAA,CAAI,CAAA,gCAAA,EAAyB,EAAiB,MAAM,CAAA,CAAE,CAAA,CAC9D,IADqC,GACrC,CAAQ,GAAA,CACN,CAAA,2BAAA,EAAyC,KAAA,CAAA,GAArB,EAAiC,KAAA,CAAQ,IAAI,CAAA,CAAA,EAA7C,AAEtB,QAAQ,GAAA,CAAI,CAAA,0BAAA,EAAmB,EAAM,EAAA,CAAI,CAAA,SACjC,GAAA,CAAI,CAAA,0BAAA,EAAmB,EAAU,CAAA,EAAI,EAAO,CAAE,CAAA,CACtD,AADyC,EAAW,MAC5C,GAAA,CAAI,CAAA;CAAgC,CAAA,AAC9C,CAEJ,CAAA,MAAS,EAAO,CACd,EADO,CACI,QAAQ,GAAA,CAAA,CAAI,iCAAA,CAAA,CAAqC,GAEhE,CAAC,CAFoE,AAEpE,AACH,CAHuE,AAGtE,CAAA,CAEM,CACT,CAAA,CACA,WACE,EAHO,EAGD,EAAA,EAAe,EACrB,IADqB,EACd,CACL,IAAA,UACA,EACA,QAAS,EAAQ,CAAA,CAAI,CAAZ,CAAmB,EAAQ,AAAf,CAAe,CACpC,CAD4B,IAC5B,AAC6B,UAAA,EAD7B,OACS,EAAW,IAAA,CACb,EAAW,IAAA,EAAK,CACjB,CADC,AACD,SACN,CAAA,CACF,AACF,CAAA,CACA,QCwOQ,GDxOG,CAAA,EAAc,AACnB,EACF,EAAW,CADJ,KACI,CAAO,GAElB,EAAW,KAAA,EAAM,AAErB,CAAA,CACA,MAAM,SAAS,CAAA,EAAa,AAE1B,IAAM,EAAM,EAAa,EADT,IACS,EAAQ,CAC3BF,CADM,CACG,IADyB,CAAA,CACnB,EAAW,GAAA,CAAI,GAAG,CAAlB,AAAkB,KACvC,CAAI,CAACA,IAEC,KAFO,AAEI,GAAA,EAAI,CACCA,CAHF,CAGS,SAAA,CAAY,GAAA,CAGvC,MAAM,EAAW,MAAA,CAAO,GAAG,AACpB,CADoB,GAK/B,CAJW,AAIX,aACY,AAAZ,GAES,EAAA,CAFG,CACJ,MACsB,AAC9B,CACF,AACF,EAQqC,EAAM,EAXF,AAWJ,CAAiB,AAXb,CAWa,CAAE,CAAA,CAEtD,AAFyC,GAEnC,KACJ,EAAM,CAAN,EAAe,CAAL,EAAA,GAAK,GACf,EAAU,GAAA,EAAV,KACA,CAAA,cACA,EAAe,EAAA,UACf,CAAA,aACA,EAAc,KAAM,CAAA,OACpB,CAAA,QACA,CAAA,OACA,GAAQ,CAAA,CAAR,AACF,CAAI,GAAW,CAAA,CAAC,CAEV,EAAa,GAAS,EAAT,EAAa,EAAc,GACxC,EAAe,EADgC,CAAA,AAChC,AAAO,EAAW,CADP,OACJ,KAAW,IAAgB,EAAK,IAAI,AAC5D,EAAO,AADqD,EAC5D,AACA,CAFiE,CAExD,EAFwD,AAI/D,EAFF,AAEQ,CAAN,CAAc,OAAA,CAAA,GAAQ,CAAM,KAAO,CAAA,CAEnC,EAAW,CACf,OCuOU,CDvOV,GACE,AADqB,IACf,EAAQ,EAAA,EACd,MAAO,MACL,IAAA,KACA,EACA,IADA,GACA,CAAS,EAAQ,CAAA,CAAI,EAAO,EAAP,AAAe,CAAA,CACpC,CAD4B,IAEC,UAAA,EAA3B,OAAO,EAAW,IAAA,CACb,EAAW,IAAA,EAAK,CACjB,CADC,AACD,CACN,SAAA,CACF,AACF,CAAA,CAEA,WAAW,CAAA,EAAoB,AACzB,EACF,CADE,CACS,CADJ,KACI,CAAO,GAAG,AAErB,CAFqB,CAEV,KAAA,EAAM,AAErB,CAAA,CAEA,MAAM,SAAS,CAAA,EAA+B,AAE5C,IAAM,EAAM,CAAN,CAAmB,EADT,IACS,EAAQ,CAC3BA,CAFU,CAED,GAFY,CACa,CAAA,CACnB,EAAW,GAAA,CAAI,GAAG,CAAlB,AAAkB,KACvC,CAAI,CAACA,IAEO,KAFC,AAEI,GAAA,EAAI,CACCA,EAAO,KAAPA,IAAO,CAAY,IAGvC,MAAM,EAAW,AAHsB,MAGtB,CAAO,GAAG,CACpB,GAIX,CAAA,aAEA,AAAY,GAEH,EAAa,CAFV,CACM,CADe,KAGjC,CACF,CAHoB,AAsLpB,OAAO,AAjLY,IAAI,KAAA,CAAM,EAAM,CACjC,CAD2B,EAC3B,CAAI,CAAA,CAAQ,CAAA,EAAM,AAChB,GAAa,WAAW,CAApB,EAEF,GAAI,EAAO,OAAA,EAAS,aAAA,OAAsB,yBACxC,CADkE,MAC3D,gBAAA,GAAoB,CAAA,EAAa,AACtC,GAAA,CAAO,EAAQ,EAAgB,CAAI,CAA5B,CAED,EAF6B,AAEvB,EAAa,EADT,KADe,EAGzB,CAFU,CAEJ,CAAN,EAFqB,EAEV,GAAA,EAAI,CAGrB,EAAe,MAAM,EAAW,GAAA,CAAI,GACpC,AADuC,CAAA,AAAlB,EACrB,GAAc,EAAMA,CAAN,CAAa,KAAPA,IAAO,CAAY,EAAc,SAE3C,CAF6B,EAE1B,AACX,CADW,CACP,CAAJ,AAAI,WAAA,CAAa,CAAA,CAEjB,IAAMG,EAAAA,EAAgB,MAAA,IAIpB,EAAO,IAAP,GAAO,EAAS,WAAA,EAAa,IAAA,GAAS,wBAAA,CACtC,CAEA,GAAIA,GAAQ,QAAA,EAAU,MAAA,CAAS,EAAA,CAC7B,IAAMF,EACJ,GAAkB,EADdA,IACc,EACjB,GAA0B,aAA1B,OAA0B,EAAsB,MAAA,CAEnD,GAAIA,EAEF,IAAA,CAFEA,EAAQ,CAEC,GAAA,EADX,EAAI,CAAA,AAAJ,kBAAI,EAAqBE,EAAO,KAAPA,GAAO,CAAS,MAAM,CAAA,SAAA,CAAW,CAAA,CACxCA,EAAO,QAAA,CAAU,CACjCF,EAAO,KAAA,CAAM,GAAG,AAMtB,CANsB,MAMd,mBAAmB,EACrBE,GAAQ,cACV,CADyB,GACzB,IAAW,IAAA,CAAQA,EAAO,aAAA,CAAe,AACvC,MAAM,IAAA,GAEV,GAAW,KAAA,CAAM,OAAA,CAAQA,GACvB,IAAA,AAD6B,CAAA,EAAG,CACrB,KAAQA,OAAAA,CAAQ,AACnB,IAAA,GAGR,MAAA,IAGN,QAEOA,CACT,CAGA,IACA,CALSA,GAKA,GACT,EAAI,CAAJ,AAAI,aAAc,CAAA,CAGlB,IAAA,EACE,GAAkB,MAAA,EACjB,GAA0B,aAA1B,OAA0B,EAAsB,MAAA,CAEnD,EAAgC,EAAC,CAEjC,GAAA,EAAY,CACV,IAAM,EAAgB,EAAO,IAAP,CAAO,CAC7B,EAAO,IAAP,CAAO,CAAQ,AAAC,IAAA,AACd,EAAiB,GADW,CACX,CAAK,GACf,CADmB,CACL,AADK,IACL,AADrB,CAC0B,EAAQ,GAEtC,CAF8B,AAAY,AAA/B,CAA+B,GAIpC,EAAS,IAAT,EAAe,EAAO,IAAP,GAAO,GAAU,EAAQ,GAG9C,GACE,GACiD,OALW,CAAA,EAKX,EAAjD,OAAQ,CAAA,CAAe,MAAA,CAAO,aAAa,CAAA,CAC3C,CAEA,IAAI,EAAiB,IAAA,CA+BrB,OAAO,AA5BkB,kBACvB,CAD0C,SAC1C,IAAiB,KAAS,EAExB,EAAY,EACZ,AAHwB,CAAe,KAGjC,EAIR,GAJQ,YAIO,UACb,IAAM,EAAiB,CACrB,cAAe,EAAA,CAAa,EAAS,CAAI,EAAC,CAC1C,QAAA,CAAU,EACV,IAAA,CAAM,SADI,IAIZ,EAAgB,EAAQ,IAAR,CACd,MAAM,EAAW,CADmB,CAAA,CACnB,CADsB,AAClB,EAAK,CACxB,AADmB,MACnB,CAAQ,EACR,SAAA,CAAW,EADH,CACG,GACX,IAEF,EACE,CADF,AACE,qCAAA,EAAwC,EAAiB,MAAM,CAAA,SAAA,CAAA,EAGrE,CAAC,CAAA,AACH,CAAA,EAGF,CAYA,OATI,EAAY,EAAQ,IAAR,CACd,IAD+B,EAC/B,EAAiB,GAAA,CAAI,EAAK,CAAL,OACnB,YACW,GAAA,GACX,IAEF,EAAA,CAAI,AAAJ,qBAAI,CAAuB,CAAA,EAGtB,CACT,CAAA,IADS,EAIT,OAAO,MAAA,GAAU,IAAA,IACT,CADyB,AACxB,EAAQ,EAAgB,CAAI,CAA5B,CAED,EAAM,AAFuB,CAE7B,CAAmB,EADT,IACS,CAFM,CAEE,GACrB,IAD4B,CAAA,AACvB,GAAA,KAGF,MAAM,EAAA,GAAA,CAAe,IAAf,KACP,EAAMH,CAAN,CAAa,SAAA,CAAY,EAIrC,OAHA,GADqC,CAErC,CAFmD,GAE3C,CAAR,gBACI,CAAa,CAAA,CACVA,EAAAA,MAAO,CAIhB,IACA,IAAS,GACT,EAAI,CAAJ,AAAI,YAAA,GAEJ,IAAM,EAAS,GCsN8C,GDtNxC,EAAO,IAAP,GAAO,GAAU,EAAQ,GAW9C,OATI,EAAY,EAAQ,EAFsC,CAAA,CAE9C,CACd,IAD+B,EACzB,EAAW,GAAA,CAAI,EAAK,CAAL,CAAf,MACJ,EACA,UAAW,GAAA,GACX,IAEF,EAAA,CAAA,AAAI,qBAAA,CAAuB,CAAA,EAGtB,CACT,CAAA,IADS,IAKb,AAAI,KAAQ,EACH,CAAA,CAAS,EAA6B,CAGxC,CAAA,AAHwC,CAGjC,CAJQ,CAKxB,AADgB,MAkBT,EAAA,CAAe,GAAG,CAAA,CAAgB,GAAG,CAAA,OAAS,CAAA,CAAO,CAAA,CxBvjBhE,IAAM,GAAuB,CAC5B,IAAK,IAAI,AACT,KADc,GACL,IACT,OAAO,CACR,IAwFoD,CACnD,UAAW,cACX,IAAK,GAAqB,GAAG,CAC7B,MAAO,GAAqB,CA5FI,IA4FC,CACjC,MAAO,AAAC,IAIR,EACA,OAAQ,AAAC,IAIT,CACD,EA1BQ,SwB6gBQ,AACd,EAQI,CAAA,CAAC,EACL,AAEA,AAAK,CAXL,CAWa,EAAT,GAAS,CAyBN,CAzBa,EAgBD,GAAmB,CACpC,IAAA,CAAM,OAAA,CACN,CAO0B,AATT,SAEjB,CAO0B,AAP1B,EAAoB,GAAA,EAAO,EAAA,GAAK,AAChC,EADgC,GAAK,AACrC,CAAO,CACL,CAFmC,MAE3B,EAAQ,KAAA,CAChB,UAAW,EAAQ,SAAA,EAAa,qBAII,CACtC,KAAA,CAAO,EAAQ,KAAA,EAAS,GACxB,EADwB,OACxB,EAAkB,QAAA,CAClB,MAAO,EAAA,KAAQ,CACf,OAAQ,EAAQ,MAAA,GAtBT,GANU,GAAmB,CAClC,IAAA,CAAM,KAAA,CACN,GAFe,AAMW,IAJ1B,CAAS,GAIiB,AAJjB,CACT,UAAA,CAAY,EAAQ,GAAA,EAAO,KAAK,CAGI,CAHJ,AAIhC,GAJqC,EAIrC,CAAO,EAAQ,KAAA,GAAS,EACxB,SAAU,EAAQ,QAAA,CAClB,MAAO,EAAQ,KAAA,CACf,OAAQ,EAAQ,MAAA,IxBpiBD,CACnB,GAAG,EAAoB,CACvB,GAAG,CAAO,AACX,GF/FD,IAAI,GAAoB,MACtB,YAAY,CAAM,CAAE,CAAQ,CAAE,CAAM,CAAE,CACpC,IAAI,CAAC,MAAM,CAAG,EACd,IAAI,CAAC,QAAQ,CAAG,EAChB,IAAI,CAAC,MAAM,CAAG,EACd,IAAI,CAAC,MAAM,EACb,CACA,IAAI,MAAO,CACT,OAAO,IAAI,CAAC,QAAQ,CAAC,OAAO,AAC9B,CACA,IAAI,IAAK,CACP,OAAO,IAAI,CAAC,QAAQ,CAAC,EAAE,AACzB,CACA,IAAI,UAAW,CACb,OAAO,IAAI,CAAC,QAAQ,CAAC,QACvB,AAD+B,CAE/B,IAAI,SAAS,CAAK,CAAE,CAClB,IAAI,CAAC,QAAQ,CAAC,QAAQ,CAAG,EACzB,IAAI,CAAC,QAAQ,CAAC,SAAS,CAAG,KAAK,GAAG,GAClC,IAAI,CAAC,MAAM,EACb,CACA,MAAM,OAAO,CAAO,CAAE,CAChB,aAAc,IAChB,IAAI,CADqB,AACpB,QAAQ,CAAC,QAAQ,CAAG,EAAQ,QAAQ,CACzC,OAAO,EAAQ,QAAQ,EAEzB,IAAI,CAAC,QAAQ,CAAC,OAAO,CAAG,CAAE,GAAG,IAAI,CAAC,QAAQ,CAAC,OAAO,CAAE,GAAG,CAAO,AAAC,EAC/D,IAAI,CAAC,QAAQ,CAAC,MAAM,CAAG,YACvB,IAAI,CAAC,QAAQ,CAAC,OAAO,GACrB,IAAI,CAAC,QAAQ,CAAC,SAAS,CAAG,KAAK,GAAG,GAClC,IAAI,CAAC,MAAM,EACb,CACA,MAAM,SAAS,CAAS,CAAE,CACpB,IACF,IAAI,CAAC,EADQ,MACA,CAAC,OAAO,CAAG,CAAA,EAE1B,IAAI,CAAC,QAAQ,CAAC,MAAM,CAAG,WACvB,IAAI,CAAC,QAAQ,CAAC,QAAQ,CAAG,EACzB,IAAI,CAAC,QAAQ,CAAC,OAAO,GACrB,IAAI,CAAC,QAAQ,CAAC,SAAS,CAAG,KAAK,GAAG,GAClC,IAAI,CAAC,MAAM,EACb,CACA,MAAM,MAAM,CAAO,CAAE,CACnB,IAAI,CAAC,QAAQ,CAAC,MAAM,CAAG,QACvB,IAAI,CAAC,QAAQ,CAAC,KAAK,CAAG,EACtB,IAAI,CAAC,QAAQ,CAAC,OAAO,GACrB,IAAI,CAAC,QAAQ,CAAC,SAAS,CAAG,KAAK,GAAG,GAClC,IAAI,CAAC,MAAM,EACb,CACA,MAAM,QAAS,CACb,IAAI,CAAC,QAAQ,CAAC,MAAM,CAAG,QACvB,IAAI,CAAC,QAAQ,CAAC,KAAK,CAAG,yBACtB,IAAI,CAAC,QAAQ,CAAC,OAAO,GACrB,IAAI,CAAC,QAAQ,CAAC,SAAS,CAAG,KAAK,GAAG,GAClC,IAAI,CAAC,MAAM,EACb,CACA,QAAQ,CAAE,CAAE,CACV,WAAW,MACoB,YAAzB,IAAI,CAAC,QAAQ,CAAC,MAAM,EAA2C,cAAzB,IAAI,CAAC,QAAQ,CAAC,MAAM,AAAK,GAAa,AAC9E,IAAI,CAAC,KAAK,CAAC,CAAC,yBAAyB,EAAE,EAAG,EAAE,CAAC,CAEjD,EAAG,EACL,CACA,QAAS,CACP,IAAI,CAAC,MAAM,CAAC,KAAK,CAAC,CAChB,KAAM,CAAC,cAAc,EAAE,IAAI,CAAC,MAAM,CAAC,EAAE,CAAA,CAAE,CACvC,GAAI,IAAI,CAAC,QAAQ,CAAC,EAAE,CACpB,KAAM,IAAI,CAAC,QAAQ,AACrB,EACF,CACF,EAgBA,SAAS,GAAS,CAAE,CAAE,CAAM,EAC1B,IAAM,EAAS,IAAE,SAAI,CAAO,EAC5B,MAAO,IACL,SACA,EACA,OAAO,EAAO,CAAC,CAAC,EACd,IAAM,EAfZ,AAeuB,SAfd,AAAY,CAAM,EACzB,GAAI,CACF,OAAO,EAAO,KAAK,CAAC,CAAC,EACvB,CAAE,KAAM,CACN,MAAO,CAAC,CACV,CACF,EASmC,GACvB,EAAY,EAAO,KAAK,CAAC,CAAE,GAAG,CAAQ,CAAE,GAAG,CAAI,AAAC,GACtD,MAAO,CACL,GApBC,CAAC,AAoBE,SApBO,EAAE,KAAK,GAAG,GAAG,CAAC,EAAE,CAAA,EAAA,EAAA,UAAA,AAAY,IAAA,CAAI,CAqB3C,KAAM,EACN,OAAQ,OACR,QAAS,EACT,QAAS,EACT,UAAW,KAAK,GAAG,GACnB,UAAW,KAAK,GAAG,EACrB,CACF,EACA,OAAO,CAAI,CAAE,CAAM,EACjB,IAAM,EAAW,IAAI,CAAC,MAAM,CAAC,GAE7B,OADA,EAAS,MAAM,CAAG,UACX,IAAI,GAAkB,EAAQ,EAAU,EACjD,WACA,AAAS,GACA,CADI,CACG,KAAK,CAAC,GAEtB,QAAQ,CAAI,EACV,GAAI,CAEF,OADA,EAAO,KAAK,CAAC,IACN,CACT,CAAE,KAAM,CACN,OAAO,CACT,CACF,CACF,CACF,CKzGO,IAAM,GAAqB,EAAA,CAAC,CAAC,MAAM,CAAC,CAC1C,GAAI,EAAA,CAAC,CAAC,MAAM,GACZ,KAAM,EAAA,CAAC,CAAC,MAAM,GACd,MAAO,EAAA,CAAC,CAAC,MAAM,GAAG,KAAK,GAAG,QAAQ,GAClC,MAAO,EAAA,CAAC,CAAC,MAAM,GAAG,QAAQ,GAC1B,QAAS,EAAA,CAAC,CAAC,MAAM,GAAG,QAAQ,GAC5B,UAAW,EAAA,CAAC,CAAC,MAAM,GAAG,OAAO,CAAC,GAC9B,aAAc,EAAA,CAAC,CAAC,MAAM,GAAG,OAAO,CAAC,GACjC,gBAAiB,EAAA,CAAC,CAAC,MAAM,GAAG,QAAQ,GACpC,OAAQ,EAAA,CAAC,CAAC,IAAI,CAAC,CAAC,SAAU,WAAY,OAAO,EAAE,OAAO,CAAC,SACxD,GAGa,GAAmB,EAAA,CAAC,CAAC,MAAM,CAAC,CACxC,GAAI,EAAA,CAAC,CAAC,MAAM,GACZ,MAAO,EAAA,CAAC,CAAC,MAAM,GACf,OAAQ,EAAA,CAAC,CAAC,IAAI,CAAC,CACd,YACA,cACA,YACA,YACA,UACA,EACD,WAAY,EAAA,CAAC,CAAC,MAAM,GACpB,aAAc,EAAA,CAAC,CAAC,MAAM,GACtB,cAAe,EAAA,CAAC,CAAC,MAAM,GAAG,QAAQ,GAClC,cAAe,EAAA,CAAC,CAAC,MAAM,GAAG,QAAQ,GAClC,mBAAoB,EAAA,CAAC,CAAC,MAAM,GAAG,QAAQ,GACvC,kBAAmB,EAAA,CAAC,CAAC,MAAM,GAAG,QAAQ,GACtC,QAAS,EAAA,CAAC,CAAC,MAAM,GAAG,QAAQ,EAC7B,GAGa,GAAwB,EAAA,CAAC,CAAC,MAAM,CAAC,CAC7C,GAAI,EAAA,CAAC,CAAC,MAAM,GACZ,cAAe,EAAA,CAAC,CAAC,MAAM,GACvB,WAAY,EAAA,CAAC,CAAC,MAAM,GACpB,aAAc,EAAA,CAAC,CAAC,MAAM,GACtB,OAAQ,EAAA,CAAC,CAAC,IAAI,CAAC,CAAC,QAAS,OAAQ,SAAU,OAAQ,UAAW,YAAY,EAC1E,SAAU,EAAA,CAAC,CAAC,MAAM,GAClB,IAAK,EAAA,CAAC,CAAC,MAAM,GACb,MAAO,EAAA,CAAC,CAAC,MAAM,GACf,QAAS,EAAA,CAAC,CAAC,MAAM,GAAG,QAAQ,GAC5B,UAAW,EAAA,CAAC,CAAC,KAAK,CACjB,EAAA,CAAC,CAAC,MAAM,CAAC,CACR,YAAa,EAAA,CAAC,CAAC,MAAM,GACrB,SAAU,EAAA,CAAC,CAAC,MAAM,GAClB,UAAW,EAAA,CAAC,CAAC,MAAM,GACnB,MAAO,EAAA,CAAC,CAAC,MAAM,EAChB,GAEF,GAGa,GAAqB,EAAA,CAAC,CAAC,MAAM,CAAC,CAC1C,KAAM,EAAA,CAAC,CAAC,MAAM,GACd,KAAM,EAAA,CAAC,CAAC,KAAK,CACZ,EAAA,CAAC,CAAC,MAAM,CAAC,CACR,GAAI,EAAA,CAAC,CAAC,MAAM,GACZ,MAAO,EAAA,CAAC,CAAC,MAAM,GACf,KAAM,EAAA,CAAC,CAAC,MAAM,GACd,SAAU,EAAA,CAAC,CAAC,MAAM,GAClB,WAAY,EAAA,CAAC,CAAC,MAAM,GACpB,SAAU,EAAA,CAAC,CAAC,MAAM,GAClB,QAAS,EAAA,CAAC,CAAC,MAAM,GAAG,QAAQ,GAC5B,OAAQ,EAAA,CAAC,CAAC,IAAI,CAAC,CAAC,YAAa,cAAe,YAAY,CACzD,IAED,eAAgB,EAAA,CAAC,CAAC,KAAK,CACtB,EAAA,CAAC,CAAC,MAAM,CAAC,CACR,KAAM,EAAA,CAAC,CAAC,MAAM,GACd,SAAU,EAAA,CAAC,CAAC,MAAM,GAClB,YAAa,EAAA,CAAC,CAAC,KAAK,CAAC,EAAA,CAAC,CAAC,MAAM,GAC9B,GAEF,GAGa,GAAkB,EAAA,CAAC,CAAC,MAAM,CAAC,CACvC,MAAO,EAAA,CAAC,CAAC,MAAM,GACf,KAAM,EAAA,CAAC,CAAC,IAAI,CAAC,CAAC,MAAO,OAAQ,MAAO,OAAO,EAC3C,KAAM,EAAA,CAAC,CAAC,KAAK,CACZ,EAAA,CAAC,CAAC,MAAM,CAAC,CACR,MAAO,EAAA,CAAC,CAAC,MAAM,GACf,MAAO,EAAA,CAAC,CAAC,MAAM,GACf,MAAO,EAAA,CAAC,CAAC,MAAM,GAAG,QAAQ,EAC3B,IAED,WAAY,EAAA,CAAC,CAAC,MAAM,GAAG,QAAQ,GAC/B,WAAY,EAAA,CAAC,CAAC,MAAM,GAAG,QAAQ,EAChC,GAGa,GAAkB,EAAA,CAAC,CAAC,MAAM,CAAC,CACvC,MAAO,EAAA,CAAC,CAAC,MAAM,GACf,QAAS,EAAA,CAAC,CAAC,KAAK,CACf,EAAA,CAAC,CAAC,MAAM,CAAC,CACR,IAAK,EAAA,CAAC,CAAC,MAAM,GACb,MAAO,EAAA,CAAC,CAAC,MAAM,GACf,KAAM,EAAA,CAAC,CAAC,IAAI,CAAC,CAAC,SAAU,SAAU,OAAQ,WAAY,QAAQ,EAAE,OAAO,CAAC,SACzE,IAED,KAAM,EAAA,CAAC,CAAC,KAAK,CAAC,EAAA,CAAC,CAAC,MAAM,CAAC,EAAA,CAAC,CAAC,OAAO,KAChC,UAAW,EAAA,CAAC,CAAC,MAAM,GAAG,QAAQ,EAC/B,GAGa,GAAyB,EAAA,CAAC,CAAC,MAAM,CAAC,CAC9C,GAAI,EAAA,CAAC,CAAC,MAAM,GACZ,eAAgB,EAAA,CAAC,CAAC,MAAM,GACxB,WAAY,EAAA,CAAC,CAAC,MAAM,GACpB,aAAc,EAAA,CAAC,CAAC,MAAM,GACtB,OAAQ,EAAA,CAAC,CAAC,IAAI,CAAC,CAAC,QAAS,OAAQ,WAAY,WAAY,UAAU,EACnE,SAAU,EAAA,CAAC,CAAC,MAAM,GAClB,IAAK,EAAA,CAAC,CAAC,MAAM,GACb,MAAO,EAAA,CAAC,CAAC,MAAM,GACf,WAAY,EAAA,CAAC,CAAC,MAAM,GAAG,QAAQ,GAC/B,UAAW,EAAA,CAAC,CAAC,KAAK,CACjB,EAAA,CAAC,CAAC,MAAM,CAAC,CACR,YAAa,EAAA,CAAC,CAAC,MAAM,GACrB,SAAU,EAAA,CAAC,CAAC,MAAM,GAClB,UAAW,EAAA,CAAC,CAAC,MAAM,GACnB,MAAO,EAAA,CAAC,CAAC,MAAM,EAChB,GAEF,GAiBoC,GAAS,CAC5C,GAAI,gBACJ,YAAa,gBACb,YAAa,uDACb,OAAQ,EACT,GAEkC,GAAS,CAC1C,GAAI,cACJ,YAAa,cACb,YAAa,6BACb,OAAQ,EACT,GAE+B,GAAS,CACvC,GAAI,UACJ,YAAa,UACb,YAAa,qCACb,OAAQ,EACT,GAEoC,GAAS,CAC5C,GAAI,gBACJ,YAAa,gBACb,YAAa,sDACb,OAAQ,EACT,GAEiC,GAAS,CACzC,GAAI,QACJ,YAAa,QACb,YAAa,qCACb,OAAQ,EACT,GAEiC,GAAS,CACzC,GAAI,QACJ,YAAa,aACb,YAAa,6CACb,OAAQ,EACT,GAEgC,GAAS,CACxC,GAAI,WACJ,YAAa,WACb,YAAa,4CACb,OAAQ,EACT,GFgHA,EAAA,CAAA,CAAA,OAmCA,EAAA,CAAA,CAAA,QJ1VA,IAAM,GAAc,CAAA,EAAA,EAAA,IAAA,AAAI,EAAC,CACxB,YAAa,yCACb,YAAa,EAAA,CAAC,CAAC,MAAM,CAAC,CACrB,SAAU,EAAA,CAAC,CAAC,MAAM,GAAG,QAAQ,CAAC,6CAC/B,GACA,QAAS,MAAO,CAAE,UAAQ,CAAE,GAEpB,EACN,WACA,YAAa,GACb,WAAY,QACZ,SAAU,GACX,CAEF,GAGM,GAAqB,CAAA,EAAA,EAAA,IAAA,AAAI,EAAC,CAC/B,YAAa,wDACb,YAAa,EAAA,CAAC,CAAC,MAAM,CAAC,CACrB,MAAO,EAAA,CAAC,CAAC,MAAM,GAAG,QAAQ,CAAC,6BAC3B,QAAS,EAAA,CAAC,CAAC,MAAM,GAAG,QAAQ,CAAC,+BAC7B,KAAM,EAAA,CAAC,CACL,IAAI,CAAC,CAAC,OAAQ,OAAQ,QAAS,QAAQ,EACvC,QAAQ,CAAC,uBACZ,GACA,QAAS,MAAO,OAAE,CAAK,SAAE,CAAO,MAAE,CAAI,CAAE,IAGhC,CACN,GAAI,CAAC,IAAI,EAAE,KAAK,GAAG,GAAA,CAAI,OACvB,UACA,OACA,EACA,UAAW,IAAI,OAAO,WAAW,GAClC,CAEF,GAEO,eAAe,GAAK,CAAgB,EAC1C,GAAI,CACH,GAAM,UAAE,CAAQ,OAAE,EAAQ,QAAQ,CAAE,CAAG,MAAM,EAAQ,IAAI,GAGrD,EAA8C,SAC9C,EAAM,QAAQ,CAAC,UAClB,CAD6B,CAClB,YACD,EAAM,QAAQ,CAAC,WAAW,CACpC,EAAW,QAAA,EAIZ,IAAM,EAAU,CAAA,EAAA,EAAA,gBAAA,AAAgB,EAAC,CAChC,WACA,OACD,GAaA,MAAO,CAVQ,MAAM,CAAA,EAAA,EAAA,UAAA,AAAU,EAAC,CAC/B,MAAO,WACP,EACA,MAAO,CACN,WAAY,GACZ,eAAgB,EACjB,EACA,YAAa,EACd,EAAA,EAEc,oBAAoB,EACnC,CAAE,MAAO,EAAO,CACf,OAAO,IAAI,SACV,KAAK,SAAS,CAAC,CACd,MAAO,aAAiB,MAAQ,EAAM,OAAO,CAAG,mBACjD,GACA,CACC,OAAQ,IACR,QAAS,CACR,eAAgB,kBACjB,CACD,EAEF,CACD,oCArF2B,YFc3B,IAAA,GAAA,EAAA,CAAA,CAAA,QAIA,IAAM,GAAc,IAAI,EAAA,mBAAmB,CAAC,CACxC,WAAY,CACR,KAAM,EAAA,SAAS,CAAC,SAAS,CACzB,KAAM,kBACN,SAAU,YACV,SAAU,QACV,WAAY,EAChB,EACA,QAAS,CAAA,OACT,IADiD,eACc,CAA3C,EACpB,iBAAkB,+CAClB,iBAZqB,GAarB,SAAA,EACJ,GAIM,kBAAE,EAAgB,sBAAE,EAAoB,aAAE,EAAW,CAAE,CAAG,GAChE,SAAS,KACL,MAAO,CAAA,EAAA,EAAA,UAAA,AAAW,EAAC,CACf,yCACA,EACJ,EACJ,CAEO,eAAe,GAAQ,CAAG,CAAE,CAAG,CAAE,CAAG,EACnC,GAAY,KAAK,EAAE,AACnB,CAAA,EAAA,EAAA,cAAA,AAAc,EAAC,EAAK,+BAAgC,QAAQ,MAAM,CAAC,MAAM,IAE7E,IAAI,EAAU,kBAKV,EAAU,EAAQ,OAAO,CAAC,WAAY,KAAO,IAMjD,IAAM,EAAgB,MAAM,GAAY,OAAO,CAAC,EAAK,EAAK,SACtD,EACA,mBAHE,CAAA,CAIN,GACA,GAAI,CAAC,EAID,OAHA,EAAI,IADY,MACF,CAAG,IACjB,EAAI,GAAG,CAAC,eACS,MAAjB,CAAwB,CAApB,IAAyB,KAAhB,EAAoB,EAAI,SAAS,CAAC,IAAI,CAAC,EAAK,QAAQ,OAAO,IACjE,KAEX,GAAM,SAAE,CAAO,QAAE,CAAM,YAAE,CAAU,WAAE,CAAS,aAAE,CAAW,mBAAE,CAAiB,qBAAE,CAAmB,sBAAE,CAAoB,yBAAE,CAAuB,kBAAE,CAAgB,yBAAE,CAAuB,uBAAE,CAAqB,CAAE,CAAG,EACnN,EAAoB,CAAA,EAAA,EAAA,gBAAA,AAAgB,EAAC,GACvC,GAAQ,EAAQ,EAAkB,aAAa,CAAC,EAAkB,EAAI,EAAkB,MAAM,CAAC,EAAiB,AAAjB,EAC7F,EAAY,WAEV,AAAuB,QAAO,KAAK,EAAI,EAAoB,SAAA,AAAS,EAAE,AACtE,MAAM,EAAoB,SAAS,CAAC,EAAK,EAAK,GAAW,GAEzD,EAAI,GAAG,CAAC,gCAEL,MAEX,GAAI,GAAS,CAAC,EAAa,CACvB,IAAM,GAAgB,CAAQ,EAAkB,MAAM,CAAC,EAAiB,CAClE,EAAgB,EAAkB,aAAa,CAAC,EAAkB,CACxE,GAAI,IAC+B,IAA3B,EAAc,KADH,GACW,EAAc,CAAC,EAAe,CACpD,GAAI,EAAW,YAAY,CAAC,WAAW,CACnC,CADqC,MAC9B,MAAM,GAEjB,OAAM,IAAI,EAAA,eAAe,AAC7B,CAER,CACA,IAAI,EAAW,MACX,GAAU,GAAY,GAAb,EAAkB,EAAK,EAAD,EAG/B,EAAW,AAAa,OAHqB,KAC7C,EAAW,CAAA,EAEwB,IAAM,CAAA,EAE7C,IAAM,GACgB,IAAtB,GAAY,CAAkB,IAAb,EAEjB,CAAC,EAKK,EAAqB,GAAS,CAAC,CAIjC,IAAyB,GACzB,CAAA,EAAA,EAAA,iBADkD,aAClD,AAA8B,EAAC,CAC3B,KAAM,GAbqF,uBAc3F,wBACA,EACA,gBAAiB,CAAA,EAAA,EAAA,qBAAqB,AAArB,EAAsB,CACnC,uBACJ,EACJ,GAEJ,IAAM,EAAS,EAAI,MAAM,EAAI,MACvB,EAAS,CAAA,EAAA,EAAA,SAAA,AAAS,IAClB,EAAa,EAAO,kBAAkB,GACtC,EAAU,CACZ,2BACA,EACA,WAAY,CACR,aAAc,CACV,gBAAgB,CAAQ,EAAW,YAAY,CAAC,cAAc,AAClE,EACA,iBAAiB,CAAQ,EAAW,eAAe,CACnD,0BACA,iBAAkB,CAAA,EAAA,EAAA,cAAA,AAAc,EAAC,EAAK,oBACtC,kBAAmB,EAAW,SAAS,CACvC,UAAW,EAAI,SAAS,CACxB,QAAU,AAAD,IACL,EAAI,EAAE,CAAC,QAAS,EACpB,EACA,sBAAkB,EAClB,8BAA+B,CAAC,EAAO,EAAU,IAAe,GAAY,cAAc,CAAC,EAAK,EAAO,EAAc,EACzH,EACA,cAAe,SACX,CACJ,CACJ,EACM,EAAc,IAAI,EAAA,eAAe,CAAC,GAClC,EAAc,IAAI,EAAA,gBAAgB,CAAC,GACnC,EAAU,EAAA,kBAAkB,CAAC,mBAAmB,CAAC,EAAa,CAAA,EAAA,EAAA,sBAAA,AAAsB,EAAC,IAC3F,GAAI,CACA,IAAM,EAAoB,MAAO,GACtB,GAAY,MAAM,CAAC,EAAS,GAAS,OAAO,CAAC,KAChD,GAAI,CAAC,EAAM,OACX,EAAK,aAAa,CAAC,CACf,mBAAoB,EAAI,UAAU,CAClC,YAAY,CAChB,GACA,IAAM,EAAqB,EAAO,qBAAqB,GAEvD,GAAI,CAAC,EACD,OAEJ,GAAI,EAAmB,GAAG,CAAC,EAHF,kBAGwB,EAAA,cAAc,CAAC,aAAa,CAAE,YAC3E,QAAQ,IAAI,CAAC,CAAC,2BAA2B,EAAE,EAAmB,GAAG,CAAC,kBAAkB,qEAAqE,CAAC,EAG9J,IAAM,EAAQ,EAAmB,GAAG,CAAC,cACrC,GAAI,EAAO,CACP,IAAM,EAAO,CAAA,EAAG,EAAO,CAAC,EAAE,EAAA,CAAO,CACjC,EAAK,aAAa,CAAC,CACf,aAAc,EACd,aAAc,EACd,iBAAkB,CACtB,GACA,EAAK,UAAU,CAAC,EACpB,MACI,CADG,CACE,UAAU,CAAC,CAAA,EAAG,EAAO,CAAC,EAAE,EAAA,CAAS,CAE9C,GAEE,GAAgB,CAAoC,CAAA,EAAA,EAAA,EAA5B,YAA4B,AAAc,EAAC,EAAK,eACxE,EAAiB,MAAO,QACtB,EA2FI,EA1FR,IAAM,EAAoB,MAAO,oBAAE,CAAkB,CAAE,IACnD,GAAI,CACA,GAAI,CAAC,GAAiB,GAAwB,GAA2B,CAAC,EAKtE,OAJA,EAAI,SADsF,CAC5E,CAAG,IAEjB,EAAI,SAAS,CAAC,iBAAkB,eAChC,EAAI,GAAG,CAAC,gCACD,KAEX,IAAM,EAAW,MAAM,EAAkB,GACzC,EAAI,YAAY,CAAG,EAAQ,UAAU,CAAC,YAAY,CAClD,IAAI,EAAmB,EAAQ,UAAU,CAAC,gBAAgB,CAGtD,GACI,EAAI,SAAS,EAAE,CACf,CAFc,CAEV,SAAS,CAAC,GACd,EAAmB,QAG3B,IAAM,EAAY,EAAQ,UAAU,CAAC,aAAa,CAGlD,IAAI,EA6BA,OADA,MAAM,CAAA,EAAA,EAAA,YAAA,AAAY,EAAC,EAAa,EAAa,EAAU,EAAQ,UAAU,CAAC,gBAAgB,EACnF,IA7BA,EACP,IAAM,EAAO,MAAM,EAAS,IAAI,GAE1B,EAAU,CAAA,EAAA,EAAA,yBAAA,AAAyB,EAAC,EAAS,OAAO,EACtD,IACA,CAAO,CAAC,EAAA,GADG,mBACmB,CAAC,CAAG,CAAA,EAElC,CAAC,CAAO,CAAC,eAAe,EAAI,EAAK,IAAI,EAAE,CACvC,CAAO,CAAC,eAAe,CAAG,EAAK,IAAA,AAAI,EAEvC,IAAM,EAAa,KAAkD,IAA3C,EAAQ,UAAU,CAAC,mBAAmB,IAAoB,EAAQ,UAAU,CAAC,mBAAmB,EAAI,EAAA,cAAA,AAAc,GAAG,AAAQ,EAAQ,UAAU,CAAC,mBAAmB,CACvL,EAAS,KAA8C,IAAvC,EAAQ,UAAU,CAAC,eAAe,EAAoB,EAAQ,UAAU,CAAC,eAAe,EAAI,EAAA,cAAc,CAAG,OAAY,EAAQ,UAAU,CAAC,eAAe,CAcjL,MAZmB,CAYZ,AAXH,MAAO,CACH,KAAM,EAAA,eAAe,CAAC,SAAS,CAC/B,OAAQ,EAAS,MAAM,CACvB,KAAM,OAAO,IAAI,CAAC,MAAM,EAAK,WAAW,IACxC,SACJ,EACA,aAAc,YACV,SACA,CACJ,CACJ,CAEJ,CAKJ,CAAE,KALS,CAKF,EAAK,CAcV,MAX0B,MAAtB,EAA6B,KAAK,EAAI,EAAmB,OAAA,AAAO,EAAE,CAClE,MAAM,GAAY,cAAc,CAAC,EAAK,EAAK,CACvC,WAAY,aACZ,UAAW,EACX,UAAW,QACX,iBAAkB,CAAA,EAAA,EAAA,mBAAA,AAAmB,EAAC,oBAClC,uBACA,CACJ,EACJ,EAAG,GAED,CACV,CACJ,EACM,EAAa,MAAM,GAAY,cAAc,CAAC,KAChD,EACA,sBACA,EACA,UAAW,EAAA,SAAS,CAAC,SAAS,CAC9B,YAAY,oBACZ,EACA,mBAAmB,uBACnB,0BACA,oBACA,EACA,UAAW,EAAI,SAAS,eACxB,CACJ,GAEA,GAAI,CAAC,EACD,KADQ,EACD,KAEX,GAAI,CAAe,MAAd,CAAqB,EAAS,AAA0C,GAA9C,IAAK,EAAoB,EAAW,KAAA,AAAK,EAAY,KAAK,EAAI,EAAkB,IAAI,IAAM,EAAA,eAAe,CAAC,SAAS,CAE9I,CAFgJ,KAE1I,OAAO,cAAc,CAAC,AAAI,MAAM,CAAC,kDAAkD,EAAgB,MAAd,CAAqB,EAAS,AAA2C,GAA/C,IAAK,EAAqB,EAAW,KAAK,AAAL,EAAiB,KAAK,EAAI,EAAmB,IAAI,CAAA,CAAE,EAAG,oBAAqB,CACjO,MAAO,OACP,YAAY,EACZ,cAAc,CAClB,EAEA,CAAC,GACD,EAAI,SAAS,CADG,AACF,iBAAkB,EAAuB,cAAgB,EAAW,MAAM,CAAG,OAAS,EAAW,OAAO,CAAG,QAAU,OAGnI,GACA,EAAI,QADS,CACA,CAAC,gBAAiB,2DAEnC,IAAM,EAAU,CAAA,EAAA,EAAA,2BAAA,AAA2B,EAAC,EAAW,KAAK,CAAC,OAAO,EAcpE,OAbI,AAAE,CAAD,EAAkB,GACnB,EAAQ,AADgB,GAAG,GACb,CAAC,EAAA,sBAAsB,GAIrC,EAAW,YAAY,EAAK,EAAD,AAAK,SAAS,CAAC,kBAAqB,EAAD,AAAS,GAAG,CAAC,kBAAkB,AAC7F,EAAQ,GAAG,CAAC,gBAAiB,CAAA,EAAA,EAAA,qBAAqB,AAArB,EAAsB,EAAW,YAAY,GAE9E,MAAM,CAAA,EAAA,EAAA,YAAA,AAAY,EAAC,EAAa,EAChC,IAAI,SAAS,EAAW,KAAK,CAAC,IAAI,CAAE,SAChC,EACA,OAAQ,EAAW,KAAK,CAAC,MAAM,EAAI,GACvC,IACO,IACX,EAGI,EACA,MAAM,EAAe,EADT,CAGZ,MAAM,EAAO,qBAAqB,CAAC,EAAI,OAAO,CAAE,IAAI,EAAO,KAAK,CAAC,EAAA,cAAc,CAAC,aAAa,CAAE,CACvF,SAAU,CAAA,EAAG,EAAO,CAAC,EAAE,EAAA,CAAS,CAChC,KAAM,EAAA,QAAQ,CAAC,MAAM,CACrB,WAAY,CACR,cAAe,EACf,cAAe,EAAI,GAAG,AAC1B,CACJ,EAAG,GAEf,CAAE,MAAO,EAAK,CAcV,GAbI,AAAE,CAAD,YAAgB,EAAA,eAAe,EAChC,CADmC,KAC7B,GAAY,cAAc,CAAC,EAAK,EAAK,CACvC,WAAY,aACZ,UAAW,EACX,UAAW,QACX,iBAAkB,CAAA,EAAA,EAAA,mBAAA,AAAmB,EAAC,oBAClC,uBACA,CACJ,EACJ,GAIA,EAAO,MAAM,EAKjB,OAHA,MAAM,CAAA,EAAA,EAAA,YAAA,AAAY,EAAC,EAAa,EAAa,IAAI,SAAS,KAAM,CAC5D,OAAQ,GACZ,IACO,IACX,CACJ,EAEA,qCAAqC","ignoreList":[0,2,3,5,11,12,13,17,20,21,22,23,24,25,26,27,28,29,30,31,32]}