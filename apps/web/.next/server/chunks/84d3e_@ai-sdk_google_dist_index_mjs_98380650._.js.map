{"version":3,"sources":["../../../../../node_modules/.pnpm/%40ai-sdk%2Bgoogle%402.0.31_zod%404.1.12/node_modules/%40ai-sdk/google/src/google-provider.ts","../../../../../node_modules/.pnpm/%40ai-sdk%2Bgoogle%402.0.31_zod%404.1.12/node_modules/%40ai-sdk/google/src/version.ts","../../../../../node_modules/.pnpm/%40ai-sdk%2Bgoogle%402.0.31_zod%404.1.12/node_modules/%40ai-sdk/google/src/google-generative-ai-embedding-model.ts","../../../../../node_modules/.pnpm/%40ai-sdk%2Bgoogle%402.0.31_zod%404.1.12/node_modules/%40ai-sdk/google/src/google-error.ts","../../../../../node_modules/.pnpm/%40ai-sdk%2Bgoogle%402.0.31_zod%404.1.12/node_modules/%40ai-sdk/google/src/google-generative-ai-embedding-options.ts","../../../../../node_modules/.pnpm/%40ai-sdk%2Bgoogle%402.0.31_zod%404.1.12/node_modules/%40ai-sdk/google/src/google-generative-ai-language-model.ts","../../../../../node_modules/.pnpm/%40ai-sdk%2Bgoogle%402.0.31_zod%404.1.12/node_modules/%40ai-sdk/google/src/convert-json-schema-to-openapi-schema.ts","../../../../../node_modules/.pnpm/%40ai-sdk%2Bgoogle%402.0.31_zod%404.1.12/node_modules/%40ai-sdk/google/src/convert-to-google-generative-ai-messages.ts","../../../../../node_modules/.pnpm/%40ai-sdk%2Bgoogle%402.0.31_zod%404.1.12/node_modules/%40ai-sdk/google/src/get-model-path.ts","../../../../../node_modules/.pnpm/%40ai-sdk%2Bgoogle%402.0.31_zod%404.1.12/node_modules/%40ai-sdk/google/src/google-generative-ai-options.ts","../../../../../node_modules/.pnpm/%40ai-sdk%2Bgoogle%402.0.31_zod%404.1.12/node_modules/%40ai-sdk/google/src/google-prepare-tools.ts","../../../../../node_modules/.pnpm/%40ai-sdk%2Bgoogle%402.0.31_zod%404.1.12/node_modules/%40ai-sdk/google/src/map-google-generative-ai-finish-reason.ts","../../../../../node_modules/.pnpm/%40ai-sdk%2Bgoogle%402.0.31_zod%404.1.12/node_modules/%40ai-sdk/google/src/tool/code-execution.ts","../../../../../node_modules/.pnpm/%40ai-sdk%2Bgoogle%402.0.31_zod%404.1.12/node_modules/%40ai-sdk/google/src/tool/file-search.ts","../../../../../node_modules/.pnpm/%40ai-sdk%2Bgoogle%402.0.31_zod%404.1.12/node_modules/%40ai-sdk/google/src/tool/google-search.ts","../../../../../node_modules/.pnpm/%40ai-sdk%2Bgoogle%402.0.31_zod%404.1.12/node_modules/%40ai-sdk/google/src/tool/url-context.ts","../../../../../node_modules/.pnpm/%40ai-sdk%2Bgoogle%402.0.31_zod%404.1.12/node_modules/%40ai-sdk/google/src/google-tools.ts","../../../../../node_modules/.pnpm/%40ai-sdk%2Bgoogle%402.0.31_zod%404.1.12/node_modules/%40ai-sdk/google/src/google-generative-ai-image-model.ts"],"sourcesContent":["import {\n  EmbeddingModelV2,\n  LanguageModelV2,\n  ProviderV2,\n  ImageModelV2,\n} from '@ai-sdk/provider';\nimport {\n  FetchFunction,\n  generateId,\n  loadApiKey,\n  withoutTrailingSlash,\n  withUserAgentSuffix,\n} from '@ai-sdk/provider-utils';\nimport { VERSION } from './version';\nimport { GoogleGenerativeAIEmbeddingModel } from './google-generative-ai-embedding-model';\nimport { GoogleGenerativeAIEmbeddingModelId } from './google-generative-ai-embedding-options';\nimport { GoogleGenerativeAILanguageModel } from './google-generative-ai-language-model';\nimport { GoogleGenerativeAIModelId } from './google-generative-ai-options';\nimport { googleTools } from './google-tools';\n\nimport {\n  GoogleGenerativeAIImageSettings,\n  GoogleGenerativeAIImageModelId,\n} from './google-generative-ai-image-settings';\nimport { GoogleGenerativeAIImageModel } from './google-generative-ai-image-model';\n\nexport interface GoogleGenerativeAIProvider extends ProviderV2 {\n  (modelId: GoogleGenerativeAIModelId): LanguageModelV2;\n\n  languageModel(modelId: GoogleGenerativeAIModelId): LanguageModelV2;\n\n  chat(modelId: GoogleGenerativeAIModelId): LanguageModelV2;\n\n  /**\nCreates a model for image generation.\n */\n  image(\n    modelId: GoogleGenerativeAIImageModelId,\n    settings?: GoogleGenerativeAIImageSettings,\n  ): ImageModelV2;\n\n  /**\n   * @deprecated Use `chat()` instead.\n   */\n  generativeAI(modelId: GoogleGenerativeAIModelId): LanguageModelV2;\n\n  /**\n@deprecated Use `textEmbedding()` instead.\n   */\n  embedding(\n    modelId: GoogleGenerativeAIEmbeddingModelId,\n  ): EmbeddingModelV2<string>;\n\n  textEmbedding(\n    modelId: GoogleGenerativeAIEmbeddingModelId,\n  ): EmbeddingModelV2<string>;\n\n  textEmbeddingModel(\n    modelId: GoogleGenerativeAIEmbeddingModelId,\n  ): EmbeddingModelV2<string>;\n\n  tools: typeof googleTools;\n}\n\nexport interface GoogleGenerativeAIProviderSettings {\n  /**\nUse a different URL prefix for API calls, e.g. to use proxy servers.\nThe default prefix is `https://generativelanguage.googleapis.com/v1beta`.\n   */\n  baseURL?: string;\n\n  /**\nAPI key that is being send using the `x-goog-api-key` header.\nIt defaults to the `GOOGLE_GENERATIVE_AI_API_KEY` environment variable.\n   */\n  apiKey?: string;\n\n  /**\nCustom headers to include in the requests.\n     */\n  headers?: Record<string, string | undefined>;\n\n  /**\nCustom fetch implementation. You can use it as a middleware to intercept requests,\nor to provide a custom fetch implementation for e.g. testing.\n    */\n  fetch?: FetchFunction;\n\n  /**\nOptional function to generate a unique ID for each request.\n     */\n  generateId?: () => string;\n\n  /**\n   * Custom provider name\n   * Defaults to 'google.generative-ai'.\n   */\n  name?: string;\n}\n\n/**\nCreate a Google Generative AI provider instance.\n */\nexport function createGoogleGenerativeAI(\n  options: GoogleGenerativeAIProviderSettings = {},\n): GoogleGenerativeAIProvider {\n  const baseURL =\n    withoutTrailingSlash(options.baseURL) ??\n    'https://generativelanguage.googleapis.com/v1beta';\n\n  const providerName = options.name ?? 'google.generative-ai';\n\n  const getHeaders = () =>\n    withUserAgentSuffix(\n      {\n        'x-goog-api-key': loadApiKey({\n          apiKey: options.apiKey,\n          environmentVariableName: 'GOOGLE_GENERATIVE_AI_API_KEY',\n          description: 'Google Generative AI',\n        }),\n        ...options.headers,\n      },\n      `ai-sdk/google/${VERSION}`,\n    );\n\n  const createChatModel = (modelId: GoogleGenerativeAIModelId) =>\n    new GoogleGenerativeAILanguageModel(modelId, {\n      provider: providerName,\n      baseURL,\n      headers: getHeaders,\n      generateId: options.generateId ?? generateId,\n      supportedUrls: () => ({\n        '*': [\n          // Google Generative Language \"files\" endpoint\n          // e.g. https://generativelanguage.googleapis.com/v1beta/files/...\n          new RegExp(`^${baseURL}/files/.*$`),\n          // YouTube URLs (public or unlisted videos)\n          new RegExp(\n            `^https://(?:www\\\\.)?youtube\\\\.com/watch\\\\?v=[\\\\w-]+(?:&[\\\\w=&.-]*)?$`,\n          ),\n          new RegExp(`^https://youtu\\\\.be/[\\\\w-]+(?:\\\\?[\\\\w=&.-]*)?$`),\n        ],\n      }),\n      fetch: options.fetch,\n    });\n\n  const createEmbeddingModel = (modelId: GoogleGenerativeAIEmbeddingModelId) =>\n    new GoogleGenerativeAIEmbeddingModel(modelId, {\n      provider: providerName,\n      baseURL,\n      headers: getHeaders,\n      fetch: options.fetch,\n    });\n\n  const createImageModel = (\n    modelId: GoogleGenerativeAIImageModelId,\n    settings: GoogleGenerativeAIImageSettings = {},\n  ) =>\n    new GoogleGenerativeAIImageModel(modelId, settings, {\n      provider: providerName,\n      baseURL,\n      headers: getHeaders,\n      fetch: options.fetch,\n    });\n\n  const provider = function (modelId: GoogleGenerativeAIModelId) {\n    if (new.target) {\n      throw new Error(\n        'The Google Generative AI model function cannot be called with the new keyword.',\n      );\n    }\n\n    return createChatModel(modelId);\n  };\n\n  provider.languageModel = createChatModel;\n  provider.chat = createChatModel;\n  provider.generativeAI = createChatModel;\n  provider.embedding = createEmbeddingModel;\n  provider.textEmbedding = createEmbeddingModel;\n  provider.textEmbeddingModel = createEmbeddingModel;\n  provider.image = createImageModel;\n  provider.imageModel = createImageModel;\n  provider.tools = googleTools;\n  return provider as GoogleGenerativeAIProvider;\n}\n\n/**\nDefault Google Generative AI provider instance.\n */\nexport const google = createGoogleGenerativeAI();\n","// Version string of this package injected at build time.\ndeclare const __PACKAGE_VERSION__: string | undefined;\nexport const VERSION: string =\n  typeof __PACKAGE_VERSION__ !== 'undefined'\n    ? __PACKAGE_VERSION__\n    : '0.0.0-test';\n","import {\n  EmbeddingModelV2,\n  TooManyEmbeddingValuesForCallError,\n} from '@ai-sdk/provider';\nimport {\n  combineHeaders,\n  createJsonResponseHandler,\n  FetchFunction,\n  lazySchema,\n  parseProviderOptions,\n  postJsonToApi,\n  resolve,\n  zodSchema,\n} from '@ai-sdk/provider-utils';\nimport { z } from 'zod/v4';\nimport { googleFailedResponseHandler } from './google-error';\nimport {\n  GoogleGenerativeAIEmbeddingModelId,\n  googleGenerativeAIEmbeddingProviderOptions,\n} from './google-generative-ai-embedding-options';\n\ntype GoogleGenerativeAIEmbeddingConfig = {\n  provider: string;\n  baseURL: string;\n  headers: () => Record<string, string | undefined>;\n  fetch?: FetchFunction;\n};\n\nexport class GoogleGenerativeAIEmbeddingModel\n  implements EmbeddingModelV2<string>\n{\n  readonly specificationVersion = 'v2';\n  readonly modelId: GoogleGenerativeAIEmbeddingModelId;\n  readonly maxEmbeddingsPerCall = 2048;\n  readonly supportsParallelCalls = true;\n\n  private readonly config: GoogleGenerativeAIEmbeddingConfig;\n\n  get provider(): string {\n    return this.config.provider;\n  }\n  constructor(\n    modelId: GoogleGenerativeAIEmbeddingModelId,\n    config: GoogleGenerativeAIEmbeddingConfig,\n  ) {\n    this.modelId = modelId;\n    this.config = config;\n  }\n\n  async doEmbed({\n    values,\n    headers,\n    abortSignal,\n    providerOptions,\n  }: Parameters<EmbeddingModelV2<string>['doEmbed']>[0]): Promise<\n    Awaited<ReturnType<EmbeddingModelV2<string>['doEmbed']>>\n  > {\n    // Parse provider options\n    const googleOptions = await parseProviderOptions({\n      provider: 'google',\n      providerOptions,\n      schema: googleGenerativeAIEmbeddingProviderOptions,\n    });\n\n    if (values.length > this.maxEmbeddingsPerCall) {\n      throw new TooManyEmbeddingValuesForCallError({\n        provider: this.provider,\n        modelId: this.modelId,\n        maxEmbeddingsPerCall: this.maxEmbeddingsPerCall,\n        values,\n      });\n    }\n\n    const mergedHeaders = combineHeaders(\n      await resolve(this.config.headers),\n      headers,\n    );\n\n    // For single embeddings, use the single endpoint (ratelimits, etc.)\n    if (values.length === 1) {\n      const {\n        responseHeaders,\n        value: response,\n        rawValue,\n      } = await postJsonToApi({\n        url: `${this.config.baseURL}/models/${this.modelId}:embedContent`,\n        headers: mergedHeaders,\n        body: {\n          model: `models/${this.modelId}`,\n          content: {\n            parts: [{ text: values[0] }],\n          },\n          outputDimensionality: googleOptions?.outputDimensionality,\n          taskType: googleOptions?.taskType,\n        },\n        failedResponseHandler: googleFailedResponseHandler,\n        successfulResponseHandler: createJsonResponseHandler(\n          googleGenerativeAISingleEmbeddingResponseSchema,\n        ),\n        abortSignal,\n        fetch: this.config.fetch,\n      });\n\n      return {\n        embeddings: [response.embedding.values],\n        usage: undefined,\n        response: { headers: responseHeaders, body: rawValue },\n      };\n    }\n\n    const {\n      responseHeaders,\n      value: response,\n      rawValue,\n    } = await postJsonToApi({\n      url: `${this.config.baseURL}/models/${this.modelId}:batchEmbedContents`,\n      headers: mergedHeaders,\n      body: {\n        requests: values.map(value => ({\n          model: `models/${this.modelId}`,\n          content: { role: 'user', parts: [{ text: value }] },\n          outputDimensionality: googleOptions?.outputDimensionality,\n          taskType: googleOptions?.taskType,\n        })),\n      },\n      failedResponseHandler: googleFailedResponseHandler,\n      successfulResponseHandler: createJsonResponseHandler(\n        googleGenerativeAITextEmbeddingResponseSchema,\n      ),\n      abortSignal,\n      fetch: this.config.fetch,\n    });\n\n    return {\n      embeddings: response.embeddings.map(item => item.values),\n      usage: undefined,\n      response: { headers: responseHeaders, body: rawValue },\n    };\n  }\n}\n\n// minimal version of the schema, focussed on what is needed for the implementation\n// this approach limits breakages when the API changes and increases efficiency\nconst googleGenerativeAITextEmbeddingResponseSchema = lazySchema(() =>\n  zodSchema(\n    z.object({\n      embeddings: z.array(z.object({ values: z.array(z.number()) })),\n    }),\n  ),\n);\n\n// Schema for single embedding response\nconst googleGenerativeAISingleEmbeddingResponseSchema = lazySchema(() =>\n  zodSchema(\n    z.object({\n      embedding: z.object({ values: z.array(z.number()) }),\n    }),\n  ),\n);\n","import {\n  createJsonErrorResponseHandler,\n  type InferValidator,\n  lazySchema,\n  zodSchema,\n} from '@ai-sdk/provider-utils';\nimport { z } from 'zod/v4';\n\nconst googleErrorDataSchema = lazySchema(() =>\n  zodSchema(\n    z.object({\n      error: z.object({\n        code: z.number().nullable(),\n        message: z.string(),\n        status: z.string(),\n      }),\n    }),\n  ),\n);\n\nexport type GoogleErrorData = InferValidator<typeof googleErrorDataSchema>;\n\nexport const googleFailedResponseHandler = createJsonErrorResponseHandler({\n  errorSchema: googleErrorDataSchema,\n  errorToMessage: data => data.error.message,\n});\n","import {\n  type InferValidator,\n  lazySchema,\n  zodSchema,\n} from '@ai-sdk/provider-utils';\nimport { z } from 'zod/v4';\n\nexport type GoogleGenerativeAIEmbeddingModelId =\n  | 'gemini-embedding-001'\n  | 'text-embedding-004'\n  | (string & {});\n\nexport const googleGenerativeAIEmbeddingProviderOptions = lazySchema(() =>\n  zodSchema(\n    z.object({\n      /**\n       * Optional. Optional reduced dimension for the output embedding.\n       * If set, excessive values in the output embedding are truncated from the end.\n       */\n      outputDimensionality: z.number().optional(),\n\n      /**\n       * Optional. Specifies the task type for generating embeddings.\n       * Supported task types:\n       * - SEMANTIC_SIMILARITY: Optimized for text similarity.\n       * - CLASSIFICATION: Optimized for text classification.\n       * - CLUSTERING: Optimized for clustering texts based on similarity.\n       * - RETRIEVAL_DOCUMENT: Optimized for document retrieval.\n       * - RETRIEVAL_QUERY: Optimized for query-based retrieval.\n       * - QUESTION_ANSWERING: Optimized for answering questions.\n       * - FACT_VERIFICATION: Optimized for verifying factual information.\n       * - CODE_RETRIEVAL_QUERY: Optimized for retrieving code blocks based on natural language queries.\n       */\n      taskType: z\n        .enum([\n          'SEMANTIC_SIMILARITY',\n          'CLASSIFICATION',\n          'CLUSTERING',\n          'RETRIEVAL_DOCUMENT',\n          'RETRIEVAL_QUERY',\n          'QUESTION_ANSWERING',\n          'FACT_VERIFICATION',\n          'CODE_RETRIEVAL_QUERY',\n        ])\n        .optional(),\n    }),\n  ),\n);\n\nexport type GoogleGenerativeAIEmbeddingProviderOptions = InferValidator<\n  typeof googleGenerativeAIEmbeddingProviderOptions\n>;\n","import {\n  LanguageModelV2,\n  LanguageModelV2CallWarning,\n  LanguageModelV2Content,\n  LanguageModelV2FinishReason,\n  LanguageModelV2Source,\n  LanguageModelV2StreamPart,\n  LanguageModelV2Usage,\n  SharedV2ProviderMetadata,\n} from '@ai-sdk/provider';\nimport {\n  FetchFunction,\n  InferValidator,\n  ParseResult,\n  Resolvable,\n  combineHeaders,\n  createEventSourceResponseHandler,\n  createJsonResponseHandler,\n  generateId,\n  lazySchema,\n  parseProviderOptions,\n  postJsonToApi,\n  resolve,\n  zodSchema,\n} from '@ai-sdk/provider-utils';\nimport { z } from 'zod/v4';\nimport { convertJSONSchemaToOpenAPISchema } from './convert-json-schema-to-openapi-schema';\nimport { convertToGoogleGenerativeAIMessages } from './convert-to-google-generative-ai-messages';\nimport { getModelPath } from './get-model-path';\nimport { googleFailedResponseHandler } from './google-error';\nimport { GoogleGenerativeAIContentPart } from './google-generative-ai-prompt';\nimport {\n  GoogleGenerativeAIModelId,\n  googleGenerativeAIProviderOptions,\n} from './google-generative-ai-options';\nimport { prepareTools } from './google-prepare-tools';\nimport { mapGoogleGenerativeAIFinishReason } from './map-google-generative-ai-finish-reason';\n\ntype GoogleGenerativeAIConfig = {\n  provider: string;\n  baseURL: string;\n  headers: Resolvable<Record<string, string | undefined>>;\n  fetch?: FetchFunction;\n  generateId: () => string;\n\n  /**\n   * The supported URLs for the model.\n   */\n  supportedUrls?: () => LanguageModelV2['supportedUrls'];\n};\n\nexport class GoogleGenerativeAILanguageModel implements LanguageModelV2 {\n  readonly specificationVersion = 'v2';\n\n  readonly modelId: GoogleGenerativeAIModelId;\n\n  private readonly config: GoogleGenerativeAIConfig;\n  private readonly generateId: () => string;\n\n  constructor(\n    modelId: GoogleGenerativeAIModelId,\n    config: GoogleGenerativeAIConfig,\n  ) {\n    this.modelId = modelId;\n    this.config = config;\n    this.generateId = config.generateId ?? generateId;\n  }\n\n  get provider(): string {\n    return this.config.provider;\n  }\n\n  get supportedUrls() {\n    return this.config.supportedUrls?.() ?? {};\n  }\n\n  private async getArgs({\n    prompt,\n    maxOutputTokens,\n    temperature,\n    topP,\n    topK,\n    frequencyPenalty,\n    presencePenalty,\n    stopSequences,\n    responseFormat,\n    seed,\n    tools,\n    toolChoice,\n    providerOptions,\n  }: Parameters<LanguageModelV2['doGenerate']>[0]) {\n    const warnings: LanguageModelV2CallWarning[] = [];\n\n    const googleOptions = await parseProviderOptions({\n      provider: 'google',\n      providerOptions,\n      schema: googleGenerativeAIProviderOptions,\n    });\n\n    // Add warning if includeThoughts is used with a non-Vertex Google provider\n    if (\n      googleOptions?.thinkingConfig?.includeThoughts === true &&\n      !this.config.provider.startsWith('google.vertex.')\n    ) {\n      warnings.push({\n        type: 'other',\n        message:\n          \"The 'includeThoughts' option is only supported with the Google Vertex provider \" +\n          'and might not be supported or could behave unexpectedly with the current Google provider ' +\n          `(${this.config.provider}).`,\n      });\n    }\n\n    const isGemmaModel = this.modelId.toLowerCase().startsWith('gemma-');\n\n    const { contents, systemInstruction } = convertToGoogleGenerativeAIMessages(\n      prompt,\n      { isGemmaModel },\n    );\n\n    const {\n      tools: googleTools,\n      toolConfig: googleToolConfig,\n      toolWarnings,\n    } = prepareTools({\n      tools,\n      toolChoice,\n      modelId: this.modelId,\n    });\n\n    return {\n      args: {\n        generationConfig: {\n          // standardized settings:\n          maxOutputTokens,\n          temperature,\n          topK,\n          topP,\n          frequencyPenalty,\n          presencePenalty,\n          stopSequences,\n          seed,\n\n          // response format:\n          responseMimeType:\n            responseFormat?.type === 'json' ? 'application/json' : undefined,\n          responseSchema:\n            responseFormat?.type === 'json' &&\n            responseFormat.schema != null &&\n            // Google GenAI does not support all OpenAPI Schema features,\n            // so this is needed as an escape hatch:\n            // TODO convert into provider option\n            (googleOptions?.structuredOutputs ?? true)\n              ? convertJSONSchemaToOpenAPISchema(responseFormat.schema)\n              : undefined,\n          ...(googleOptions?.audioTimestamp && {\n            audioTimestamp: googleOptions.audioTimestamp,\n          }),\n\n          // provider options:\n          responseModalities: googleOptions?.responseModalities,\n          thinkingConfig: googleOptions?.thinkingConfig,\n          ...(googleOptions?.imageConfig && {\n            imageConfig: googleOptions.imageConfig,\n          }),\n          ...(googleOptions?.mediaResolution && {\n            mediaResolution: googleOptions.mediaResolution,\n          }),\n        },\n        contents,\n        systemInstruction: isGemmaModel ? undefined : systemInstruction,\n        safetySettings: googleOptions?.safetySettings,\n        tools: googleTools,\n        toolConfig: googleToolConfig,\n        cachedContent: googleOptions?.cachedContent,\n        labels: googleOptions?.labels,\n      },\n      warnings: [...warnings, ...toolWarnings],\n    };\n  }\n\n  async doGenerate(\n    options: Parameters<LanguageModelV2['doGenerate']>[0],\n  ): Promise<Awaited<ReturnType<LanguageModelV2['doGenerate']>>> {\n    const { args, warnings } = await this.getArgs(options);\n    const body = JSON.stringify(args);\n\n    const mergedHeaders = combineHeaders(\n      await resolve(this.config.headers),\n      options.headers,\n    );\n\n    const {\n      responseHeaders,\n      value: response,\n      rawValue: rawResponse,\n    } = await postJsonToApi({\n      url: `${this.config.baseURL}/${getModelPath(\n        this.modelId,\n      )}:generateContent`,\n      headers: mergedHeaders,\n      body: args,\n      failedResponseHandler: googleFailedResponseHandler,\n      successfulResponseHandler: createJsonResponseHandler(responseSchema),\n      abortSignal: options.abortSignal,\n      fetch: this.config.fetch,\n    });\n\n    const candidate = response.candidates[0];\n    const content: Array<LanguageModelV2Content> = [];\n\n    // map ordered parts to content:\n    const parts = candidate.content?.parts ?? [];\n\n    const usageMetadata = response.usageMetadata;\n\n    // Associates a code execution result with its preceding call.\n    let lastCodeExecutionToolCallId: string | undefined;\n\n    // Build content array from all parts\n    for (const part of parts) {\n      if ('executableCode' in part && part.executableCode?.code) {\n        const toolCallId = this.config.generateId();\n        lastCodeExecutionToolCallId = toolCallId;\n\n        content.push({\n          type: 'tool-call',\n          toolCallId,\n          toolName: 'code_execution',\n          input: JSON.stringify(part.executableCode),\n          providerExecuted: true,\n        });\n      } else if ('codeExecutionResult' in part && part.codeExecutionResult) {\n        content.push({\n          type: 'tool-result',\n          // Assumes a result directly follows its corresponding call part.\n          toolCallId: lastCodeExecutionToolCallId!,\n          toolName: 'code_execution',\n          result: {\n            outcome: part.codeExecutionResult.outcome,\n            output: part.codeExecutionResult.output,\n          },\n          providerExecuted: true,\n        });\n        // Clear the ID after use to avoid accidental reuse.\n        lastCodeExecutionToolCallId = undefined;\n      } else if ('text' in part && part.text != null && part.text.length > 0) {\n        content.push({\n          type: part.thought === true ? 'reasoning' : 'text',\n          text: part.text,\n          providerMetadata: part.thoughtSignature\n            ? { google: { thoughtSignature: part.thoughtSignature } }\n            : undefined,\n        });\n      } else if ('functionCall' in part) {\n        content.push({\n          type: 'tool-call' as const,\n          toolCallId: this.config.generateId(),\n          toolName: part.functionCall.name,\n          input: JSON.stringify(part.functionCall.args),\n          providerMetadata: part.thoughtSignature\n            ? { google: { thoughtSignature: part.thoughtSignature } }\n            : undefined,\n        });\n      } else if ('inlineData' in part) {\n        content.push({\n          type: 'file' as const,\n          data: part.inlineData.data,\n          mediaType: part.inlineData.mimeType,\n        });\n      }\n    }\n\n    const sources =\n      extractSources({\n        groundingMetadata: candidate.groundingMetadata,\n        generateId: this.config.generateId,\n      }) ?? [];\n    for (const source of sources) {\n      content.push(source);\n    }\n\n    return {\n      content,\n      finishReason: mapGoogleGenerativeAIFinishReason({\n        finishReason: candidate.finishReason,\n        hasToolCalls: content.some(part => part.type === 'tool-call'),\n      }),\n      usage: {\n        inputTokens: usageMetadata?.promptTokenCount ?? undefined,\n        outputTokens: usageMetadata?.candidatesTokenCount ?? undefined,\n        totalTokens: usageMetadata?.totalTokenCount ?? undefined,\n        reasoningTokens: usageMetadata?.thoughtsTokenCount ?? undefined,\n        cachedInputTokens: usageMetadata?.cachedContentTokenCount ?? undefined,\n      },\n      warnings,\n      providerMetadata: {\n        google: {\n          promptFeedback: response.promptFeedback ?? null,\n          groundingMetadata: candidate.groundingMetadata ?? null,\n          urlContextMetadata: candidate.urlContextMetadata ?? null,\n          safetyRatings: candidate.safetyRatings ?? null,\n          usageMetadata: usageMetadata ?? null,\n        },\n      },\n      request: { body },\n      response: {\n        // TODO timestamp, model id, id\n        headers: responseHeaders,\n        body: rawResponse,\n      },\n    };\n  }\n\n  async doStream(\n    options: Parameters<LanguageModelV2['doStream']>[0],\n  ): Promise<Awaited<ReturnType<LanguageModelV2['doStream']>>> {\n    const { args, warnings } = await this.getArgs(options);\n\n    const body = JSON.stringify(args);\n    const headers = combineHeaders(\n      await resolve(this.config.headers),\n      options.headers,\n    );\n\n    const { responseHeaders, value: response } = await postJsonToApi({\n      url: `${this.config.baseURL}/${getModelPath(\n        this.modelId,\n      )}:streamGenerateContent?alt=sse`,\n      headers,\n      body: args,\n      failedResponseHandler: googleFailedResponseHandler,\n      successfulResponseHandler: createEventSourceResponseHandler(chunkSchema),\n      abortSignal: options.abortSignal,\n      fetch: this.config.fetch,\n    });\n\n    let finishReason: LanguageModelV2FinishReason = 'unknown';\n    const usage: LanguageModelV2Usage = {\n      inputTokens: undefined,\n      outputTokens: undefined,\n      totalTokens: undefined,\n    };\n    let providerMetadata: SharedV2ProviderMetadata | undefined = undefined;\n\n    const generateId = this.config.generateId;\n    let hasToolCalls = false;\n\n    // Track active blocks to group consecutive parts of same type\n    let currentTextBlockId: string | null = null;\n    let currentReasoningBlockId: string | null = null;\n    let blockCounter = 0;\n\n    // Track emitted sources to prevent duplicates\n    const emittedSourceUrls = new Set<string>();\n    // Associates a code execution result with its preceding call.\n    let lastCodeExecutionToolCallId: string | undefined;\n\n    return {\n      stream: response.pipeThrough(\n        new TransformStream<\n          ParseResult<ChunkSchema>,\n          LanguageModelV2StreamPart\n        >({\n          start(controller) {\n            controller.enqueue({ type: 'stream-start', warnings });\n          },\n\n          transform(chunk, controller) {\n            if (options.includeRawChunks) {\n              controller.enqueue({ type: 'raw', rawValue: chunk.rawValue });\n            }\n\n            if (!chunk.success) {\n              controller.enqueue({ type: 'error', error: chunk.error });\n              return;\n            }\n\n            const value = chunk.value;\n\n            const usageMetadata = value.usageMetadata;\n\n            if (usageMetadata != null) {\n              usage.inputTokens = usageMetadata.promptTokenCount ?? undefined;\n              usage.outputTokens =\n                usageMetadata.candidatesTokenCount ?? undefined;\n              usage.totalTokens = usageMetadata.totalTokenCount ?? undefined;\n              usage.reasoningTokens =\n                usageMetadata.thoughtsTokenCount ?? undefined;\n              usage.cachedInputTokens =\n                usageMetadata.cachedContentTokenCount ?? undefined;\n            }\n\n            const candidate = value.candidates?.[0];\n\n            // sometimes the API returns an empty candidates array\n            if (candidate == null) {\n              return;\n            }\n\n            const content = candidate.content;\n\n            const sources = extractSources({\n              groundingMetadata: candidate.groundingMetadata,\n              generateId,\n            });\n            if (sources != null) {\n              for (const source of sources) {\n                if (\n                  source.sourceType === 'url' &&\n                  !emittedSourceUrls.has(source.url)\n                ) {\n                  emittedSourceUrls.add(source.url);\n                  controller.enqueue(source);\n                }\n              }\n            }\n\n            // Process tool call's parts before determining finishReason to ensure hasToolCalls is properly set\n            if (content != null) {\n              // Process text parts individually to handle reasoning parts\n              const parts = content.parts ?? [];\n              for (const part of parts) {\n                if ('executableCode' in part && part.executableCode?.code) {\n                  const toolCallId = generateId();\n                  lastCodeExecutionToolCallId = toolCallId;\n\n                  controller.enqueue({\n                    type: 'tool-call',\n                    toolCallId,\n                    toolName: 'code_execution',\n                    input: JSON.stringify(part.executableCode),\n                    providerExecuted: true,\n                  });\n\n                  hasToolCalls = true;\n                } else if (\n                  'codeExecutionResult' in part &&\n                  part.codeExecutionResult\n                ) {\n                  // Assumes a result directly follows its corresponding call part.\n                  const toolCallId = lastCodeExecutionToolCallId;\n\n                  if (toolCallId) {\n                    controller.enqueue({\n                      type: 'tool-result',\n                      toolCallId,\n                      toolName: 'code_execution',\n                      result: {\n                        outcome: part.codeExecutionResult.outcome,\n                        output: part.codeExecutionResult.output,\n                      },\n                      providerExecuted: true,\n                    });\n                    // Clear the ID after use.\n                    lastCodeExecutionToolCallId = undefined;\n                  }\n                } else if (\n                  'text' in part &&\n                  part.text != null &&\n                  part.text.length > 0\n                ) {\n                  if (part.thought === true) {\n                    // End any active text block before starting reasoning\n                    if (currentTextBlockId !== null) {\n                      controller.enqueue({\n                        type: 'text-end',\n                        id: currentTextBlockId,\n                      });\n                      currentTextBlockId = null;\n                    }\n\n                    // Start new reasoning block if not already active\n                    if (currentReasoningBlockId === null) {\n                      currentReasoningBlockId = String(blockCounter++);\n                      controller.enqueue({\n                        type: 'reasoning-start',\n                        id: currentReasoningBlockId,\n                        providerMetadata: part.thoughtSignature\n                          ? {\n                              google: {\n                                thoughtSignature: part.thoughtSignature,\n                              },\n                            }\n                          : undefined,\n                      });\n                    }\n\n                    controller.enqueue({\n                      type: 'reasoning-delta',\n                      id: currentReasoningBlockId,\n                      delta: part.text,\n                      providerMetadata: part.thoughtSignature\n                        ? {\n                            google: { thoughtSignature: part.thoughtSignature },\n                          }\n                        : undefined,\n                    });\n                  } else {\n                    // End any active reasoning block before starting text\n                    if (currentReasoningBlockId !== null) {\n                      controller.enqueue({\n                        type: 'reasoning-end',\n                        id: currentReasoningBlockId,\n                      });\n                      currentReasoningBlockId = null;\n                    }\n\n                    // Start new text block if not already active\n                    if (currentTextBlockId === null) {\n                      currentTextBlockId = String(blockCounter++);\n                      controller.enqueue({\n                        type: 'text-start',\n                        id: currentTextBlockId,\n                        providerMetadata: part.thoughtSignature\n                          ? {\n                              google: {\n                                thoughtSignature: part.thoughtSignature,\n                              },\n                            }\n                          : undefined,\n                      });\n                    }\n\n                    controller.enqueue({\n                      type: 'text-delta',\n                      id: currentTextBlockId,\n                      delta: part.text,\n                      providerMetadata: part.thoughtSignature\n                        ? {\n                            google: { thoughtSignature: part.thoughtSignature },\n                          }\n                        : undefined,\n                    });\n                  }\n                }\n              }\n\n              const inlineDataParts = getInlineDataParts(content.parts);\n              if (inlineDataParts != null) {\n                for (const part of inlineDataParts) {\n                  controller.enqueue({\n                    type: 'file',\n                    mediaType: part.inlineData.mimeType,\n                    data: part.inlineData.data,\n                  });\n                }\n              }\n\n              const toolCallDeltas = getToolCallsFromParts({\n                parts: content.parts,\n                generateId,\n              });\n\n              if (toolCallDeltas != null) {\n                for (const toolCall of toolCallDeltas) {\n                  controller.enqueue({\n                    type: 'tool-input-start',\n                    id: toolCall.toolCallId,\n                    toolName: toolCall.toolName,\n                    providerMetadata: toolCall.providerMetadata,\n                  });\n\n                  controller.enqueue({\n                    type: 'tool-input-delta',\n                    id: toolCall.toolCallId,\n                    delta: toolCall.args,\n                    providerMetadata: toolCall.providerMetadata,\n                  });\n\n                  controller.enqueue({\n                    type: 'tool-input-end',\n                    id: toolCall.toolCallId,\n                    providerMetadata: toolCall.providerMetadata,\n                  });\n\n                  controller.enqueue({\n                    type: 'tool-call',\n                    toolCallId: toolCall.toolCallId,\n                    toolName: toolCall.toolName,\n                    input: toolCall.args,\n                    providerMetadata: toolCall.providerMetadata,\n                  });\n\n                  hasToolCalls = true;\n                }\n              }\n            }\n\n            if (candidate.finishReason != null) {\n              finishReason = mapGoogleGenerativeAIFinishReason({\n                finishReason: candidate.finishReason,\n                hasToolCalls,\n              });\n\n              providerMetadata = {\n                google: {\n                  promptFeedback: value.promptFeedback ?? null,\n                  groundingMetadata: candidate.groundingMetadata ?? null,\n                  urlContextMetadata: candidate.urlContextMetadata ?? null,\n                  safetyRatings: candidate.safetyRatings ?? null,\n                },\n              };\n              if (usageMetadata != null) {\n                providerMetadata.google.usageMetadata = usageMetadata;\n              }\n            }\n          },\n\n          flush(controller) {\n            // Close any open blocks before finishing\n            if (currentTextBlockId !== null) {\n              controller.enqueue({\n                type: 'text-end',\n                id: currentTextBlockId,\n              });\n            }\n            if (currentReasoningBlockId !== null) {\n              controller.enqueue({\n                type: 'reasoning-end',\n                id: currentReasoningBlockId,\n              });\n            }\n\n            controller.enqueue({\n              type: 'finish',\n              finishReason,\n              usage,\n              providerMetadata,\n            });\n          },\n        }),\n      ),\n      response: { headers: responseHeaders },\n      request: { body },\n    };\n  }\n}\n\nfunction getToolCallsFromParts({\n  parts,\n  generateId,\n}: {\n  parts: ContentSchema['parts'];\n  generateId: () => string;\n}) {\n  const functionCallParts = parts?.filter(\n    part => 'functionCall' in part,\n  ) as Array<\n    GoogleGenerativeAIContentPart & {\n      functionCall: { name: string; args: unknown };\n      thoughtSignature?: string | null;\n    }\n  >;\n\n  return functionCallParts == null || functionCallParts.length === 0\n    ? undefined\n    : functionCallParts.map(part => ({\n        type: 'tool-call' as const,\n        toolCallId: generateId(),\n        toolName: part.functionCall.name,\n        args: JSON.stringify(part.functionCall.args),\n        providerMetadata: part.thoughtSignature\n          ? { google: { thoughtSignature: part.thoughtSignature } }\n          : undefined,\n      }));\n}\n\nfunction getInlineDataParts(parts: ContentSchema['parts']) {\n  return parts?.filter(\n    (\n      part,\n    ): part is {\n      inlineData: { mimeType: string; data: string };\n    } => 'inlineData' in part,\n  );\n}\n\nfunction extractSources({\n  groundingMetadata,\n  generateId,\n}: {\n  groundingMetadata: GroundingMetadataSchema | undefined | null;\n  generateId: () => string;\n}): undefined | LanguageModelV2Source[] {\n  return groundingMetadata?.groundingChunks\n    ?.filter(\n      (\n        chunk,\n      ): chunk is GroundingChunkSchema & {\n        web: { uri: string; title?: string };\n      } => chunk.web != null,\n    )\n    .map(chunk => ({\n      type: 'source',\n      sourceType: 'url',\n      id: generateId(),\n      url: chunk.web.uri,\n      title: chunk.web.title,\n    }));\n}\n\nexport const getGroundingMetadataSchema = () =>\n  z.object({\n    webSearchQueries: z.array(z.string()).nullish(),\n    retrievalQueries: z.array(z.string()).nullish(),\n    searchEntryPoint: z.object({ renderedContent: z.string() }).nullish(),\n    groundingChunks: z\n      .array(\n        z.object({\n          web: z\n            .object({ uri: z.string(), title: z.string().nullish() })\n            .nullish(),\n          retrievedContext: z.union([\n            z\n              .object({ uri: z.string(), title: z.string().nullish() })\n              .nullish(),\n            z.object({\n              title: z.string().nullish(),\n              text: z.string().nullish(),\n            }),\n          ]),\n        }),\n      )\n      .nullish(),\n    groundingSupports: z\n      .array(\n        z.object({\n          segment: z.object({\n            startIndex: z.number().nullish(),\n            endIndex: z.number().nullish(),\n            text: z.string().nullish(),\n          }),\n          segment_text: z.string().nullish(),\n          groundingChunkIndices: z.array(z.number()).nullish(),\n          supportChunkIndices: z.array(z.number()).nullish(),\n          confidenceScores: z.array(z.number()).nullish(),\n          confidenceScore: z.array(z.number()).nullish(),\n        }),\n      )\n      .nullish(),\n    retrievalMetadata: z\n      .union([\n        z.object({\n          webDynamicRetrievalScore: z.number(),\n        }),\n        z.object({}),\n      ])\n      .nullish(),\n  });\n\nconst getContentSchema = () =>\n  z.object({\n    parts: z\n      .array(\n        z.union([\n          // note: order matters since text can be fully empty\n          z.object({\n            functionCall: z.object({\n              name: z.string(),\n              args: z.unknown(),\n            }),\n            thoughtSignature: z.string().nullish(),\n          }),\n          z.object({\n            inlineData: z.object({\n              mimeType: z.string(),\n              data: z.string(),\n            }),\n          }),\n          z.object({\n            executableCode: z\n              .object({\n                language: z.string(),\n                code: z.string(),\n              })\n              .nullish(),\n            codeExecutionResult: z\n              .object({\n                outcome: z.string(),\n                output: z.string(),\n              })\n              .nullish(),\n            text: z.string().nullish(),\n            thought: z.boolean().nullish(),\n            thoughtSignature: z.string().nullish(),\n          }),\n        ]),\n      )\n      .nullish(),\n  });\n\n// https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/configure-safety-filters\nconst getSafetyRatingSchema = () =>\n  z.object({\n    category: z.string().nullish(),\n    probability: z.string().nullish(),\n    probabilityScore: z.number().nullish(),\n    severity: z.string().nullish(),\n    severityScore: z.number().nullish(),\n    blocked: z.boolean().nullish(),\n  });\n\nconst usageSchema = z.object({\n  cachedContentTokenCount: z.number().nullish(),\n  thoughtsTokenCount: z.number().nullish(),\n  promptTokenCount: z.number().nullish(),\n  candidatesTokenCount: z.number().nullish(),\n  totalTokenCount: z.number().nullish(),\n});\n\n// https://ai.google.dev/api/generate-content#UrlRetrievalMetadata\nexport const getUrlContextMetadataSchema = () =>\n  z.object({\n    urlMetadata: z.array(\n      z.object({\n        retrievedUrl: z.string(),\n        urlRetrievalStatus: z.string(),\n      }),\n    ),\n  });\n\nconst responseSchema = lazySchema(() =>\n  zodSchema(\n    z.object({\n      candidates: z.array(\n        z.object({\n          content: getContentSchema().nullish().or(z.object({}).strict()),\n          finishReason: z.string().nullish(),\n          safetyRatings: z.array(getSafetyRatingSchema()).nullish(),\n          groundingMetadata: getGroundingMetadataSchema().nullish(),\n          urlContextMetadata: getUrlContextMetadataSchema().nullish(),\n        }),\n      ),\n      usageMetadata: usageSchema.nullish(),\n      promptFeedback: z\n        .object({\n          blockReason: z.string().nullish(),\n          safetyRatings: z.array(getSafetyRatingSchema()).nullish(),\n        })\n        .nullish(),\n    }),\n  ),\n);\n\ntype ContentSchema = NonNullable<\n  InferValidator<typeof responseSchema>['candidates'][number]['content']\n>;\nexport type GroundingMetadataSchema = NonNullable<\n  InferValidator<\n    typeof responseSchema\n  >['candidates'][number]['groundingMetadata']\n>;\n\ntype GroundingChunkSchema = NonNullable<\n  GroundingMetadataSchema['groundingChunks']\n>[number];\n\nexport type UrlContextMetadataSchema = NonNullable<\n  InferValidator<\n    typeof responseSchema\n  >['candidates'][number]['urlContextMetadata']\n>;\n\nexport type SafetyRatingSchema = NonNullable<\n  InferValidator<typeof responseSchema>['candidates'][number]['safetyRatings']\n>[number];\n\n// limited version of the schema, focussed on what is needed for the implementation\n// this approach limits breakages when the API changes and increases efficiency\nconst chunkSchema = lazySchema(() =>\n  zodSchema(\n    z.object({\n      candidates: z\n        .array(\n          z.object({\n            content: getContentSchema().nullish(),\n            finishReason: z.string().nullish(),\n            safetyRatings: z.array(getSafetyRatingSchema()).nullish(),\n            groundingMetadata: getGroundingMetadataSchema().nullish(),\n            urlContextMetadata: getUrlContextMetadataSchema().nullish(),\n          }),\n        )\n        .nullish(),\n      usageMetadata: usageSchema.nullish(),\n      promptFeedback: z\n        .object({\n          blockReason: z.string().nullish(),\n          safetyRatings: z.array(getSafetyRatingSchema()).nullish(),\n        })\n        .nullish(),\n    }),\n  ),\n);\n\ntype ChunkSchema = InferValidator<typeof chunkSchema>;\n","import { JSONSchema7Definition } from '@ai-sdk/provider';\n\n/**\n * Converts JSON Schema 7 to OpenAPI Schema 3.0\n */\nexport function convertJSONSchemaToOpenAPISchema(\n  jsonSchema: JSONSchema7Definition | undefined,\n): unknown {\n  // parameters need to be undefined if they are empty objects:\n  if (jsonSchema == null || isEmptyObjectSchema(jsonSchema)) {\n    return undefined;\n  }\n\n  if (typeof jsonSchema === 'boolean') {\n    return { type: 'boolean', properties: {} };\n  }\n\n  const {\n    type,\n    description,\n    required,\n    properties,\n    items,\n    allOf,\n    anyOf,\n    oneOf,\n    format,\n    const: constValue,\n    minLength,\n    enum: enumValues,\n  } = jsonSchema;\n\n  const result: Record<string, unknown> = {};\n\n  if (description) result.description = description;\n  if (required) result.required = required;\n  if (format) result.format = format;\n\n  if (constValue !== undefined) {\n    result.enum = [constValue];\n  }\n\n  // Handle type\n  if (type) {\n    if (Array.isArray(type)) {\n      if (type.includes('null')) {\n        result.type = type.filter(t => t !== 'null')[0];\n        result.nullable = true;\n      } else {\n        result.type = type;\n      }\n    } else if (type === 'null') {\n      result.type = 'null';\n    } else {\n      result.type = type;\n    }\n  }\n\n  // Handle enum\n  if (enumValues !== undefined) {\n    result.enum = enumValues;\n  }\n\n  if (properties != null) {\n    result.properties = Object.entries(properties).reduce(\n      (acc, [key, value]) => {\n        acc[key] = convertJSONSchemaToOpenAPISchema(value);\n        return acc;\n      },\n      {} as Record<string, unknown>,\n    );\n  }\n\n  if (items) {\n    result.items = Array.isArray(items)\n      ? items.map(convertJSONSchemaToOpenAPISchema)\n      : convertJSONSchemaToOpenAPISchema(items);\n  }\n\n  if (allOf) {\n    result.allOf = allOf.map(convertJSONSchemaToOpenAPISchema);\n  }\n  if (anyOf) {\n    // Handle cases where anyOf includes a null type\n    if (\n      anyOf.some(\n        schema => typeof schema === 'object' && schema?.type === 'null',\n      )\n    ) {\n      const nonNullSchemas = anyOf.filter(\n        schema => !(typeof schema === 'object' && schema?.type === 'null'),\n      );\n\n      if (nonNullSchemas.length === 1) {\n        // If there's only one non-null schema, convert it and make it nullable\n        const converted = convertJSONSchemaToOpenAPISchema(nonNullSchemas[0]);\n        if (typeof converted === 'object') {\n          result.nullable = true;\n          Object.assign(result, converted);\n        }\n      } else {\n        // If there are multiple non-null schemas, keep them in anyOf\n        result.anyOf = nonNullSchemas.map(convertJSONSchemaToOpenAPISchema);\n        result.nullable = true;\n      }\n    } else {\n      result.anyOf = anyOf.map(convertJSONSchemaToOpenAPISchema);\n    }\n  }\n  if (oneOf) {\n    result.oneOf = oneOf.map(convertJSONSchemaToOpenAPISchema);\n  }\n\n  if (minLength !== undefined) {\n    result.minLength = minLength;\n  }\n\n  return result;\n}\n\nfunction isEmptyObjectSchema(jsonSchema: JSONSchema7Definition): boolean {\n  return (\n    jsonSchema != null &&\n    typeof jsonSchema === 'object' &&\n    jsonSchema.type === 'object' &&\n    (jsonSchema.properties == null ||\n      Object.keys(jsonSchema.properties).length === 0) &&\n    !jsonSchema.additionalProperties\n  );\n}\n","import {\n  LanguageModelV2Prompt,\n  UnsupportedFunctionalityError,\n} from '@ai-sdk/provider';\nimport {\n  GoogleGenerativeAIContent,\n  GoogleGenerativeAIContentPart,\n  GoogleGenerativeAIPrompt,\n} from './google-generative-ai-prompt';\nimport { convertToBase64 } from '@ai-sdk/provider-utils';\n\nexport function convertToGoogleGenerativeAIMessages(\n  prompt: LanguageModelV2Prompt,\n  options?: { isGemmaModel?: boolean },\n): GoogleGenerativeAIPrompt {\n  const systemInstructionParts: Array<{ text: string }> = [];\n  const contents: Array<GoogleGenerativeAIContent> = [];\n  let systemMessagesAllowed = true;\n  const isGemmaModel = options?.isGemmaModel ?? false;\n\n  for (const { role, content } of prompt) {\n    switch (role) {\n      case 'system': {\n        if (!systemMessagesAllowed) {\n          throw new UnsupportedFunctionalityError({\n            functionality:\n              'system messages are only supported at the beginning of the conversation',\n          });\n        }\n\n        systemInstructionParts.push({ text: content });\n        break;\n      }\n\n      case 'user': {\n        systemMessagesAllowed = false;\n\n        const parts: GoogleGenerativeAIContentPart[] = [];\n\n        for (const part of content) {\n          switch (part.type) {\n            case 'text': {\n              parts.push({ text: part.text });\n              break;\n            }\n\n            case 'file': {\n              // default to image/jpeg for unknown image/* types\n              const mediaType =\n                part.mediaType === 'image/*' ? 'image/jpeg' : part.mediaType;\n\n              parts.push(\n                part.data instanceof URL\n                  ? {\n                      fileData: {\n                        mimeType: mediaType,\n                        fileUri: part.data.toString(),\n                      },\n                    }\n                  : {\n                      inlineData: {\n                        mimeType: mediaType,\n                        data: convertToBase64(part.data),\n                      },\n                    },\n              );\n\n              break;\n            }\n          }\n        }\n\n        contents.push({ role: 'user', parts });\n        break;\n      }\n\n      case 'assistant': {\n        systemMessagesAllowed = false;\n\n        contents.push({\n          role: 'model',\n          parts: content\n            .map(part => {\n              switch (part.type) {\n                case 'text': {\n                  return part.text.length === 0\n                    ? undefined\n                    : {\n                        text: part.text,\n                        thoughtSignature:\n                          part.providerOptions?.google?.thoughtSignature,\n                      };\n                }\n\n                case 'reasoning': {\n                  return part.text.length === 0\n                    ? undefined\n                    : {\n                        text: part.text,\n                        thought: true,\n                        thoughtSignature:\n                          part.providerOptions?.google?.thoughtSignature,\n                      };\n                }\n\n                case 'file': {\n                  if (part.mediaType !== 'image/png') {\n                    throw new UnsupportedFunctionalityError({\n                      functionality:\n                        'Only PNG images are supported in assistant messages',\n                    });\n                  }\n\n                  if (part.data instanceof URL) {\n                    throw new UnsupportedFunctionalityError({\n                      functionality:\n                        'File data URLs in assistant messages are not supported',\n                    });\n                  }\n\n                  return {\n                    inlineData: {\n                      mimeType: part.mediaType,\n                      data: convertToBase64(part.data),\n                    },\n                  };\n                }\n\n                case 'tool-call': {\n                  return {\n                    functionCall: {\n                      name: part.toolName,\n                      args: part.input,\n                    },\n                    thoughtSignature:\n                      part.providerOptions?.google?.thoughtSignature,\n                  };\n                }\n              }\n            })\n            .filter(part => part !== undefined),\n        });\n        break;\n      }\n\n      case 'tool': {\n        systemMessagesAllowed = false;\n\n        const parts: GoogleGenerativeAIContentPart[] = [];\n\n        for (const part of content) {\n          const output = part.output;\n\n          if (output.type === 'content') {\n            for (const contentPart of output.value) {\n              switch (contentPart.type) {\n                case 'text':\n                  parts.push({\n                    functionResponse: {\n                      name: part.toolName,\n                      response: {\n                        name: part.toolName,\n                        content: contentPart.text,\n                      },\n                    },\n                  });\n                  break;\n                case 'media':\n                  parts.push(\n                    {\n                      inlineData: {\n                        mimeType: contentPart.mediaType,\n                        data: contentPart.data,\n                      },\n                    },\n                    {\n                      text: 'Tool executed successfully and returned this image as a response',\n                    },\n                  );\n                  break;\n                default:\n                  parts.push({ text: JSON.stringify(contentPart) });\n                  break;\n              }\n            }\n          } else {\n            parts.push({\n              functionResponse: {\n                name: part.toolName,\n                response: {\n                  name: part.toolName,\n                  content: output.value,\n                },\n              },\n            });\n          }\n        }\n\n        contents.push({\n          role: 'user',\n          parts,\n        });\n        break;\n      }\n    }\n  }\n\n  if (\n    isGemmaModel &&\n    systemInstructionParts.length > 0 &&\n    contents.length > 0 &&\n    contents[0].role === 'user'\n  ) {\n    const systemText = systemInstructionParts\n      .map(part => part.text)\n      .join('\\n\\n');\n\n    contents[0].parts.unshift({ text: systemText + '\\n\\n' });\n  }\n\n  return {\n    systemInstruction:\n      systemInstructionParts.length > 0 && !isGemmaModel\n        ? { parts: systemInstructionParts }\n        : undefined,\n    contents,\n  };\n}\n","export function getModelPath(modelId: string): string {\n  return modelId.includes('/') ? modelId : `models/${modelId}`;\n}\n","import {\n  type InferValidator,\n  lazySchema,\n  zodSchema,\n} from '@ai-sdk/provider-utils';\nimport { z } from 'zod/v4';\n\nexport type GoogleGenerativeAIModelId =\n  // Stable models\n  // https://ai.google.dev/gemini-api/docs/models/gemini\n  | 'gemini-1.5-flash'\n  | 'gemini-1.5-flash-latest'\n  | 'gemini-1.5-flash-001'\n  | 'gemini-1.5-flash-002'\n  | 'gemini-1.5-flash-8b'\n  | 'gemini-1.5-flash-8b-latest'\n  | 'gemini-1.5-flash-8b-001'\n  | 'gemini-1.5-pro'\n  | 'gemini-1.5-pro-latest'\n  | 'gemini-1.5-pro-001'\n  | 'gemini-1.5-pro-002'\n  | 'gemini-2.0-flash'\n  | 'gemini-2.0-flash-001'\n  | 'gemini-2.0-flash-live-001'\n  | 'gemini-2.0-flash-lite'\n  | 'gemini-2.0-pro-exp-02-05'\n  | 'gemini-2.0-flash-thinking-exp-01-21'\n  | 'gemini-2.0-flash-exp'\n  | 'gemini-2.5-pro'\n  | 'gemini-2.5-flash'\n  | 'gemini-2.5-flash-image-preview'\n  | 'gemini-2.5-flash-lite'\n  | 'gemini-2.5-flash-lite-preview-09-2025'\n  | 'gemini-2.5-flash-preview-04-17'\n  | 'gemini-2.5-flash-preview-09-2025'\n  // Experimental models\n  // https://ai.google.dev/gemini-api/docs/models/experimental-models\n  | 'gemini-2.5-pro-exp-03-25'\n  | 'gemini-exp-1206'\n  | 'gemma-3-12b-it'\n  | 'gemma-3-27b-it'\n  | (string & {});\n\nexport const googleGenerativeAIProviderOptions = lazySchema(() =>\n  zodSchema(\n    z.object({\n      responseModalities: z.array(z.enum(['TEXT', 'IMAGE'])).optional(),\n\n      thinkingConfig: z\n        .object({\n          thinkingBudget: z.number().optional(),\n          includeThoughts: z.boolean().optional(),\n        })\n        .optional(),\n\n      /**\n       * Optional.\n       * The name of the cached content used as context to serve the prediction.\n       * Format: cachedContents/{cachedContent}\n       */\n      cachedContent: z.string().optional(),\n\n      /**\n       * Optional. Enable structured output. Default is true.\n       *\n       * This is useful when the JSON Schema contains elements that are\n       * not supported by the OpenAPI schema version that\n       * Google Generative AI uses. You can use this to disable\n       * structured outputs if you need to.\n       */\n      structuredOutputs: z.boolean().optional(),\n\n      /**\n       * Optional. A list of unique safety settings for blocking unsafe content.\n       */\n      safetySettings: z\n        .array(\n          z.object({\n            category: z.enum([\n              'HARM_CATEGORY_UNSPECIFIED',\n              'HARM_CATEGORY_HATE_SPEECH',\n              'HARM_CATEGORY_DANGEROUS_CONTENT',\n              'HARM_CATEGORY_HARASSMENT',\n              'HARM_CATEGORY_SEXUALLY_EXPLICIT',\n              'HARM_CATEGORY_CIVIC_INTEGRITY',\n            ]),\n            threshold: z.enum([\n              'HARM_BLOCK_THRESHOLD_UNSPECIFIED',\n              'BLOCK_LOW_AND_ABOVE',\n              'BLOCK_MEDIUM_AND_ABOVE',\n              'BLOCK_ONLY_HIGH',\n              'BLOCK_NONE',\n              'OFF',\n            ]),\n          }),\n        )\n        .optional(),\n\n      threshold: z\n        .enum([\n          'HARM_BLOCK_THRESHOLD_UNSPECIFIED',\n          'BLOCK_LOW_AND_ABOVE',\n          'BLOCK_MEDIUM_AND_ABOVE',\n          'BLOCK_ONLY_HIGH',\n          'BLOCK_NONE',\n          'OFF',\n        ])\n        .optional(),\n\n      /**\n       * Optional. Enables timestamp understanding for audio-only files.\n       *\n       * https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/audio-understanding\n       */\n      audioTimestamp: z.boolean().optional(),\n\n      /**\n       * Optional. Defines labels used in billing reports. Available on Vertex AI only.\n       *\n       * https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/add-labels-to-api-calls\n       */\n      labels: z.record(z.string(), z.string()).optional(),\n\n      /**\n       * Optional. If specified, the media resolution specified will be used.\n       *\n       * https://ai.google.dev/api/generate-content#MediaResolution\n       */\n      mediaResolution: z\n        .enum([\n          'MEDIA_RESOLUTION_UNSPECIFIED',\n          'MEDIA_RESOLUTION_LOW',\n          'MEDIA_RESOLUTION_MEDIUM',\n          'MEDIA_RESOLUTION_HIGH',\n        ])\n        .optional(),\n\n      /**\n       * Optional. Configures the image generation aspect ratio for Gemini models.\n       *\n       * https://ai.google.dev/gemini-api/docs/image-generation#aspect_ratios\n       */\n      imageConfig: z\n        .object({\n          aspectRatio: z\n            .enum([\n              '1:1',\n              '2:3',\n              '3:2',\n              '3:4',\n              '4:3',\n              '4:5',\n              '5:4',\n              '9:16',\n              '16:9',\n              '21:9',\n            ])\n            .optional(),\n        })\n        .optional(),\n    }),\n  ),\n);\n\nexport type GoogleGenerativeAIProviderOptions = InferValidator<\n  typeof googleGenerativeAIProviderOptions\n>;\n","import {\n  LanguageModelV2CallOptions,\n  LanguageModelV2CallWarning,\n  UnsupportedFunctionalityError,\n} from '@ai-sdk/provider';\nimport { convertJSONSchemaToOpenAPISchema } from './convert-json-schema-to-openapi-schema';\nimport { GoogleGenerativeAIModelId } from './google-generative-ai-options';\n\nexport function prepareTools({\n  tools,\n  toolChoice,\n  modelId,\n}: {\n  tools: LanguageModelV2CallOptions['tools'];\n  toolChoice?: LanguageModelV2CallOptions['toolChoice'];\n  modelId: GoogleGenerativeAIModelId;\n}): {\n  tools:\n    | {\n        functionDeclarations: Array<{\n          name: string;\n          description: string;\n          parameters: unknown;\n        }>;\n      }\n    | Record<string, any>\n    | undefined;\n  toolConfig:\n    | undefined\n    | {\n        functionCallingConfig: {\n          mode: 'AUTO' | 'NONE' | 'ANY';\n          allowedFunctionNames?: string[];\n        };\n      };\n  toolWarnings: LanguageModelV2CallWarning[];\n} {\n  // when the tools array is empty, change it to undefined to prevent errors:\n  tools = tools?.length ? tools : undefined;\n\n  const toolWarnings: LanguageModelV2CallWarning[] = [];\n\n  const isGemini2 = modelId.includes('gemini-2');\n  const supportsDynamicRetrieval =\n    modelId.includes('gemini-1.5-flash') && !modelId.includes('-8b');\n  const supportsFileSearch = modelId.includes('gemini-2.5');\n\n  if (tools == null) {\n    return { tools: undefined, toolConfig: undefined, toolWarnings };\n  }\n\n  // Check for mixed tool types and add warnings\n  const hasFunctionTools = tools.some(tool => tool.type === 'function');\n  const hasProviderDefinedTools = tools.some(\n    tool => tool.type === 'provider-defined',\n  );\n\n  if (hasFunctionTools && hasProviderDefinedTools) {\n    toolWarnings.push({\n      type: 'unsupported-tool',\n      tool: tools.find(tool => tool.type === 'function')!,\n      details:\n        'Cannot mix function tools with provider-defined tools in the same request. Please use either function tools or provider-defined tools, but not both.',\n    });\n  }\n\n  if (hasProviderDefinedTools) {\n    const googleTools: any[] = [];\n\n    const providerDefinedTools = tools.filter(\n      tool => tool.type === 'provider-defined',\n    );\n    providerDefinedTools.forEach(tool => {\n      switch (tool.id) {\n        case 'google.google_search':\n          if (isGemini2) {\n            googleTools.push({ googleSearch: {} });\n          } else if (supportsDynamicRetrieval) {\n            // For non-Gemini-2 models that don't support dynamic retrieval, use basic googleSearchRetrieval\n            googleTools.push({\n              googleSearchRetrieval: {\n                dynamicRetrievalConfig: {\n                  mode: tool.args.mode as\n                    | 'MODE_DYNAMIC'\n                    | 'MODE_UNSPECIFIED'\n                    | undefined,\n                  dynamicThreshold: tool.args.dynamicThreshold as\n                    | number\n                    | undefined,\n                },\n              },\n            });\n          } else {\n            googleTools.push({ googleSearchRetrieval: {} });\n          }\n          break;\n        case 'google.url_context':\n          if (isGemini2) {\n            googleTools.push({ urlContext: {} });\n          } else {\n            toolWarnings.push({\n              type: 'unsupported-tool',\n              tool,\n              details:\n                'The URL context tool is not supported with other Gemini models than Gemini 2.',\n            });\n          }\n          break;\n        case 'google.code_execution':\n          if (isGemini2) {\n            googleTools.push({ codeExecution: {} });\n          } else {\n            toolWarnings.push({\n              type: 'unsupported-tool',\n              tool,\n              details:\n                'The code execution tools is not supported with other Gemini models than Gemini 2.',\n            });\n          }\n          break;\n        case 'google.file_search':\n          if (supportsFileSearch) {\n            googleTools.push({ fileSearch: { ...tool.args } });\n          } else {\n            toolWarnings.push({\n              type: 'unsupported-tool',\n              tool,\n              details:\n                'The file search tool is only supported with Gemini 2.5 models.',\n            });\n          }\n          break;\n        default:\n          toolWarnings.push({ type: 'unsupported-tool', tool });\n          break;\n      }\n    });\n\n    return {\n      tools: googleTools.length > 0 ? googleTools : undefined,\n      toolConfig: undefined,\n      toolWarnings,\n    };\n  }\n\n  const functionDeclarations = [];\n  for (const tool of tools) {\n    switch (tool.type) {\n      case 'function':\n        functionDeclarations.push({\n          name: tool.name,\n          description: tool.description ?? '',\n          parameters: convertJSONSchemaToOpenAPISchema(tool.inputSchema),\n        });\n        break;\n      default:\n        toolWarnings.push({ type: 'unsupported-tool', tool });\n        break;\n    }\n  }\n\n  if (toolChoice == null) {\n    return {\n      tools: { functionDeclarations },\n      toolConfig: undefined,\n      toolWarnings,\n    };\n  }\n\n  const type = toolChoice.type;\n\n  switch (type) {\n    case 'auto':\n      return {\n        tools: { functionDeclarations },\n        toolConfig: { functionCallingConfig: { mode: 'AUTO' } },\n        toolWarnings,\n      };\n    case 'none':\n      return {\n        tools: { functionDeclarations },\n        toolConfig: { functionCallingConfig: { mode: 'NONE' } },\n        toolWarnings,\n      };\n    case 'required':\n      return {\n        tools: { functionDeclarations },\n        toolConfig: { functionCallingConfig: { mode: 'ANY' } },\n        toolWarnings,\n      };\n    case 'tool':\n      return {\n        tools: { functionDeclarations },\n        toolConfig: {\n          functionCallingConfig: {\n            mode: 'ANY',\n            allowedFunctionNames: [toolChoice.toolName],\n          },\n        },\n        toolWarnings,\n      };\n    default: {\n      const _exhaustiveCheck: never = type;\n      throw new UnsupportedFunctionalityError({\n        functionality: `tool choice type: ${_exhaustiveCheck}`,\n      });\n    }\n  }\n}\n","import { LanguageModelV2FinishReason } from '@ai-sdk/provider';\n\nexport function mapGoogleGenerativeAIFinishReason({\n  finishReason,\n  hasToolCalls,\n}: {\n  finishReason: string | null | undefined;\n  hasToolCalls: boolean;\n}): LanguageModelV2FinishReason {\n  switch (finishReason) {\n    case 'STOP':\n      return hasToolCalls ? 'tool-calls' : 'stop';\n    case 'MAX_TOKENS':\n      return 'length';\n    case 'IMAGE_SAFETY':\n    case 'RECITATION':\n    case 'SAFETY':\n    case 'BLOCKLIST':\n    case 'PROHIBITED_CONTENT':\n    case 'SPII':\n      return 'content-filter';\n    case 'FINISH_REASON_UNSPECIFIED':\n    case 'OTHER':\n      return 'other';\n    case 'MALFORMED_FUNCTION_CALL':\n      return 'error';\n    default:\n      return 'unknown';\n  }\n}\n","import { createProviderDefinedToolFactoryWithOutputSchema } from '@ai-sdk/provider-utils';\nimport { z } from 'zod/v4';\n\n/**\n * A tool that enables the model to generate and run Python code.\n *\n * @note Ensure the selected model supports Code Execution.\n * Multi-tool usage with the code execution tool is typically compatible with Gemini >=2 models.\n *\n * @see https://ai.google.dev/gemini-api/docs/code-execution (Google AI)\n * @see https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/code-execution-api (Vertex AI)\n */\nexport const codeExecution = createProviderDefinedToolFactoryWithOutputSchema<\n  {\n    language: string;\n    code: string;\n  },\n  {\n    outcome: string;\n    output: string;\n  },\n  {}\n>({\n  id: 'google.code_execution',\n  name: 'code_execution',\n  inputSchema: z.object({\n    language: z.string().describe('The programming language of the code.'),\n    code: z.string().describe('The code to be executed.'),\n  }),\n  outputSchema: z.object({\n    outcome: z\n      .string()\n      .describe('The outcome of the execution (e.g., \"OUTCOME_OK\").'),\n    output: z.string().describe('The output from the code execution.'),\n  }),\n});\n","import {\n  createProviderDefinedToolFactory,\n  lazySchema,\n  zodSchema,\n} from '@ai-sdk/provider-utils';\nimport { z } from 'zod/v4';\n\n/** Tool to retrieve knowledge from the File Search Stores. */\nconst fileSearchArgsBaseSchema = z\n  .object({\n    /** The names of the file_search_stores to retrieve from.\n     *  Example: `fileSearchStores/my-file-search-store-123`\n     */\n    fileSearchStoreNames: z\n      .array(z.string())\n      .describe(\n        'The names of the file_search_stores to retrieve from. Example: `fileSearchStores/my-file-search-store-123`',\n      ),\n    /** The number of file search retrieval chunks to retrieve. */\n    topK: z\n      .number()\n      .int()\n      .positive()\n      .describe('The number of file search retrieval chunks to retrieve.')\n      .optional(),\n\n    /** Metadata filter to apply to the file search retrieval documents.\n     *  See https://google.aip.dev/160 for the syntax of the filter expression.\n     */\n    metadataFilter: z\n      .string()\n      .describe(\n        'Metadata filter to apply to the file search retrieval documents. See https://google.aip.dev/160 for the syntax of the filter expression.',\n      )\n      .optional(),\n  })\n  .passthrough();\n\nexport type GoogleFileSearchToolArgs = z.infer<typeof fileSearchArgsBaseSchema>;\n\nconst fileSearchArgsSchema = lazySchema(() =>\n  zodSchema(fileSearchArgsBaseSchema),\n);\n\nexport const fileSearch = createProviderDefinedToolFactory<\n  {},\n  GoogleFileSearchToolArgs\n>({\n  id: 'google.file_search',\n  name: 'file_search',\n  inputSchema: fileSearchArgsSchema,\n});\n","import {\n  createProviderDefinedToolFactory,\n  lazySchema,\n  zodSchema,\n} from '@ai-sdk/provider-utils';\nimport { z } from 'zod/v4';\n\n// https://ai.google.dev/gemini-api/docs/google-search\n// https://ai.google.dev/api/generate-content#GroundingSupport\n// https://cloud.google.com/vertex-ai/generative-ai/docs/grounding/grounding-with-google-search\n\nexport const googleSearch = createProviderDefinedToolFactory<\n  {},\n  {\n    /**\n     * The mode of the predictor to be used in dynamic retrieval. The following modes are supported:\n     *  - MODE_DYNAMIC: Run retrieval only when system decides it is necessary\n     *  - MODE_UNSPECIFIED: Always trigger retrieval\n     * @default MODE_UNSPECIFIED\n     */\n    mode?: 'MODE_DYNAMIC' | 'MODE_UNSPECIFIED';\n\n    /**\n     * The threshold to be used in dynamic retrieval (if not set, a system default value is used).\n     */\n    dynamicThreshold?: number;\n  }\n>({\n  id: 'google.google_search',\n  name: 'google_search',\n  inputSchema: lazySchema(() =>\n    zodSchema(\n      z.object({\n        mode: z\n          .enum(['MODE_DYNAMIC', 'MODE_UNSPECIFIED'])\n          .default('MODE_UNSPECIFIED'),\n        dynamicThreshold: z.number().default(1),\n      }),\n    ),\n  ),\n});\n","import {\n  createProviderDefinedToolFactory,\n  lazySchema,\n  zodSchema,\n} from '@ai-sdk/provider-utils';\nimport { z } from 'zod/v4';\n\nexport const urlContext = createProviderDefinedToolFactory<\n  {\n    // Url context does not have any input schema, it will directly use the url from the prompt\n  },\n  {}\n>({\n  id: 'google.url_context',\n  name: 'url_context',\n  inputSchema: lazySchema(() => zodSchema(z.object({}))),\n});\n","import { codeExecution } from './tool/code-execution';\nimport { fileSearch } from './tool/file-search';\nimport { googleSearch } from './tool/google-search';\nimport { urlContext } from './tool/url-context';\n\nexport const googleTools = {\n  /**\n   * Creates a Google search tool that gives Google direct access to real-time web content.\n   * Must have name \"google_search\".\n   */\n  googleSearch,\n\n  /**\n   * Creates a URL context tool that gives Google direct access to real-time web content.\n   * Must have name \"url_context\".\n   */\n  urlContext,\n  /**\n   * Enables Retrieval Augmented Generation (RAG) via the Gemini File Search tool.\n   * Must have name \"file_search\".\n   *\n   * @param fileSearchStoreNames - Fully-qualified File Search store resource names.\n   * @param metadataFilter - Optional filter expression to restrict the files that can be retrieved.\n   * @param topK - Optional result limit for the number of chunks returned from File Search.\n   *\n   * @see https://ai.google.dev/gemini-api/docs/file-search\n   */\n  fileSearch,\n  /**\n   * A tool that enables the model to generate and run Python code.\n   * Must have name \"code_execution\".\n   *\n   * @note Ensure the selected model supports Code Execution.\n   * Multi-tool usage with the code execution tool is typically compatible with Gemini >=2 models.\n   *\n   * @see https://ai.google.dev/gemini-api/docs/code-execution (Google AI)\n   * @see https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/code-execution-api (Vertex AI)\n   */\n  codeExecution,\n};\n","import { ImageModelV2, ImageModelV2CallWarning } from '@ai-sdk/provider';\nimport {\n  combineHeaders,\n  createJsonResponseHandler,\n  type InferValidator,\n  lazySchema,\n  parseProviderOptions,\n  postJsonToApi,\n  resolve,\n  zodSchema,\n} from '@ai-sdk/provider-utils';\nimport { z } from 'zod/v4';\nimport { googleFailedResponseHandler } from './google-error';\nimport {\n  GoogleGenerativeAIImageModelId,\n  GoogleGenerativeAIImageSettings,\n} from './google-generative-ai-image-settings';\nimport { FetchFunction, Resolvable } from '@ai-sdk/provider-utils';\n\ninterface GoogleGenerativeAIImageModelConfig {\n  provider: string;\n  baseURL: string;\n  headers?: Resolvable<Record<string, string | undefined>>;\n  fetch?: FetchFunction;\n  generateId?: () => string;\n  _internal?: {\n    currentDate?: () => Date;\n  };\n}\n\nexport class GoogleGenerativeAIImageModel implements ImageModelV2 {\n  readonly specificationVersion = 'v2';\n\n  get maxImagesPerCall(): number {\n    // https://ai.google.dev/gemini-api/docs/imagen#imagen-model\n    return this.settings.maxImagesPerCall ?? 4;\n  }\n\n  get provider(): string {\n    return this.config.provider;\n  }\n\n  constructor(\n    readonly modelId: GoogleGenerativeAIImageModelId,\n    private readonly settings: GoogleGenerativeAIImageSettings,\n    private readonly config: GoogleGenerativeAIImageModelConfig,\n  ) {}\n\n  async doGenerate(\n    options: Parameters<ImageModelV2['doGenerate']>[0],\n  ): Promise<Awaited<ReturnType<ImageModelV2['doGenerate']>>> {\n    const {\n      prompt,\n      n = 1,\n      size = '1024x1024',\n      aspectRatio = '1:1',\n      seed,\n      providerOptions,\n      headers,\n      abortSignal,\n    } = options;\n    const warnings: Array<ImageModelV2CallWarning> = [];\n\n    if (size != null) {\n      warnings.push({\n        type: 'unsupported-setting',\n        setting: 'size',\n        details:\n          'This model does not support the `size` option. Use `aspectRatio` instead.',\n      });\n    }\n\n    if (seed != null) {\n      warnings.push({\n        type: 'unsupported-setting',\n        setting: 'seed',\n        details:\n          'This model does not support the `seed` option through this provider.',\n      });\n    }\n\n    const googleOptions = await parseProviderOptions({\n      provider: 'google',\n      providerOptions,\n      schema: googleImageProviderOptionsSchema,\n    });\n\n    const currentDate = this.config._internal?.currentDate?.() ?? new Date();\n\n    const parameters: Record<string, unknown> = {\n      sampleCount: n,\n    };\n\n    if (aspectRatio != null) {\n      parameters.aspectRatio = aspectRatio;\n    }\n\n    if (googleOptions) {\n      Object.assign(parameters, googleOptions);\n    }\n\n    const body = {\n      instances: [{ prompt }],\n      parameters,\n    };\n\n    const { responseHeaders, value: response } = await postJsonToApi<{\n      predictions: Array<{ bytesBase64Encoded: string }>;\n    }>({\n      url: `${this.config.baseURL}/models/${this.modelId}:predict`,\n      headers: combineHeaders(await resolve(this.config.headers), headers),\n      body,\n      failedResponseHandler: googleFailedResponseHandler,\n      successfulResponseHandler: createJsonResponseHandler(\n        googleImageResponseSchema,\n      ),\n      abortSignal,\n      fetch: this.config.fetch,\n    });\n    return {\n      images: response.predictions.map(\n        (p: { bytesBase64Encoded: string }) => p.bytesBase64Encoded,\n      ),\n      warnings: warnings ?? [],\n      providerMetadata: {\n        google: {\n          images: response.predictions.map(prediction => ({\n            // Add any prediction-specific metadata here\n          })),\n        },\n      },\n      response: {\n        timestamp: currentDate,\n        modelId: this.modelId,\n        headers: responseHeaders,\n      },\n    };\n  }\n}\n\n// minimal version of the schema\nconst googleImageResponseSchema = lazySchema(() =>\n  zodSchema(\n    z.object({\n      predictions: z\n        .array(z.object({ bytesBase64Encoded: z.string() }))\n        .default([]),\n    }),\n  ),\n);\n\n// Note: For the initial GA launch of Imagen 3, safety filters are not configurable.\n// https://ai.google.dev/gemini-api/docs/imagen#imagen-model\nconst googleImageProviderOptionsSchema = lazySchema(() =>\n  zodSchema(\n    z.object({\n      personGeneration: z\n        .enum(['dont_allow', 'allow_adult', 'allow_all'])\n        .nullish(),\n      aspectRatio: z.enum(['1:1', '3:4', '4:3', '9:16', '16:9']).nullish(),\n    }),\n  ),\n);\n\nexport type GoogleGenerativeAIImageProviderOptions = InferValidator<\n  typeof googleImageProviderOptionsSchema\n>;\n"],"names":["generateId","lazySchema","zodSchema","z","responseHeaders","response","rawValue","combineHeaders","createJsonResponseHandler","parseProviderOptions","postJsonToApi","resolve","_a","UnsupportedFunctionalityError","googleTools","createProviderDefinedToolFactory"],"mappings":"uCAMA,IAAA,EAAA,EAAA,CAAA,CAAA,QENA,EAAA,EAAA,CAAA,CAAA,QAcA,EAAkB,EAAA,CAAT,AAAS,CAAA,IAATG,ICNH,EAAA,CAAA,EAAwB,CDMZ,CCNY,UAAA,EAAW,IAAA,CAAA,EACvC,EAAA,SAAA,EACE,EAAA,CAAA,CAAE,MAAA,CAAO,CACP,MAAO,EAAA,CAAA,CAAE,MAAA,CAAO,CACd,KAAM,EAAA,CAAA,CAAE,MAAA,CAAO,EAAE,QAAA,CAAS,EAC1B,QAAS,EAAA,CAAA,CAAE,MAAA,CAAO,EAClB,OAAQ,EAAA,CAAA,CAAE,MAAA,CAAO,CACnB,CAAC,CACH,CAAC,IAMQ,EAAA,CAAA,EAA8B,EAAA,8BAAA,EAA+B,CACxE,YAAa,EACb,eAAgB,GAAQ,EAAK,KAAA,CAAM,OAAA,AACrC,CAAC,ECbY,EAAA,CAAA,EAA6CF,EAAAA,UAAAA,EAAW,IAAA,CAAA,EACnEC,EAAAA,SAAAA,EACEC,EAAAA,CAAAA,CAAE,MAAA,CAAO,CAKP,qBAAsBA,EAAAA,CAAAA,CAAE,MAAA,CAAO,EAAE,QAAA,CAAS,EAc1C,SAAUA,EAAAA,CAAAA,CACP,IAAA,CAAK,CACJ,sBACA,iBACA,aACA,qBACA,kBACA,qBACA,oBACA,uBACD,EACA,QAAA,CAAS,CACd,CAAC,IFjBQ,EAAN,MAEP,AAWE,YACE,CAAA,CACA,CAAA,CACA,CAbF,IAAA,CAAS,oBAAA,CAAuB,KAEhC,IAAA,CAAS,oBAAA,CAAuB,KAChC,IAAA,CAAS,qBAAA,EAAwB,EAW/B,IAAA,CAAK,OAAA,CAAU,EACf,IAAA,CAAK,MAAA,CAAS,CAChB,CATA,IAAI,UAAmB,CACrB,OAAO,IAAA,CAAK,MAAA,CAAO,QAAA,AACrB,CASA,MAAM,QAAQ,QACZ,CAAA,SACA,CAAA,aACA,CAAA,iBACA,CAAA,CACF,CAEE,CAEA,IAAM,EAAgB,MAAA,CAAA,EAAM,EAAA,oBAAA,EAAqB,CAC/C,SAAU,yBACV,EACA,OAAQ,CACV,CAAC,EAED,GAAI,EAAO,MAAA,CAAS,IAAA,CAAK,oBAAA,CACvB,CAD6C,KACvC,IAAI,EAAA,kCAAA,CAAmC,CAC3C,SAAU,IAAA,CAAK,QAAA,CACf,QAAS,IAAA,CAAK,OAAA,CACd,qBAAsB,IAAA,CAAK,oBAAA,QAC3B,CACF,CAAC,EAGH,IAAM,EAAA,CAAA,EAAgB,EAAA,cAAA,EACpB,MAAA,CAAA,EAAM,EAAA,OAAA,EAAQ,IAAA,CAAK,MAAA,CAAO,OAAO,EACjC,GAIF,GAAsB,IAAlB,EAAO,MAAA,CAAc,CACvB,GAAM,CACJ,gBAAAC,CAAAA,CACA,MAAOC,CAAAA,CACP,SAAAC,CAAAA,CACF,CAAI,MAAM,CAAA,EAAA,EAAA,aAAA,EAAc,CACtB,IAAK,CAAA,EAAG,IAAA,CAAK,MAAA,CAAO,OAAO,CAAA,QAAA,EAAW,IAAA,CAAK,OAAO,CAAA,aAAA,CAAA,CAClD,QAAS,EACT,KAAM,CACJ,MAAO,CAAA,OAAA,EAAU,IAAA,CAAK,OAAO,CAAA,CAAA,CAC7B,QAAS,CACP,MAAO,CAAC,CAAE,KAAM,CAAA,CAAO,CAAC,CAAA,AAAE,CAAC,CAAA,AAC7B,EACA,qBAAsB,MAAA,EAAA,KAAA,EAAA,EAAe,oBAAA,CACrC,SAAU,MAAA,EAAA,KAAA,EAAA,EAAe,QAAA,AAC3B,EACA,sBAAuB,EACvB,0BAAA,CAAA,EAA2B,EAAA,yBAAA,EACzB,eAEF,EACA,MAAO,IAAA,CAAK,MAAA,CAAO,KACrB,AADqB,CACpB,EAED,MAAO,CACL,WAAY,CAACD,EAAS,SAAA,CAAU,MAAM,CAAA,CACtC,MAAO,KAAA,EACP,SAAU,CAAE,QAASD,EAAiB,KAAME,CAAS,CACvD,CACF,CAEA,GAAM,iBACJ,CAAA,CACA,MAAO,CAAA,UACP,CAAA,CACF,CAAI,MAAA,CAAA,EAAM,EAAA,aAAA,EAAc,CACtB,IAAK,CAAA,EAAG,IAAA,CAAK,MAAA,CAAO,OAAO,CAAA,QAAA,EAAW,IAAA,CAAK,OAAO,CAAA,mBAAA,CAAA,CAClD,QAAS,EACT,KAAM,CACJ,SAAU,EAAO,GAAA,CAAI,IAAU,CAC7B,GADmB,GACZ,CAAA,OAAA,EAAU,IAAA,CAAK,OAAO,CAAA,CAAA,CAC7B,QAAS,CAAE,KAAM,OAAQ,MAAO,CAAC,CAAE,KAAM,CAAM,CAAC,CAAE,AAAF,EAChD,qBAAsB,MAAA,EAAA,KAAA,EAAA,EAAe,oBAAA,CACrC,SAAU,MAAA,EAAA,KAAA,EAAA,EAAe,QAAA,CAC3B,CAAA,CAAE,AACJ,EACA,sBAAuB,EACvB,0BAAA,CAAA,EAA2B,EAAA,yBAAA,EACzB,eAEF,EACA,MAAO,IAAA,CAAK,MAAA,CAAO,KAAA,AACrB,CAAC,EAED,MAAO,CACL,WAAY,EAAS,UAAA,CAAW,GAAA,CAAI,GAAQ,EAAK,MAAM,EACvD,MAAO,KAAA,EACP,SAAU,CAAE,QAAS,EAAiB,KAAM,CAAS,CACvD,CACF,CACF,EAIM,EAAA,CAAA,EAAgDL,EAAAA,UAAAA,EAAW,IAAA,CAAA,EAC/DC,EAAAA,SAAAA,EACEC,EAAAA,CAAAA,CAAE,MAAA,CAAO,CACP,WAAYA,EAAAA,CAAAA,CAAE,KAAA,CAAMA,EAAAA,CAAAA,CAAE,MAAA,CAAO,CAAE,OAAQA,EAAAA,CAAAA,CAAE,KAAA,CAAMA,EAAAA,CAAAA,CAAE,MAAA,CAAO,CAAC,CAAE,CAAC,CAAC,CAC/D,CAAC,IAKC,EAAA,CAAA,EAAkDF,EAAAA,UAAAA,EAAW,IAAA,CAAA,EACjEC,EAAAA,SAAAA,EACEC,EAAAA,CAAAA,CAAE,MAAA,CAAO,CACP,UAAWA,EAAAA,CAAAA,CAAE,MAAA,CAAO,CAAE,OAAQA,EAAAA,CAAAA,CAAE,KAAA,CAAMA,EAAAA,CAAAA,CAAE,MAAA,CAAO,CAAC,CAAE,CAAC,CACrD,CAAC,IIvJE,SAAS,EACd,CAAA,EACS,IAiHkB,EA/G3B,GAAkB,KA+GS,CA/GvB,CA+GmE,CA/G7C,CAiHxB,AAAc,SAjH8B,IAkHtB,MAlHgC,GAAG,CAkHzD,OAAO,GACP,AAAoB,YAAA,CAAT,IAAA,GACe,MAAzB,EAAW,UAAA,EACV,WAAO,IAAA,CAAK,EAAW,UAAU,EAAE,MAAA,AAAW,CAAA,EAChD,CAAC,EAAW,oBAAA,CArHZ,OAAO,AAGT,GAAI,AAAsB,EAHjB,SAG4B,OAA1B,EACT,MAAO,CAAE,KAAM,UAAW,WAAY,CAAC,CAAE,EAG3C,GAAM,MACJ,CAAA,aACA,CAAA,UACA,CAAA,CACA,YAAA,OACA,CAAA,OACA,CAAA,OACA,CAAA,OACA,CAAA,QACA,CAAA,CACA,MAAO,CAAA,WACP,CAAA,CACA,KAAM,CAAA,CACR,CAAI,EAEE,EAAkC,CAAC,EAkDzC,GAhDI,IAAa,EAAO,MAAP,KAAO,CAAc,CAAA,EAClC,GAAU,GAAO,GAAP,KAAO,CAAW,CAAA,EAC5B,IAAQ,EAAO,CAAP,KAAO,CAAS,CAAA,EAET,KAAA,GAAW,CAA1B,IACF,EAAO,IAAA,CAAO,CAAC,EAAU,EAIvB,IACE,EALqB,AAIjB,IACE,OAAA,CAAQ,GACZ,CADgB,CACX,EADc,MACd,CAAS,MAAM,GAAG,AACzB,EAAO,IAAA,CAAO,EAAK,MAAA,CAAO,GAAW,MAAM,GAAZ,EAAY,CAAE,CAAC,CAAA,CAC9C,EAAO,QAAA,EAAW,GAElB,EAAO,IAAA,CAAO,EAEP,AAAS,QAAQ,GAC1B,EAAO,IAAA,CAAO,OAEd,EAAO,IAAA,CAAO,GAKC,KAAA,GAAW,CAA1B,IACF,EAAO,IAAA,CAAO,CAAA,EAGE,MAAM,AAApB,IACF,EAAO,UAAA,CAAa,OAAO,OAAA,CAAQ,GAAY,MAAA,CAAF,AAC3C,CAAC,EAAK,CAAC,EAAK,EAAK,GAAA,CACf,CADqB,AACrB,CAAI,EAAG,CAAA,AAAI,EAAiC,GACrC,EAD0C,CAGnD,CAAC,EAAA,EAID,IACF,EAAO,CADE,IACF,CAAQ,MAAM,OAAA,CAAQ,GACzB,EAD8B,AACxB,GAAA,CAAI,GACV,EAAiC,EAAK,EAGxC,IACF,EAAO,CADE,IACF,CAAQ,EAAM,GAAA,CAAI,EAAgC,EAEvD,CAP4C,CAS9C,GACE,EAHO,AAGD,IAAA,CACJ,GAA4B,UAAlB,OAAO,GAAW,CAAY,MAAA,EAAA,KAAA,EAAA,EAAQ,IAAA,IAAS,QAE3D,CACA,IAAM,EAAiB,EAAM,MAAA,CAC3B,GAA8B,MAApB,CAAA,GAAE,OAAO,GAAW,CAAY,MAAA,EAAA,KAAA,EAAA,EAAQ,IAAA,IAAS,MAAA,EAG7D,GAA8B,IAA1B,EAAe,MAAA,CAAc,CAE/B,IAAM,EAAY,EAAiC,CAAA,CAAe,CAAC,CAAC,EAC3C,UAArB,AAA+B,OAAxB,IACT,EAAO,QAAA,EAAW,EAClB,OAAO,MAAA,CAAO,EAAQ,GAE1B,MAEE,AAJiC,CAE5B,CAEE,KAAA,CAAQ,EAAe,GAAA,CAAI,GAClC,EAAO,QAAA,EAAW,CAEtB,MACE,CADK,CACE,KAAA,CAAQ,EAJqD,AAI/C,GAAA,CAAI,GAW7B,OARI,IACF,EAAO,CADE,IACF,CAAQ,EAAM,GAAA,CAAI,EAAgC,EAJE,AAO3C,KAAA,GAAW,CAAzB,IACF,EAAO,SAAA,CAAY,CAAA,EAGd,CACT,CEtHO,SAAS,EAAa,CAAA,EAAyB,AACpD,OAAO,EAAQ,QAAA,CAAS,GAAG,EAAI,EAAU,CAAA,OAAA,EAAU,EAAO,CAAA,AAC5D,CCyCO,GD1CqD,CC0C/C,EAAA,CAAA,EAAoCF,EAAAA,UAAAA,EAAW,IAAA,CAAA,EAC1DC,EAAAA,SAAAA,EACEC,EAAAA,CAAAA,CAAE,MAAA,CAAO,CACP,mBAAoBA,EAAAA,CAAAA,CAAE,KAAA,CAAMA,EAAAA,CAAAA,CAAE,IAAA,CAAK,CAAC,OAAQ,OAAO,CAAC,CAAC,EAAE,QAAA,CAAS,EAEhE,eAAgBA,EAAAA,CAAAA,CACb,MAAA,CAAO,CACN,eAAgBA,EAAAA,CAAAA,CAAE,MAAA,CAAO,EAAE,QAAA,CAAS,EACpC,gBAAiBA,EAAAA,CAAAA,CAAE,OAAA,CAAQ,EAAE,QAAA,CAAS,CACxC,CAAC,EACA,QAAA,CAAS,EAOZ,cAAeA,EAAAA,CAAAA,CAAE,MAAA,CAAO,EAAE,QAAA,CAAS,EAUnC,kBAAmBA,EAAAA,CAAAA,CAAE,OAAA,CAAQ,EAAE,QAAA,CAAS,EAKxC,eAAgBA,EAAAA,CAAAA,CACb,KAAA,CACCA,EAAAA,CAAAA,CAAE,MAAA,CAAO,CACP,SAAUA,EAAAA,CAAAA,CAAE,IAAA,CAAK,CACf,4BACA,4BACA,kCACA,2BACA,kCACA,gCACD,EACD,UAAWA,EAAAA,CAAAA,CAAE,IAAA,CAAK,CAChB,mCACA,sBACA,yBACA,kBACA,aACA,MACD,CACH,CAAC,GAEF,QAAA,CAAS,EAEZ,UAAWA,EAAAA,CAAAA,CACR,IAAA,CAAK,CACJ,mCACA,sBACA,yBACA,kBACA,aACA,MACD,EACA,QAAA,CAAS,EAOZ,eAAgBA,EAAAA,CAAAA,CAAE,OAAA,CAAQ,EAAE,QAAA,CAAS,EAOrC,OAAQA,EAAAA,CAAAA,CAAE,MAAA,CAAOA,EAAAA,CAAAA,CAAE,MAAA,CAAO,EAAGA,EAAAA,CAAAA,CAAE,MAAA,CAAO,CAAC,EAAE,QAAA,CAAS,EAOlD,gBAAiBA,EAAAA,CAAAA,CACd,IAAA,CAAK,CACJ,+BACA,uBACA,0BACA,wBACD,EACA,QAAA,CAAS,EAOZ,YAAaA,EAAAA,CAAAA,CACV,MAAA,CAAO,CACN,YAAaA,EAAAA,CAAAA,CACV,IAAA,CAAK,CACJ,MACA,MACA,MACA,MACA,MACA,MACA,MACA,OACA,OACA,OACD,EACA,QAAA,CAAS,CACd,CAAC,EACA,QAAA,CAAS,CACd,CAAC,IE9JE,SAAS,EAAkC,cAChD,CAAA,cACA,CAAA,CACF,EAGgC,AAC9B,OAAQ,GACN,IAAK,OADe,AAElB,OAAO,EAAe,aAAe,MACvC,KAAK,aACH,MAAO,QACT,KAAK,eACL,IAAK,aACL,IAAK,SACL,IAAK,YACL,IAAK,qBACL,IAAK,OACH,MAAO,gBACT,KAAK,4BACL,IAAK,QACH,MAAO,OACT,KAAK,0BACH,MAAO,OACT,SACE,MAAO,SACX,CACF,CNsBO,IAAM,EAAN,MAAiE,AAQtE,YACE,CAAA,CACA,CAAA,CACA,KA9DJ,EAoDE,IAAA,CAAS,oBAAA,CAAuB,KAW9B,IAAA,CAAK,OAAA,CAAU,EACf,IAAA,CAAK,MAAA,CAAS,EACd,IAAA,CAAK,UAAA,CAAA,AAAa,OAAA,EAAA,EAAO,UAAA,EAAP,EAAqB,EAAA,UACzC,AADyC,CAGzC,IAAI,UAAmB,CACrB,OAAO,IAAA,CAAK,MAAA,CAAO,QAAA,AACrB,CAEA,IAAI,eAAgB,CAxEtB,IAAA,EAAA,EAAA,EAyEI,OAAA,AAAO,OAAA,EAAA,MAAA,GAAA,CAAA,EAAA,IAAA,CAAK,MAAA,EAAO,aAAA,EAAZ,KAAA,EAAA,EAAA,IAAA,CAAA,EAAA,CAAA,CAAA,EAAiC,CAAC,CAC3C,CAEA,MAAc,QAAQ,QACpB,CAAA,iBACA,CAAA,aACA,CAAA,MACA,CAAA,MACA,CAAA,kBACA,CAAA,CACA,iBAAA,eACA,CAAA,gBACA,CAAA,MACA,CAAA,OACA,CAAA,YACA,CAAA,iBACA,CAAA,CACF,CAAiD,CA1FnD,IAAA,EAAA,EA2FI,IAAM,EAAyC,CAAC,CAAA,CAE1C,EAAgB,MAAA,CAAA,EAAMM,EAAAA,oBAAAA,EAAqB,CAC/C,SAAU,yBACV,EACA,OAAQ,CACV,CAAC,CAGD,EAAA,AACE,OAAA,EAAA,QAAA,KAAA,EAAA,EAAe,cAAA,EAAf,KAAA,EAAA,EAA+B,eAAA,KAAoB,GAClD,IAAA,CAAD,AAAM,MAAA,CAAO,QAAA,CAAS,UAAA,CAAW,gBAAgB,GACjD,AACA,EAAS,IAAA,CAAK,CACZ,KAAM,QACN,QACE,CAAA,yKAAA,EAEI,IAAA,CAAK,MAAA,CAAO,QAAQ,CAAA,EAAA,CAAA,AAC5B,CAAC,EAGH,IAAM,EAAe,IAAA,CAAK,OAAA,CAAQ,WAAA,CAAY,EAAE,UAAA,CAAW,QAAQ,EAE7D,UAAE,CAAA,mBAAU,CAAA,CAAkB,CAAI,AExGrC,SAAS,AACd,CAAA,CACA,CAAA,EAC0B,AAd5B,IAAA,EAeE,IAAM,EAAkD,CAAC,CAAA,CACnD,EAA6C,CAAC,CAAA,CAChD,EAAwB,GACtB,EAAA,AAAe,OAAA,EAAA,MAAA,EAAA,KAAA,EAAA,EAAS,YAAA,GAAT,EAErB,GAF8C,CAE9C,GAAW,MAAE,CAAA,SAAM,CAAA,CAAQ,GAAK,EAC9B,KADsC,EAC9B,GACN,GADY,CACP,SACH,GAAI,CAAC,EACH,MAAM,IAAI,EAAA,SADgB,oBAChB,CAA8B,CACtC,cACE,yEACJ,CAAC,EAGH,EAAuB,IAAA,CAAK,CAAE,KAAM,CAAQ,CAAC,EAC7C,KAGF,KAAK,OAAQ,CACX,GAAwB,EAExB,IAAM,EAAyC,CAAC,CAAA,CAEhD,IAAA,IAAW,KAAQ,EACjB,MAD0B,CAClB,EAAK,IAAA,EAAM,AACjB,IAAK,OACH,EAAM,IAAA,CAAK,CAAE,KAAM,EAAK,IAAA,AAAK,CAAC,EAC9B,KAGF,KAAK,OAAQ,CAEX,IAAM,EACe,YAAnB,EAAK,SAAA,CAA0B,aAAe,EAAK,SAAA,CAErD,EAAM,IAAA,CACJ,EAAK,IAAA,YAAgB,IACjB,CACE,SAAU,CACR,SAAU,EACV,QAAS,EAAK,IAAA,CAAK,QAAA,CAAS,CAC9B,CACF,EACA,CACE,WAAY,CACV,SAAU,EACV,KAAA,CAAA,EAAM,EAAA,eAAA,EAAgB,EAAK,IAAI,CACjC,CACF,EAIR,CACF,CAGF,EAAS,IAAA,CAAK,CAAE,KAAM,aAAQ,CAAM,CAAC,EACrC,KACF,CAEA,IAAK,YACH,GAAwB,EAExB,EAAS,IAAA,CAAK,CACZ,KAAM,QACN,MAAO,EACJ,GAAA,CAAI,IAlFjB,IAAAG,CAkFyB,CAlFzB,EAAA,EAAA,EAAA,EAAA,EAmFc,OAAQ,EAAK,IAAA,EAAM,AACjB,IAAK,OACH,OAA4B,IAArB,EAAK,IAAA,CAAK,MAAA,CACb,KAAA,EACA,CACE,KAAM,EAAK,IAAA,CACX,iBAAA,AACE,OAAA,EAAA,OAAAA,EAAA,EAAK,eAAA,EAAL,KAAA,EAAAA,EAAsB,MAAA,EAAtB,KAAA,EAAA,EAA8B,gBAAA,AAClC,CAGN,KAAK,YACH,OAA4B,IAArB,EAAK,IAAA,CAAK,MAAA,CACb,KAAA,EACA,CACE,KAAM,EAAK,IAAA,CACX,SAAS,EACT,iBACE,AADF,OACE,EAAA,OAAA,EAAA,EAAK,eAAA,EAAL,KAAA,EAAA,EAAsB,MAAA,EAAtB,KAAA,EAAA,EAA8B,gBAAA,AAClC,CAGN,KAAK,OACH,GAAuB,aAAa,CAAhC,EAAK,SAAA,CACP,MAAM,IAAI,EAAA,6BAAA,CAA8B,CACtC,cACE,qDACJ,CAAC,EAGH,GAAI,EAAK,IAAA,YAAgB,IACvB,CAD4B,KACtB,IAAI,EAAA,6BAAA,CAA8B,CACtC,cACE,wDACJ,CAAC,EAGH,MAAO,CACL,WAAY,CACV,SAAU,EAAK,SAAA,CACf,KAAA,CAAA,EAAM,EAAA,eAAA,EAAgB,EAAK,IAAI,CACjC,CACF,CAGF,KAAK,YACH,MAAO,CACL,aAAc,CACZ,KAAM,EAAK,QAAA,CACX,KAAM,EAAK,KAAA,AACb,EACA,iBAAA,AACE,OAAA,EAAA,OAAA,EAAA,EAAK,eAAA,EAAL,KAAA,EAAA,EAAsB,MAAA,EAAtB,KAAA,EAAA,EAA8B,gBAAA,AAClC,CAEJ,CACF,CAAC,EACA,MAAA,CAAO,GAAiB,KAAA,CAAS,GAAlB,EACpB,CAAC,EACD,KAGF,KAAK,OAAQ,CACX,GAAwB,EAExB,IAAM,EAAyC,CAAC,CAAA,CAEhD,IAAA,IAAW,KAAQ,EAAS,CAC1B,IAAM,EAAS,EAAK,MAAA,CAEpB,GAAoB,WAAW,CAA3B,EAAO,IAAA,CACT,IAAA,IAAW,KAAe,EAAO,KAAA,CAAO,AACtC,OAAQ,EAAY,IAAA,EAAM,AACxB,IAAK,OACH,EAAM,IAAA,CAAK,CACT,iBAAkB,CAChB,KAAM,EAAK,QAAA,CACX,SAAU,CACR,KAAM,EAAK,QAAA,CACX,QAAS,EAAY,IAAA,AACvB,CACF,CACF,CAAC,EACD,KACF,KAAK,QACH,EAAM,IAAA,CACJ,CACE,WAAY,CACV,SAAU,EAAY,SAAA,CACtB,KAAM,EAAY,IAAA,AACpB,CACF,EACA,CACE,KAAM,kEACR,GAEF,KACF,SACE,EAAM,IAAA,CAAK,CAAE,KAAM,KAAK,SAAA,CAAU,EAAa,CAAC,CAEpD,MAGF,CALmD,CAK7C,IAAA,CAAK,CACT,iBAAkB,CAChB,KAAM,EAAK,QAAA,CACX,SAAU,CACR,KAAM,EAAK,QAAA,CACX,QAAS,EAAO,KAAA,AAClB,CACF,CACF,CAAC,CAEL,CAEA,EAAS,IAAA,CAAK,CACZ,KAAM,aACN,CACF,CAAC,CAEH,CACF,CAGF,GACE,GACA,EAAuB,MAAA,CAAS,GAChC,EAAS,MAAA,CAAS,GACG,AAArB,UAAA,CAAS,CAAC,CAAA,CAAE,IAAA,CACZ,CACA,IAAM,EAAa,EAChB,GAAA,CAAI,GAAQ,EAAK,IAAI,EACrB,IAAA,CAAK,MAAM,EAEd,CAAA,CAAS,CAAC,CAAA,CAAE,KAAA,CAAM,OAAA,CAAQ,CAAE,KAAM,EAAa,MAAO,CAAC,CACzD,CAEA,MAAO,CACL,kBACE,EAAuB,MAAA,CAAS,GAAK,CAAC,EAClC,CAAE,MAAO,CAAuB,EAChC,KAAA,WACN,CACF,CACF,EF/GM,EACA,cAAE,CAAa,GAGX,CACJ,MAAOE,CAAAA,CACP,WAAY,CAAA,cACZ,CAAA,CACF,CAAI,AKpHD,SAAsB,AAAb,OACd,CAAA,YACA,CAAA,SACA,CAAA,CACF,EAwBE,AApCF,IAAA,EAsCE,EAAA,CAAQ,QAAA,KAAA,EAAA,EAAO,MAAA,EAAS,EAAQ,KAAA,EAEhC,IAAM,EAA6C,CAAC,CAAA,CAE9C,EAAY,EAAQ,QAAA,CAAS,UAAU,EACvC,EACJ,EAAQ,QAAA,CAAS,kBAAkB,GAAK,CAAC,EAAQ,QAAA,CAAS,KAAK,EAC3D,EAAqB,EAAQ,QAAA,CAAS,YAAY,EAExD,GAAa,MAAT,AAAe,EACjB,MAAO,CAAE,MAAO,KAAA,EAAW,WAAY,KAAA,eAAW,CAAa,EAIjE,IAAM,EAAmB,EAAM,IAAA,CAAK,GAAsB,UAAU,GAAxB,EAAK,IAAA,EAC3C,EAA0B,EAAM,IAAA,CACpC,GAAsB,AAAd,uBAAK,IAAA,EAYf,GATI,GAAoB,GACtB,EAAa,IAAA,CAAK,CAChB,KAAM,SAFuC,UAG7C,KAAM,EAAM,IAAA,CAAK,GAAsB,UAAU,GAAxB,EAAK,IAAA,EAC9B,QACE,sJACJ,CAAC,EAGC,EAAyB,CAC3B,IAAMA,EAAqB,CAAC,CAAA,CAuE5B,OArE6B,AAG7B,EAHmC,MAAA,CACjC,GAAsB,qBAAd,EAAK,IAAA,EAEM,OAAA,CAAQ,IAC3B,KADmC,EAC3B,EAAK,EAAA,EACX,AADe,IACV,uBACC,EACFA,EAAY,IAAA,CAAK,CAAE,CADN,YACoB,CAAC,CAAE,CAAC,EAC5B,EAETA,EAAY,IAAA,CAAK,CACf,gBAHiC,MAGV,CACrB,uBAAwB,CACtB,KAAM,EAAK,IAAA,CAAK,IAAA,CAIhB,iBAAkB,EAAK,IAAA,CAAK,gBAG9B,AAH8B,CAIhC,CACF,CAAC,EAEDA,EAAY,IAAA,CAAK,CAAE,sBAAuB,CAAC,CAAE,CAAC,EAEhD,KACF,KAAK,qBACC,EACFA,EAAY,IAAA,CAAK,CAAE,CADN,UACkB,CAAC,CAAE,CAAC,EAEnC,EAAa,IAAA,CAAK,CAChB,KAAM,wBACN,EACA,QACE,+EACJ,CAAC,EAEH,KACF,KAAK,wBACC,EACFA,EAAY,IAAA,CAAK,CAAE,CADN,aACqB,CAAC,CAAE,CAAC,EAEtC,EAAa,IAAA,CAAK,CAChB,KAAM,wBACN,EACA,QACE,mFACJ,CAAC,EAEH,KACF,KAAK,qBACC,EACFA,EAAY,IAAA,CAAK,CAAE,UADG,CACS,CAAE,GAAG,EAAK,IAAA,AAAK,CAAE,CAAC,EAEjD,EAAa,IAAA,CAAK,CAChB,KAAM,wBACN,EACA,QACE,gEACJ,CAAC,EAEH,KACF,SACE,EAAa,IAAA,CAAK,CAAE,KAAM,wBAAoB,CAAK,CAAC,CAExD,CACF,CAAC,EAEM,CACL,MAAOA,EAAY,MAAA,CAAS,EAAIA,EAAc,KAAA,EAC9C,WAAY,KAAA,eACZ,CACF,CACF,CAEA,IAAM,EAAuB,CAAC,CAAA,CAC9B,IAAA,IAAW,KAAQ,EAEV,IAFiB,SAChB,EAAK,IAAA,CAET,CAFe,CAEM,IAAA,CAAK,CACxB,KAAM,EAAK,IAAA,CACX,YAAA,AAAa,OAAA,EAAA,EAAK,WAAA,EAAL,EAAoB,GACjC,WAAY,EAAiC,EAAK,WAAW,CAC/D,CAAC,EAGD,EAAa,IAAA,CAAK,CAAE,KAAM,wBAAoB,CAAK,CAAC,EAK1D,GAAkB,MAAd,AAAoB,EACtB,MAAO,CACL,MAAO,CAAE,sBAAqB,EAC9B,WAAY,KAAA,eACZ,CACF,EAGF,IAAM,EAAO,EAAW,IAAA,CAExB,OAAQ,GACN,GADY,CACP,OACH,MAAO,CACL,MAAO,sBAAE,CAAqB,EAC9B,WAAY,CAAE,sBAAuB,CAAE,KAAM,MAAO,CAAE,eACtD,CACF,CACF,KAAK,OACH,MAAO,CACL,MAAO,CAAE,sBAAqB,EAC9B,WAAY,CAAE,sBAAuB,CAAE,KAAM,MAAO,CAAE,eACtD,CACF,CACF,KAAK,WACH,MAAO,CACL,MAAO,sBAAE,CAAqB,EAC9B,WAAY,CAAE,sBAAuB,CAAE,KAAM,KAAM,CAAE,eACrD,CACF,CACF,KAAK,OACH,MAAO,CACL,MAAO,sBAAE,CAAqB,EAC9B,WAAY,CACV,sBAAuB,CACrB,KAAM,MACN,qBAAsB,CAAC,EAAW,QAAQ,CAAA,AAC5C,CACF,eACA,CACF,CACF,SAEE,MAAM,IAAID,EAAAA,6BAAAA,CAA8B,CACtC,cAAe,CAAA,kBAAA,EAAqB,AAFN,EAEsB,CAAA,AACtD,CAAC,CAEL,CACF,ELpFqB,OACf,CK+EsD,YL9EtD,EACA,QAAS,IAAA,CAAK,OAAA,AAChB,CAAC,EAED,MAAO,CACL,KAAM,CACJ,iBAAkB,iBAEhB,cACA,OACA,OACA,mBACA,kBACA,EACA,gBACA,OAGA,iBAAA,CACE,MAAA,EAAA,KAAA,EAAA,EAAgB,IAAA,IAAS,OAAS,mBAAqB,KAAA,EACzD,eAAA,CACE,MAAA,EAAA,KAAA,EAAA,EAAgB,IAAA,IAAS,QACA,AAAzB,QAAyB,AAAV,MAAA,EAAU,CAIxB,OAAA,EAAA,MAAA,EAAA,KAAA,EAAA,EAAe,iBAAA,GAAf,CAAoC,CAAA,CACjC,EAAiC,AADA,CAJZ,CAK2B,MAAM,EACtD,KAAA,EACN,GAAA,CAAI,MAAA,EAAA,KAAA,EAAA,EAAe,cAAA,GAAkB,CACnC,eAAgB,EAAc,cAAA,AAChC,CAAA,CAGA,mBAAoB,MAAA,EAAA,KAAA,EAAA,EAAe,kBAAA,CACnC,eAAgB,QAAA,KAAA,EAAA,EAAe,cAAA,CAC/B,GAAA,CAAI,MAAA,EAAA,KAAA,EAAA,EAAe,WAAA,GAAe,CAChC,YAAa,EAAc,WAAA,AAC7B,CAAA,CACA,GAAA,CAAI,MAAA,EAAA,KAAA,EAAA,EAAe,eAAA,GAAmB,CACpC,gBAAiB,EAAc,eAAA,AACjC,CAAA,AACF,WACA,EACA,kBAAmB,EAAe,KAAA,EAAY,EAC9C,eAAgB,MAAA,EAAA,KAAA,EAAA,EAAe,cAAA,CAC/B,MAAOC,EACP,WAAY,EACZ,cAAe,MAAA,EAAA,KAAA,EAAA,EAAe,aAAA,CAC9B,OAAQ,QAAA,KAAA,EAAA,EAAe,MAAA,AACzB,EACA,SAAU,CAAC,GAAG,KAAa,EAAY,AACzC,CACF,CAEA,CAJ4B,KAItB,EAJqC,SAKzC,CAAA,CAC6D,KAvLjE,EAAA,EAAA,EAAA,EAAA,EAAA,EAAA,EAAA,EAAA,EAAA,EAAA,EAAA,EAAA,MAyNQ,EAjCE,MAAE,CAAA,UAAM,CAAA,CAAS,CAAI,MAAM,IAAA,CAAK,OAAA,CAAQ,GACxC,EAAO,EADwC,GACnC,SAAA,CAAU,GAEtB,CAF0B,CAE1B,CAAA,EAAgBP,EAAAA,cAAAA,EACpB,MAAMI,CAAAA,EAAAA,EAAAA,OAAAA,EAAQ,IAAA,CAAK,MAAA,CAAO,OAAO,EACjC,EAAQ,OAAA,EAGJ,iBACJ,CAAA,CACA,MAAO,CAAA,CACP,SAAU,CAAA,CACZ,CAAI,MAAA,CAAA,EAAMD,EAAAA,aAAAA,EAAc,CACtB,IAAK,CAAA,EAAG,IAAA,CAAK,MAAA,CAAO,OAAO,CAAA,CAAA,EAAI,EAC7B,IAAA,CAAK,OAAA,EACN,gBAAA,CAAA,CACD,QAAS,EACT,KAAM,EACN,sBAAuB,EACvB,0BAAA,CAAA,EAA2BF,EAAAA,yBAAAA,EAA0B,GACrD,WADmE,CACtD,EAAQ,WAAA,CACrB,MAAO,IAAA,CAAK,MAAA,CAAO,KAAA,AACrB,CAAC,EAEK,EAAY,EAAS,UAAA,CAAW,CAAC,CAAA,CACjC,EAAyC,CAAC,CAAA,CAG1C,EAAQ,AAAR,OAAQ,EAAA,OAAA,EAAA,EAAU,OAAA,EAAV,KAAA,EAAA,EAAmB,KAAA,EAAnB,EAA4B,CAAC,CAAA,CAErC,EAAgB,EAAS,aAAA,CAM/B,IAAA,IAAW,KAAQ,EACjB,GAAI,CADoB,kBACA,IAAA,AAAQ,IAAR,GAAQ,EAAA,EAAK,cAAA,EAAL,KAAA,EAAA,EAAqB,IAAA,EAAM,CACzD,IAAM,EAAa,IAAA,CAAK,MAAA,CAAO,UAAA,CAAW,EAC1C,EAA8B,EAE9B,EAAQ,IAAA,CAAK,CACX,KAAM,uBACN,EACA,SAAU,iBACV,MAAO,KAAK,SAAA,CAAU,EAAK,cAAc,EACzC,kBAAkB,CACpB,CAAC,CACH,KAAW,EAAX,sBAAoC,GAAQ,EAAK,mBAAA,EAAqB,AACpE,EAAQ,IAAA,CAAK,CACX,KAAM,cAEN,WAAY,EACZ,SAAU,iBACV,OAAQ,CACN,QAAS,EAAK,mBAAA,CAAoB,OAAA,CAClC,OAAQ,EAAK,mBAAA,CAAoB,MAAA,AACnC,EACA,iBAAkB,EACpB,CAAC,EAED,EAA8B,KAAA,GACrB,SAAU,GAAqB,MAAb,EAAK,IAAA,EAAgB,EAAK,IAAA,CAAK,MAAA,CAAS,EACnE,CADsE,CAC9D,IAAA,CAAK,CACX,MAAuB,IAAjB,EAAK,OAAA,CAAmB,YAAc,OAC5C,KAAM,EAAK,IAAA,CACX,iBAAkB,EAAK,gBAAA,CACnB,CAAE,OAAQ,CAAE,iBAAkB,EAAK,gBAAA,AAAiB,CAAE,EACtD,KAAA,CACN,CAAC,EACQ,iBAAkB,EAC3B,EAAQ,EADyB,EACzB,CAAK,CACX,KAAM,YACN,WAAY,IAAA,CAAK,MAAA,CAAO,UAAA,CAAW,EACnC,SAAU,EAAK,YAAA,CAAa,IAAA,CAC5B,MAAO,KAAK,SAAA,CAAU,EAAK,YAAA,CAAa,IAAI,EAC5C,iBAAkB,EAAK,gBAAA,CACnB,CAAE,OAAQ,CAAE,iBAAkB,EAAK,gBAAA,AAAiB,CAAE,EACtD,KAAA,CACN,CAAC,EACQ,eAAgB,GACzB,EAAQ,CADuB,GACvB,CAAK,CACX,KAAM,OACN,KAAM,EAAK,UAAA,CAAW,IAAA,CACtB,UAAW,EAAK,UAAA,CAAW,QAAA,AAC7B,CAAC,EASL,IAAA,IAAW,KALL,AACJ,KAImB,EAJnB,EAAA,EAAe,CACb,CAG0B,iBAHP,EAAU,iBAAA,CAC7B,WAAY,IAAA,CAAK,MAAA,CAAO,UAAA,AAC1B,EAAC,CAAA,CAHD,EAGM,CAAC,CAAA,CAEP,EAAQ,IAAA,CAAK,GAGf,GAHqB,GAGd,SACL,EACA,aAAc,EAAkC,CAC9C,aAAc,EAAU,YAAA,CACxB,aAAc,EAAQ,IAAA,CAAK,GAAsB,WAAW,GAAzB,EAAK,IAAA,CAC1C,CAAC,EACD,MAAO,CACL,YAAA,AAAa,OAAA,EAAA,MAAA,EAAA,KAAA,EAAA,EAAe,gBAAA,EAAf,EAAmC,KAAA,EAChD,aAAA,AAAc,OAAA,EAAA,MAAA,EAAA,KAAA,EAAA,EAAe,oBAAA,EAAf,EAAuC,KAAA,EACrD,YAAA,AAAa,OAAA,EAAA,MAAA,EAAA,KAAA,EAAA,EAAe,eAAA,EAAf,EAAkC,KAAA,EAC/C,gBAAA,AAAiB,OAAA,EAAA,MAAA,EAAA,KAAA,EAAA,EAAe,kBAAA,EAAf,EAAqC,KAAA,EACtD,kBAAA,AAAmB,OAAA,EAAA,MAAA,EAAA,KAAA,EAAA,EAAe,uBAAA,EAAf,EAA0C,KAAA,CAC/D,WACA,EACA,iBAAkB,CAChB,OAAQ,CACN,eAAA,AAAgB,OAAA,EAAA,EAAS,cAAA,EAAT,EAA2B,KAC3C,kBAAA,AAAmB,OAAA,EAAA,EAAU,iBAAA,EAAV,EAA+B,KAClD,mBAAoB,AAApB,OAAoB,EAAA,EAAU,kBAAA,EAAV,EAAgC,KACpD,cAAA,AAAe,OAAA,EAAA,EAAU,aAAA,EAAV,EAA2B,KAC1C,cAAe,MAAA,EAAA,EAAiB,IAClC,CACF,EACA,QAAS,MAAE,CAAK,EAChB,SAAU,CAER,QAAS,EACT,KAAM,CACR,CACF,CACF,CAEA,MAAM,SACJ,CAAA,CAC2D,CAC3D,IAuCI,EAbA,EA1BE,MAAE,CAAA,UAAM,AA0B+C,CA1B/C,CAAS,CAAI,EA0BkC,IA1B5B,IAAA,CAAK,OAAA,CAAQ,GAExC,EAAO,EAFwC,GAEnC,SAAA,CAAU,GACtB,CAD0B,CAC1B,CAAA,EAAUD,EAAAA,cAAAA,EACd,MAAA,CAAA,EAAMI,EAAAA,OAAAA,EAAQ,IAAA,CAAK,MAAA,CAAO,OAAO,EACjC,EAAQ,OAAA,EAGJ,iBAAE,CAAA,CAAiB,MAAO,CAAA,CAAS,CAAI,MAAMD,CAAAA,EAAAA,EAAAA,aAAAA,EAAc,CAC/D,IAAK,CAAA,EAAG,IAAA,CAAK,MAAA,CAAO,OAAO,CAAA,CAAA,EAAI,EAC7B,IAAA,CAAK,OAAA,EACN,8BAAA,CAAA,CACD,UACA,KAAM,EACN,sBAAuB,EACvB,0BAAA,CAAA,EAA2B,EAAA,gCAAA,EAAiC,GAC5D,QADuE,IAC1D,EAAQ,WAAA,CACrB,MAAO,IAAA,CAAK,MAAA,CAAO,KAAA,AACrB,CAAC,EAEG,EAA4C,UAC1C,EAA8B,CAClC,YAAa,KAAA,EACb,aAAc,KAAA,EACd,YAAa,KAAA,CACf,EAGMV,EAAa,IAAA,CAAK,MAAA,CAAO,UAAA,CAC3B,GAAe,EAGf,EAAoC,KACpC,EAAyC,KACzC,EAAe,EAGb,EAAoB,IAAI,IAAY,AAI1C,MAAO,CACL,GALwB,IAKhB,EAAS,OALO,IAKP,CACf,IAAI,gBAGF,CACA,MAAM,CAAA,EAAY,AAChB,EAAW,OAAA,CAAQ,CAAE,KAAM,wBAAgB,CAAS,CAAC,CACvD,EAEA,UAAU,CAAA,CAAO,CAAA,EAAY,IAhXvC,EAAA,EAAA,EAAA,EAAA,EAAA,EAAA,EAAA,EAAA,EAAA,EAAA,EAAA,EA4pB4B,EAvShB,GAJI,AA2SY,EA3SJ,AA2SmC,gBA3SnC,EAAkB,AAC5B,EAAW,OAAA,CAAQ,CAAE,KAAM,MAAO,SAAU,EAAM,QAAS,AAAT,CAAU,EAG1D,CAAC,EAAM,OAAA,CAAS,YAClB,EAAW,OAAA,CAAQ,CAAE,KAAM,QAAS,MAAO,EAAM,KAAA,AAAM,CAAC,EAI1D,IAAM,EAAQ,EAAM,KAAA,CAEd,EAAgB,EAAM,aAEP,AAFO,MAED,CAAvB,IACF,EAAM,WAAA,CAAA,AAAc,OAAA,EAAA,EAAc,gBAAA,EAAd,EAAkC,KAAA,EACtD,EAAM,YAAA,CACJ,AADI,OACJ,EAAA,EAAc,oBAAA,EAAd,EAAsC,KAAA,EACxC,EAAM,WAAA,CAAA,AAAc,OAAA,EAAA,EAAc,eAAA,EAAd,EAAiC,KAAA,EACrD,EAAM,eAAA,CACJ,AADI,MACJ,GAAA,EAAc,kBAAA,EAAd,EAAoC,KAAA,EACtC,EAAM,iBAAA,CACJ,AADI,OACJ,EAAA,EAAc,uBAAA,EAAd,EAAyC,KAAA,GAG7C,IAAM,EAAA,AAAY,OAAA,EAAA,EAAM,UAAA,EAAN,KAAA,EAAA,CAAA,CAAmB,EAAA,CAGrC,GAAiB,MAAb,AAAmB,EACrB,OAGF,IAAM,EAAU,EAAU,OAAA,CAEpB,EAAU,EAAe,CAC7B,kBAAmB,EAAU,iBAAA,CAC7B,WAAAA,CACF,CAAC,EACD,GAAI,AAAW,MAAM,EACnB,IAAA,IAAW,KAAU,EAEK,MAFI,EAE1B,CACA,CADO,UAAA,EACN,EAAkB,GAAA,CAAI,EAAO,GAAG,GACjC,CACA,EAAkB,GAAA,CAAI,EAAO,GAAG,EAChC,EAAW,OAAA,CAAQ,IAMzB,EAN+B,CAM3B,AAAW,QAAM,CAGnB,IAAA,IAAW,KADG,AAAR,GACa,IADL,EACY,AADZ,EAAQ,KAAA,EAAR,EAAiB,CAAC,CAAA,CAE9B,GAAI,mBAAoB,IAAQ,AAAR,IAAA,GAAQ,EAAA,EAAK,cAAA,EAAL,KAAA,EAAA,EAAqB,IAAA,EAAM,CACzD,IAAM,EAAaA,IACnB,EAA8B,EAE9B,EAAW,EAHmB,KAGnB,CAAQ,CACjB,KAAM,uBACN,EACA,SAAU,iBACV,MAAO,KAAK,SAAA,CAAU,EAAK,cAAc,EACzC,kBAAkB,CACpB,CAAC,EAED,GAAe,CACjB,MAAA,GACE,wBAAyB,GACzB,EAAK,mBAAA,CACL,CAEA,IAAM,EAAa,EAEf,IACF,EAAW,MADG,CACH,CAAQ,CACjB,KAAM,cACN,aACA,SAAU,iBACV,OAAQ,CACN,QAAS,EAAK,mBAAA,CAAoB,OAAA,CAClC,OAAQ,EAAK,mBAAA,CAAoB,MAAA,AACnC,EACA,kBAAkB,CACpB,CAAC,EAED,EAA8B,KAAA,EAElC,KACE,EADF,OACY,GACG,MAAb,EAAK,IAAA,EACL,EAAK,IAAA,CAAK,MAAA,CAAS,GACnB,EACqB,IAAjB,EAAK,AAAkB,OAAlB,EAEoB,MAAM,CAA7B,IACF,EAAW,OAAA,CAAQ,CACjB,KAAM,WACN,GAAI,CACN,CAAC,EACD,EAAqB,MAIS,MAAM,CAAlC,IACF,EAA0B,OAAO,KACjC,EAAW,OAAA,AADoC,CAC5B,CACjB,KAAM,kBACN,GAAI,EACJ,iBAAkB,EAAK,gBAAA,CACnB,CACE,OAAQ,CACN,iBAAkB,EAAK,gBAAA,AACzB,CACF,EACA,KAAA,CACN,CAAC,GAGH,EAAW,OAAA,CAAQ,CACjB,KAAM,kBACN,GAAI,EACJ,MAAO,EAAK,IAAA,CACZ,iBAAkB,EAAK,gBAAA,CACnB,CACE,OAAQ,CAAE,iBAAkB,EAAK,gBAAA,AAAiB,CACpD,EACA,KAAA,CACN,CAAC,IAG+B,MAAM,CAAlC,IACF,EAAW,OAAA,CAAQ,CACjB,KAAM,gBACN,GAAI,CACN,CAAC,EACD,EAA0B,MAID,MAAM,CAA7B,IACF,EAAqB,OAAO,KAC5B,EAAW,OAD+B,AAC/B,CAAQ,CACjB,KAAM,aACN,GAAI,EACJ,iBAAkB,EAAK,gBAAA,CACnB,CACE,OAAQ,CACN,iBAAkB,EAAK,gBACzB,AADyB,CAE3B,EACA,KAAA,CACN,CAAC,GAGH,EAAW,OAAA,CAAQ,CACjB,KAAM,aACN,GAAI,EACJ,MAAO,EAAK,IAAA,CACZ,iBAAkB,EAAK,gBAAA,CACnB,CACE,OAAQ,CAAE,iBAAkB,EAAK,gBAAA,AAAiB,CACpD,EACA,KAAA,CACN,CAAC,IAKP,IAAM,EAmIX,SAnIgD,EAAQ,KAA3B,AAAgC,EAmI7D,KAAA,EAAA,EAAO,MAAA,CACZ,AACE,GAGG,eAAgB,GAvIX,GAAuB,MAAnB,AAAyB,EAC3B,IAAA,IAAW,KAAQ,EACjB,EAAW,OAAA,CAAQ,CACjB,GAFgC,EAE1B,OACN,UAAW,EAAK,UAAA,CAAW,QAAA,CAC3B,KAAM,EAAK,UAAA,CAAW,IAAA,AACxB,CAAC,EAIL,IAAM,EA0FpB,AA1FqC,SA0F5B,AAAsB,OAC7B,CAAA,CACA,WAAAA,CAAAA,CACF,EAGG,AACD,IAAM,EAAoB,MAAA,EAAA,KAAA,EAAA,EAAO,MAAA,CAC/B,GAAQ,iBAAkB,GAQ5B,OAA4B,MAArB,GAA6B,AAA6B,MAAX,MAAA,CAClD,KAAA,EACA,EAAkB,GAAA,CAAI,IAAS,CAC7B,EADoB,GACd,YACN,WAAYA,IACZ,QADuB,CACb,EAAK,YAAA,CAAa,IAAA,CAC5B,KAAM,KAAK,SAAA,CAAU,EAAK,YAAA,CAAa,IAAI,EAC3C,iBAAkB,EAAK,gBAAA,CACnB,CAAE,OAAQ,CAAE,iBAAkB,EAAK,gBAAA,AAAiB,CAAE,EACtD,KAAA,EACN,CAAA,CAAE,AACR,EArH2D,CAC3C,MAAO,EAAQ,KAAA,CACf,WAAAA,CACF,CAAC,EAED,GAAsB,MAAM,AAAxB,EACF,IAAA,IAAW,KAAY,EACrB,EAAW,OAAA,CAAQ,CACjB,EAFmC,GAE7B,mBACN,GAAI,EAAS,UAAA,CACb,SAAU,EAAS,QAAA,CACnB,iBAAkB,EAAS,gBAAA,AAC7B,CAAC,EAED,EAAW,OAAA,CAAQ,CACjB,KAAM,mBACN,GAAI,EAAS,UAAA,CACb,MAAO,EAAS,IAAA,CAChB,iBAAkB,EAAS,gBAAA,AAC7B,CAAC,EAED,EAAW,OAAA,CAAQ,CACjB,KAAM,iBACN,GAAI,EAAS,UAAA,CACb,iBAAkB,EAAS,gBAAA,AAC7B,CAAC,EAED,EAAW,OAAA,CAAQ,CACjB,KAAM,YACN,WAAY,EAAS,UAAA,CACrB,SAAU,EAAS,QAAA,CACnB,MAAO,EAAS,IAAA,CAChB,iBAAkB,EAAS,gBAAA,AAC7B,CAAC,EAED,GAAe,CAGrB,CAE8B,MAA1B,AAAgC,EAAtB,YAAA,GACZ,EAAe,EAAkC,CAC/C,aAAc,EAAU,YAAA,cACxB,CACF,CAAC,EAED,EAAmB,CACjB,OAAQ,CACN,eAAA,AAAgB,OAAA,EAAA,EAAM,cAAA,EAAN,EAAwB,KACxC,kBAAA,AAAmB,OAAA,EAAA,EAAU,iBAAA,EAAV,EAA+B,KAClD,mBAAoB,AAApB,OAAoB,EAAA,EAAU,kBAAA,EAAV,EAAgC,KACpD,cAAe,AAAf,OAAe,EAAA,EAAU,aAAA,EAAV,EAA2B,IAC5C,CACF,EACqB,MAAjB,AAAuB,IACzB,EAAiB,MAAA,CAAO,aAAA,CAAgB,CAAA,EAG9C,EAEA,MAAM,CAAA,EAAY,AAEW,MAAM,CAA7B,GACF,EAAW,OAAA,CAAQ,CACjB,KAAM,WACN,GAAI,CACN,CAAC,EAE6B,MAAM,CAAlC,GACF,EAAW,OAAA,CAAQ,CACjB,KAAM,gBACN,GAAI,CACN,CAAC,EAGH,EAAW,OAAA,CAAQ,CACjB,KAAM,sBACN,EACA,yBACA,CACF,CAAC,CACH,CACF,CAAC,GAEH,SAAU,CAAE,QAAS,CAAgB,EACrC,QAAS,MAAE,CAAK,CAClB,CACF,CACF,EAyCA,SAAS,EAAe,mBACtB,CAAA,CACA,WAAAA,CAAAA,CACF,EAGwC,AA5qBxC,IAAA,EA6qBE,OAAA,AAAO,MAAA,GAAA,QAAA,KAAA,EAAA,EAAmB,eAAA,EAAnB,KAAA,EAAA,EACH,MAAA,CACA,AACE,GAGgB,MAAb,EAAM,GAAA,EAEZ,GAAA,CAAI,IAAU,CACb,GADG,EACG,SACN,WAAY,MACZ,GAAIA,IACJ,IAAK,EAAM,EADI,CACJ,CAAI,GAAA,CACf,MAAO,EAAM,GAAA,CAAI,KAAA,CACnB,CAAA,CACJ,CAEO,IAAM,EAA6B,IACxCG,EAAAA,CAAAA,CAAE,MAAA,CAAO,CACP,iBAAkBA,EAAAA,CAAAA,CAAE,KAAA,CAAMA,EAAAA,CAAAA,CAAE,MAAA,CAAO,CAAC,EAAE,OAAA,CAAQ,EAC9C,iBAAkBA,EAAAA,CAAAA,CAAE,KAAA,CAAMA,EAAAA,CAAAA,CAAE,MAAA,CAAO,CAAC,EAAE,OAAA,CAAQ,EAC9C,iBAAkBA,EAAAA,CAAAA,CAAE,MAAA,CAAO,CAAE,gBAAiBA,EAAAA,CAAAA,CAAE,MAAA,CAAO,CAAE,CAAC,EAAE,OAAA,CAAQ,EACpE,gBAAiBA,EAAAA,CAAAA,CACd,KAAA,CACCA,EAAAA,CAAAA,CAAE,MAAA,CAAO,CACP,IAAKA,EAAAA,CAAAA,CACF,MAAA,CAAO,CAAE,IAAKA,EAAAA,CAAAA,CAAE,MAAA,CAAO,EAAG,MAAOA,EAAAA,CAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ,CAAE,CAAC,EACvD,OAAA,CAAQ,EACX,iBAAkBA,EAAAA,CAAAA,CAAE,KAAA,CAAM,CACxBA,EAAAA,CAAAA,CACG,MAAA,CAAO,CAAE,IAAKA,EAAAA,CAAAA,CAAE,MAAA,CAAO,EAAG,MAAOA,EAAAA,CAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ,CAAE,CAAC,EACvD,OAAA,CAAQ,EACXA,EAAAA,CAAAA,CAAE,MAAA,CAAO,CACP,MAAOA,EAAAA,CAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ,EAC1B,KAAMA,EAAAA,CAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ,CAC3B,CAAC,EACF,CACH,CAAC,GAEF,OAAA,CAAQ,EACX,kBAAmBA,EAAAA,CAAAA,CAChB,KAAA,CACCA,EAAAA,CAAAA,CAAE,MAAA,CAAO,CACP,QAASA,EAAAA,CAAAA,CAAE,MAAA,CAAO,CAChB,WAAYA,EAAAA,CAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ,EAC/B,SAAUA,EAAAA,CAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ,EAC7B,KAAMA,EAAAA,CAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ,CAC3B,CAAC,EACD,aAAcA,EAAAA,CAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ,EACjC,sBAAuBA,EAAAA,CAAAA,CAAE,KAAA,CAAMA,EAAAA,CAAAA,CAAE,MAAA,CAAO,CAAC,EAAE,OAAA,CAAQ,EACnD,oBAAqBA,EAAAA,CAAAA,CAAE,KAAA,CAAMA,EAAAA,CAAAA,CAAE,MAAA,CAAO,CAAC,EAAE,OAAA,CAAQ,EACjD,iBAAkBA,EAAAA,CAAAA,CAAE,KAAA,CAAMA,EAAAA,CAAAA,CAAE,MAAA,CAAO,CAAC,EAAE,OAAA,CAAQ,EAC9C,gBAAiBA,EAAAA,CAAAA,CAAE,KAAA,CAAMA,EAAAA,CAAAA,CAAE,MAAA,CAAO,CAAC,EAAE,OAAA,CAAQ,CAC/C,CAAC,GAEF,OAAA,CAAQ,EACX,kBAAmBA,EAAAA,CAAAA,CAChB,KAAA,CAAM,CACLA,EAAAA,CAAAA,CAAE,MAAA,CAAO,CACP,yBAA0BA,EAAAA,CAAAA,CAAE,MAAA,CAAO,CACrC,CAAC,EACDA,EAAAA,CAAAA,CAAE,MAAA,CAAO,CAAC,CAAC,EACZ,EACA,OAAA,CAAQ,CACb,CAAC,EAEG,EAAmB,IACvBA,EAAAA,CAAAA,CAAE,MAAA,CAAO,CACP,MAAOA,EAAAA,CAAAA,CACJ,KAAA,CACCA,EAAAA,CAAAA,CAAE,KAAA,CAAM,CAENA,EAAAA,CAAAA,CAAE,MAAA,CAAO,CACP,aAAcA,EAAAA,CAAAA,CAAE,MAAA,CAAO,CACrB,KAAMA,EAAAA,CAAAA,CAAE,MAAA,CAAO,EACf,KAAMA,EAAAA,CAAAA,CAAE,OAAA,CAAQ,CAClB,CAAC,EACD,iBAAkBA,EAAAA,CAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ,CACvC,CAAC,EACDA,EAAAA,CAAAA,CAAE,MAAA,CAAO,CACP,WAAYA,EAAAA,CAAAA,CAAE,MAAA,CAAO,CACnB,SAAUA,EAAAA,CAAAA,CAAE,MAAA,CAAO,EACnB,KAAMA,EAAAA,CAAAA,CAAE,MAAA,CAAO,CACjB,CAAC,CACH,CAAC,EACDA,EAAAA,CAAAA,CAAE,MAAA,CAAO,CACP,eAAgBA,EAAAA,CAAAA,CACb,MAAA,CAAO,CACN,SAAUA,EAAAA,CAAAA,CAAE,MAAA,CAAO,EACnB,KAAMA,EAAAA,CAAAA,CAAE,MAAA,CAAO,CACjB,CAAC,EACA,OAAA,CAAQ,EACX,oBAAqBA,EAAAA,CAAAA,CAClB,MAAA,CAAO,CACN,QAASA,EAAAA,CAAAA,CAAE,MAAA,CAAO,EAClB,OAAQA,EAAAA,CAAAA,CAAE,MAAA,CAAO,CACnB,CAAC,EACA,OAAA,CAAQ,EACX,KAAMA,EAAAA,CAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ,EACzB,QAASA,EAAAA,CAAAA,CAAE,OAAA,CAAQ,EAAE,OAAA,CAAQ,EAC7B,iBAAkBA,EAAAA,CAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ,CACvC,CAAC,EACF,GAEF,OAAA,CAAQ,CACb,CAAC,EAGG,EAAwB,IAC5BA,EAAAA,CAAAA,CAAE,MAAA,CAAO,CACP,SAAUA,EAAAA,CAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ,EAC7B,YAAaA,EAAAA,CAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ,EAChC,iBAAkBA,EAAAA,CAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ,EACrC,SAAUA,EAAAA,CAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ,EAC7B,cAAeA,EAAAA,CAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ,EAClC,QAASA,EAAAA,CAAAA,CAAE,OAAA,CAAQ,EAAE,OAAA,CAAQ,CAC/B,CAAC,EAEG,EAAcA,EAAAA,CAAAA,CAAE,MAAA,CAAO,CAC3B,wBAAyBA,EAAAA,CAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ,EAC5C,mBAAoBA,EAAAA,CAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ,EACvC,iBAAkBA,EAAAA,CAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ,EACrC,qBAAsBA,EAAAA,CAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ,EACzC,gBAAiBA,EAAAA,CAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ,CACtC,CAAC,EAGY,EAA8B,IACzCA,EAAAA,CAAAA,CAAE,MAAA,CAAO,CACP,YAAaA,EAAAA,CAAAA,CAAE,KAAA,CACbA,EAAAA,CAAAA,CAAE,MAAA,CAAO,CACP,aAAcA,EAAAA,CAAAA,CAAE,MAAA,CAAO,EACvB,mBAAoBA,EAAAA,CAAAA,CAAE,MAAA,CAAO,CAC/B,CAAC,EAEL,CAAC,EAEG,EAAA,CAAA,EAAiBF,EAAAA,UAAAA,EAAW,IAAA,CAAA,EAChCC,EAAAA,SAAAA,EACEC,EAAAA,CAAAA,CAAE,MAAA,CAAO,CACP,WAAYA,EAAAA,CAAAA,CAAE,KAAA,CACZA,EAAAA,CAAAA,CAAE,MAAA,CAAO,CACP,QAAS,IAAmB,OAAA,CAAQ,EAAE,EAAA,CAAZ,AAAeA,EAAAA,CAAAA,CAAE,MAAA,CAAO,CAAC,CAAC,EAAE,MAAA,CAAO,CAAC,EAC9D,aAAcA,EAAAA,CAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ,EACjC,cAAeA,EAAAA,CAAAA,CAAE,KAAA,CAAM,KAAyB,OAAA,CAAQ,EACxD,OAD6C,CAAC,UAC3B,IAA6B,OAAA,CAAQ,EACxD,aAD8C,MAC1B,IAA8B,OAAA,CAAQ,CAC5D,CAAC,GAEH,WAHoD,GAGrC,EAAY,OAAA,CAAQ,EACnC,eAAgBA,EAAAA,CAAAA,CACb,MAAA,CAAO,CACN,YAAaA,EAAAA,CAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ,EAChC,cAAeA,EAAAA,CAAAA,CAAE,KAAA,CAAM,KAAyB,OAAA,CAAQ,CAC1D,CAAC,EACA,KAF8C,CAAC,CAE/C,CAAQ,CACb,CAAC,IA6BC,EAAA,CAAA,EAAcF,EAAAA,UAAAA,EAAW,IAAA,CAAA,EAC7BC,EAAAA,SAAAA,EACEC,EAAAA,CAAAA,CAAE,MAAA,CAAO,CACP,WAAYA,EAAAA,CAAAA,CACT,KAAA,CACCA,EAAAA,CAAAA,CAAE,MAAA,CAAO,CACP,QAAS,IAAmB,OAAA,CAAQ,EACpC,GAD0B,UACZA,EAAAA,CAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ,EACjC,cAAeA,EAAAA,CAAAA,CAAE,KAAA,CAAM,KAAyB,OAAA,CAAQ,EACxD,OAD6C,CAAC,UAC3B,IAA6B,OAAA,CAAQ,EACxD,aAD8C,MAC1B,IAA8B,OAAA,CAAQ,CAC5D,CAAC,GAEF,OAAA,CAAQ,EACX,CAJsD,aAIvC,EAAY,OAAA,CAAQ,EACnC,eAAgBA,EAAAA,CAAAA,CACb,MAAA,CAAO,CACN,YAAaA,EAAAA,CAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ,EAChC,cAAeA,EAAAA,CAAAA,CAAE,KAAA,CAAM,KAAyB,OAAA,CAAQ,CAC1D,CAAC,EACA,KAF8C,CAAC,CAE/C,CAAQ,CACb,CAAC,IO/2BQ,EAAA,CAAA,EAAgB,EAAA,gDAAA,EAU3B,CACA,GAAI,wBACJ,KAAM,iBACN,YAAaA,EAAAA,CAAAA,CAAE,MAAA,CAAO,CACpB,SAAUA,EAAAA,CAAAA,CAAE,MAAA,CAAO,EAAE,QAAA,CAAS,uCAAuC,EACrE,KAAMA,EAAAA,CAAAA,CAAE,MAAA,CAAO,EAAE,QAAA,CAAS,0BAA0B,CACtD,CAAC,EACD,aAAcA,EAAAA,CAAAA,CAAE,MAAA,CAAO,CACrB,QAASA,EAAAA,CAAAA,CACN,MAAA,CAAO,EACP,QAAA,CAAS,oDAAoD,EAChE,OAAQA,EAAAA,CAAAA,CAAE,MAAA,CAAO,EAAE,QAAA,CAAS,qCAAqC,CACnE,CAAC,CACH,CAAC,EC3BK,EAA2BA,EAAAA,CAAAA,CAC9B,MAAA,CAAO,CAIN,qBAAsBA,EAAAA,CAAAA,CACnB,KAAA,CAAMA,EAAAA,CAAAA,CAAE,MAAA,CAAO,CAAC,EAChB,QAAA,CACC,8GAGJ,KAAMA,EAAAA,CAAAA,CACH,MAAA,CAAO,EACP,GAAA,CAAI,EACJ,QAAA,CAAS,EACT,QAAA,CAAS,yDAAyD,EAClE,QAAA,CAAS,EAKZ,eAAgBA,EAAAA,CAAAA,CACb,MAAA,CAAO,EACP,QAAA,CACC,4IAED,QAAA,CAAS,CACd,CAAC,EACA,WAAA,CAAY,EAIT,EAAA,CAAA,EAAuBF,EAAAA,UAAAA,EAAW,IAAA,CAAA,EACtCC,EAAAA,SAAAA,EAAU,IAGC,EAAA,CAAA,EAAa,EAAA,aAHU,mBAGV,EAGxB,CACA,GAAI,qBACJ,KAAM,cACN,YAAa,CACf,CAAC,EG9CY,EAAc,CAKzB,aFCW,CAAA,EAAea,EAAAA,gCAAAA,EAgB1B,CACA,GAAI,uBACJ,KAAM,gBACN,YAAA,CAAA,EAAad,EAAAA,UAAAA,EAAW,IAAA,CAAA,EACtBC,EAAAA,SAAAA,EACEC,EAAAA,CAAAA,CAAE,MAAA,CAAO,CACP,KAAMA,EAAAA,CAAAA,CACH,IAAA,CAAK,CAAC,eAAgB,kBAAkB,CAAC,EACzC,OAAA,CAAQ,kBAAkB,EAC7B,iBAAkBA,EAAAA,CAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ,CAAC,CACxC,CAAC,GAGP,CAAC,EExBC,WDTwBY,CAAAA,EAAAA,EAAAA,gCAAAA,EAKxB,CACA,GAAI,qBACJ,KAAM,cACN,YAAA,CAAA,EAAad,EAAAA,UAAAA,EAAW,IAAA,CAAA,EAAMC,EAAAA,SAAAA,EAAUC,EAAAA,CAAAA,CAAE,MAAA,CAAO,CAAC,CAAC,CAAC,CAAC,CACvD,CAAC,aCWC,gBAWA,CACF,ECTa,EAAN,MAA2D,AAYhE,YACW,CAAA,CACQ,CAAA,CACA,CAAA,CACjB,CAHS,IAAA,CAAA,OAAA,CAAA,EACQ,IAAA,CAAA,QAAA,CAAA,EACA,IAAA,CAAA,MAAA,CAAA,EAdnB,IAAA,CAAS,oBAAA,CAAuB,IAe7B,CAbH,IAAI,kBAA2B,CAjCjC,IAAA,EAmCI,OAAA,AAAO,OAAA,EAAA,IAAA,CAAK,QAAA,CAAS,gBAAA,EAAd,EAAkC,CAC3C,CAEA,IAAI,UAAmB,CACrB,OAAO,IAAA,CAAK,MAAA,CAAO,QACrB,AADqB,CASrB,MAAM,WACJ,CAAA,CAC0D,CAlD9D,IAAA,EAAA,EAAA,EAmDI,GAAM,QACJ,CAAA,CACA,IAAI,CAAA,MACJ,EAAO,WAAA,aACP,EAAc,KAAA,MACd,CAAA,iBACA,CAAA,SACA,CAAA,aACA,CAAA,CACF,CAAI,EACE,EAA2C,CAAC,CAAA,AAEtC,MAAM,CAAd,GACF,EAAS,IAAA,CAAK,CACZ,KAAM,sBACN,QAAS,OACT,QACE,2EACJ,CAAC,EAGS,MAAR,AAAc,GAChB,EAAS,IAAA,CAAK,CACZ,KAAM,sBACN,QAAS,OACT,QACE,sEACJ,CAAC,EAGH,IAAM,EAAgB,MAAA,CAAA,EAAMM,EAAAA,oBAAAA,EAAqB,CAC/C,SAAU,yBACV,EACA,OAAQ,CACV,CAAC,EAEK,EAAA,AAAc,OAAA,EAAA,OAAA,EAAA,OAAA,EAAA,IAAA,CAAK,MAAA,CAAO,SAAA,EAAZ,KAAA,EAAA,EAAuB,WAAA,EAAvB,KAAA,EAAA,EAAA,IAAA,CAAA,EAAA,CAAA,CAAA,EAA0C,GAAA,CAAI,KAAK,AAEjE,EAAsC,CAC1C,IAH4D,QAG/C,CACf,CAEmB,MAAM,CAArB,IACF,EAAW,WAAA,CAAc,CAAA,EAGvB,GACF,OAAO,KADU,CACV,CAAO,EAAY,GAQ5B,GAAM,OARmC,UAQjC,CAAA,CAAiB,MAAO,CAAA,CAAS,CAAI,MAAA,CAAA,EAAMC,EAAAA,aAAAA,EAEhD,CACD,IAAK,CAAA,EAAG,IAAA,CAAK,MAAA,CAAO,OAAO,CAAA,QAAA,EAAW,IAAA,CAAK,OAAO,CAAA,QAAA,CAAA,CAClD,QAAA,CAAA,EAASH,EAAAA,cAAAA,EAAe,MAAA,CAAA,EAAMI,EAAAA,OAAAA,EAAQ,IAAA,CAAK,MAAA,CAAO,OAAO,EAAG,GAC5D,IADmE,CATxD,CACX,UAAW,CAAC,QAAE,CAAO,CAAC,CAAA,CACtB,YACF,EAQE,sBAAuB,EACvB,0BAAA,CAAA,EAA2BH,EAAAA,yBAAAA,EACzB,eAEF,EACA,MAAO,IAAA,CAAK,MAAA,CAAO,KAAA,AACrB,CAAC,EACD,MAAO,CACL,OAAQ,EAAS,WAAA,CAAY,GAAA,CAC3B,AAAC,GAAsC,EAAE,kBAAA,EAE3C,SAAU,MAAA,EAAA,EAAY,CAAC,CAAA,CACvB,iBAAkB,CAChB,OAAQ,CACN,OAAQ,EAAS,WAAA,CAAY,GAAA,CAAI,IAAe,EAEhD,CAAA,CAAE,AACJ,CACF,EACA,EALqC,OAK3B,CACR,UAAW,EACX,QAAS,IAAA,CAAK,OAAA,CACd,QAAS,CACX,CACF,CACF,CACF,EAGM,EAAA,CAAA,EAA4BP,EAAAA,UAAAA,EAAW,IAAA,CAAA,EAC3CC,EAAAA,SAAAA,EACEC,EAAAA,CAAAA,CAAE,MAAA,CAAO,CACP,YAAaA,EAAAA,CAAAA,CACV,KAAA,CAAMA,EAAAA,CAAAA,CAAE,MAAA,CAAO,CAAE,mBAAoBA,EAAAA,CAAAA,CAAE,MAAA,CAAO,CAAE,CAAC,CAAC,EAClD,OAAA,CAAQ,CAAC,CAAC,CACf,CAAC,IAMC,EAAA,CAAA,EAAmCF,EAAAA,UAAAA,EAAW,IAAA,CAAA,EAClDC,EAAAA,SAAAA,EACEC,EAAAA,CAAAA,CAAE,MAAA,CAAO,CACP,iBAAkBA,EAAAA,CAAAA,CACf,IAAA,CAAK,CAAC,aAAc,cAAe,WAAW,CAAC,EAC/C,OAAA,CAAQ,EACX,YAAaA,EAAAA,CAAAA,CAAE,IAAA,CAAK,CAAC,MAAO,MAAO,MAAO,OAAQ,MAAM,CAAC,EAAE,OAAA,CAAQ,CACrE,CAAC,IjBzDE,SAAS,EACd,EAA8C,CAAC,CAAA,EACnB,AAzG9B,IAAA,EAAA,EA0GE,IAAM,EAAA,AACJ,OAAA,EAAA,CAAA,EAAA,EAAA,oBAAA,EAAqB,EAAQ,OAAO,CAAA,EAApC,EACA,mDAEI,EAAA,AAAe,OAAA,EAAA,EAAQ,IAAA,EAAR,EAAgB,uBAE/B,EAAa,IAAA,CAAA,EACjB,EAAA,mBAAA,EACE,CACE,iBAAA,CAAA,EAAkB,EAAA,UAAA,EAAW,CAC3B,OAAQ,EAAQ,MAAA,CAChB,wBAAyB,+BACzB,YAAa,sBACf,CAAC,EACD,GAAG,EAAQ,OAAA,AACb,EACA,CAAA,cAAA,EAAiB,OAAO,AAGtB,EAHsB,AAGJ,AAAC,IA7H3B,IAAAS,EA8HI,EAD2D,KAC3D,IAAI,EAAgC,EAAS,CAC3C,SAAU,EACV,UACA,QAAS,EACT,WAAA,AAAY,OAAAA,EAAA,EAAQ,UAAA,EAARA,EAAsBZ,EAAAA,UAAAA,CAClC,cAAe,IAAA,CAAO,CACpB,IAAK,CAGH,AAAI,OAAO,CAAA,CAAA,EAAI,EAAO,KAAA,KAAA,CAAY,EAElC,AAAI,OACF,CAAA,oEAAA,CAAA,EAEF,AAAI,OAAO,CAAA,8CAAA,CAAgD,EAC7D,CACF,CAAA,CACA,MAAO,EAAQ,KAAA,AACjB,CAAC,CAAA,EAEG,EAAwB,AAAD,GAC3B,IAAI,EAAiC,EAAS,CAC5C,SAAU,EACV,UACA,QAAS,EACT,MAAO,EAAQ,KAAA,AACjB,CAAC,EAEG,EAAmB,CACvB,EACA,EAA4C,CAAC,CAAA,GAE7C,IAAI,EAA6B,EAAS,EAAU,CAClD,SAAU,UACV,EACA,QAAS,EACT,MAAO,EAAQ,KAAA,AACjB,CAAC,EAEG,EAAW,SAAU,CAAA,EAAoC,AAC7D,GAAI,WACF,CADc,KACR,AAAI,MACR,kFAIJ,OAAO,EAAgB,EACzB,EAWA,GAZgC,IAGhC,EAAS,aAAA,CAAgB,EACzB,EAAS,IAAA,CAAO,EAChB,EAAS,YAAA,CAAe,EACxB,EAAS,SAAA,CAAY,EACrB,EAAS,aAAA,CAAgB,EACzB,EAAS,kBAAA,CAAqB,EAC9B,EAAS,KAAA,CAAQ,EACjB,EAAS,UAAA,CAAa,EACtB,EAAS,KAAA,CAAQ,EACV,CACT,CAKO,IAAM,EAAS,yBAAyB"}